{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Using SDL2 binaries from pysdl2-dll 2.30.0\n"
     ]
    }
   ],
   "source": [
    "from pok_env_gym_RLLib import PokemonEnv\n",
    "from ray.tune.registry import register_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(arg):\n",
    "    print(arg)\n",
    "    return PokemonEnv()\n",
    "\n",
    "register_env(\"PokemonEnv\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 17:58:09,970\tWARNING deprecation.py:50 -- DeprecationWarning: `rllib/algorithms/simple_q/` has been deprecated. Use `rllib_contrib/simple_q/` instead. This will raise an error in the future!\n",
      "/Users/jskaf/miniconda3/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:483: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/Users/jskaf/miniconda3/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/jskaf/miniconda3/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/jskaf/miniconda3/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-03-07 17:58:11,683\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m {, worker=1/2, vector_idx=0, remote=False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m 2024-03-07 17:58:14,191\tWARNING env.py:162 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 17:58:15,887\tWARNING util.py:62 -- Install gputil for GPU system monitoring.\n",
      "2024-03-07 17:58:16,213\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m 2024-03-07 17:58:16.772 python[95588:4402642] Warning: Window move completed without beginning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m {, worker=2/2, vector_idx=0, remote=False}\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 17:58:22,844\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 68x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 1000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 1000\n",
      "  num_agent_steps_sampled: 1000\n",
      "  num_agent_steps_trained: 28800\n",
      "  num_env_steps_sampled: 1000\n",
      "  num_env_steps_trained: 28800\n",
      "  num_target_updates: 2\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_17-59-36\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 1000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.00045619055163115263\n",
      "        max_q: 0.0178279597312212\n",
      "        mean_q: 0.010365869849920273\n",
      "        min_q: 0.005030696280300617\n",
      "      mean_td_error: -0.00022338892449624836\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 450.0\n",
      "      td_error: [0.0036355480551719666, -0.0035962769761681557, -0.00043467897921800613,\n",
      "        0.006228750571608543, -0.002964983694255352, -0.000627114437520504, 0.0036355480551719666,\n",
      "        -0.0008314372971653938, 0.002615978941321373, -0.008728766813874245, -0.0035962769761681557,\n",
      "        -0.0036513078957796097, 0.0021329079754650593, -0.0008325120434165001, -0.008728766813874245,\n",
      "        -0.000627114437520504, 0.0016237772069871426, 0.0017247376963496208, 0.000768579076975584,\n",
      "        0.002415485680103302, 0.002575431950390339, 0.005493308883160353, 0.002656647004187107,\n",
      "        -0.008808299899101257, -0.0006835456006228924, -0.0008325120434165001, 0.0006090020760893822,\n",
      "        0.002843084279447794, 0.006210343912243843, 0.00016448553651571274, -0.000627114437520504,\n",
      "        -0.0025104722008109093, 0.00039054639637470245, 0.0003720521926879883, 0.0017237495630979538,\n",
      "        -0.0003924081102013588, 0.00016448553651571274, -0.0028118854388594627, -0.003334205597639084,\n",
      "        -0.001788436435163021, -0.0014014430344104767, -0.0014089061878621578, -0.004694425966590643,\n",
      "        -0.0022896751761436462, -0.0019108578562736511, 0.000768579076975584, 0.005195301026105881,\n",
      "        -0.0026075737550854683, -0.001871895045042038, 0.003126133233308792, 0.0017247376963496208,\n",
      "        -0.0017166873440146446, 0.0017020595259964466, -0.004682845901697874, 0.0017237495630979538,\n",
      "        0.006228750571608543, -0.0035962769761681557, 0.0036355480551719666, -0.0003924081102013588,\n",
      "        -0.0035862354561686516, 0.00039054639637470245, 0.0036355480551719666, -0.0001936415210366249,\n",
      "        -0.0036513078957796097]\n",
      "  num_agent_steps_sampled: 1000\n",
      "  num_agent_steps_trained: 28800\n",
      "  num_env_steps_sampled: 1000\n",
      "  num_env_steps_trained: 28800\n",
      "  num_target_updates: 2\n",
      "iterations_since_restore: 1\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 1000\n",
      "num_agent_steps_trained: 28800\n",
      "num_env_steps_sampled: 1000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 12.429354398706632\n",
      "num_env_steps_trained: 28800\n",
      "num_env_steps_trained_this_iter: 28800\n",
      "num_env_steps_trained_throughput_per_sec: 357.965406682751\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 28800\n",
      "perf:\n",
      "  cpu_util_percent: 10.784347826086956\n",
      "  ram_util_percent: 52.873913043478275\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 80.47181797027588\n",
      "time_this_iter_s: 80.47181797027588\n",
      "time_total_s: 80.47181797027588\n",
      "timers:\n",
      "  learn_throughput: 6085.385\n",
      "  learn_time_ms: 10.517\n",
      "  load_throughput: 771587.974\n",
      "  load_time_ms: 0.083\n",
      "  sample_time_ms: 140.194\n",
      "  synch_weights_time_ms: 3.991\n",
      "  training_iteration_time_ms: 164.628\n",
      "timestamp: 1709830776\n",
      "timesteps_total: 1000\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 2000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 2000\n",
      "  num_agent_steps_sampled: 2000\n",
      "  num_agent_steps_trained: 60800\n",
      "  num_env_steps_sampled: 2000\n",
      "  num_env_steps_trained: 60800\n",
      "  num_target_updates: 4\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-00-57\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 2000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0001618407404748723\n",
      "        max_q: 0.022105682641267776\n",
      "        mean_q: 0.016286060214042664\n",
      "        min_q: 0.01281355693936348\n",
      "      mean_td_error: -0.0009949732339009643\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 950.0\n",
      "      td_error: [-0.0007714051753282547, -0.0008175075054168701, -0.0016687307506799698,\n",
      "        -0.003320656716823578, 0.00042229704558849335, -0.0022454485297203064, -0.0008646966889500618,\n",
      "        -0.003320656716823578, -8.257105946540833e-06, -0.0012863650918006897, -0.0025575626641511917,\n",
      "        -0.0007106838747859001, -0.00027445144951343536, -0.0005938336253166199, -0.005254334770143032,\n",
      "        -0.0007106838747859001, -0.000383526086807251, -0.0007106838747859001, -0.0022026561200618744,\n",
      "        9.533576667308807e-05, -0.0003032218664884567, 9.533576667308807e-05, 0.002224268391728401,\n",
      "        -0.0005938336253166199, -0.003390338271856308, -0.0005938336253166199, -0.005137484520673752,\n",
      "        -4.0259212255477905e-05, -0.0007106838747859001, 0.0003126021474599838, -0.00011282507330179214,\n",
      "        0.0004087574779987335, -0.001849709078669548, -0.0020769722759723663, -9.139813482761383e-05,\n",
      "        -0.003320656716823578, -0.00017351843416690826, -0.0013401024043560028, -0.00010179169476032257,\n",
      "        0.0005272310227155685, 0.0010407380759716034, -0.003390338271856308, -0.002847053110599518,\n",
      "        -0.0012003518640995026, 0.000776657834649086, 0.0005272310227155685, -0.005254334770143032,\n",
      "        0.0003126021474599838, 0.0003144312649965286, -0.004016419872641563, -0.0028344402089715004,\n",
      "        0.0017092106863856316, 0.001153312623500824, -0.004016419872641563, 0.0004087574779987335,\n",
      "        -0.0007106838747859001, -0.001206008717417717, 0.000372815877199173, -0.0008039772510528564,\n",
      "        -0.004050757735967636, 0.0001940615475177765, -0.0019071828573942184, 0.0005272310227155685,\n",
      "        0.004675574600696564]\n",
      "  num_agent_steps_sampled: 2000\n",
      "  num_agent_steps_trained: 60800\n",
      "  num_env_steps_sampled: 2000\n",
      "  num_env_steps_trained: 60800\n",
      "  num_target_updates: 4\n",
      "iterations_since_restore: 2\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 2000\n",
      "num_agent_steps_trained: 60800\n",
      "num_env_steps_sampled: 2000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 12.297913439296993\n",
      "num_env_steps_trained: 60800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 393.5332300575038\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.280000000000001\n",
      "  ram_util_percent: 52.812173913043466\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 161.8036186695099\n",
      "time_this_iter_s: 81.33180069923401\n",
      "time_total_s: 161.8036186695099\n",
      "timers:\n",
      "  learn_throughput: 6203.817\n",
      "  learn_time_ms: 10.316\n",
      "  load_throughput: 824686.501\n",
      "  load_time_ms: 0.078\n",
      "  sample_time_ms: 137.655\n",
      "  synch_weights_time_ms: 3.004\n",
      "  training_iteration_time_ms: 160.468\n",
      "timestamp: 1709830857\n",
      "timesteps_total: 2000\n",
      "training_iteration: 2\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 3000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 3000\n",
      "  num_agent_steps_sampled: 3000\n",
      "  num_agent_steps_trained: 92800\n",
      "  num_env_steps_sampled: 3000\n",
      "  num_env_steps_trained: 92800\n",
      "  num_target_updates: 6\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-02-19\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 3000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 1449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 7.0260874053929e-05\n",
      "        max_q: 0.02319316565990448\n",
      "        mean_q: 0.018890175968408585\n",
      "        min_q: 0.01605064421892166\n",
      "      mean_td_error: 8.690872346051037e-05\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 1450.0\n",
      "      td_error: [0.0011494159698486328, 0.0013820603489875793, -0.0023099277168512344,\n",
      "        0.0004695821553468704, -4.735589027404785e-05, 0.0013499874621629715, -0.0012415088713169098,\n",
      "        -9.746290743350983e-05, -0.00017596781253814697, 1.9060447812080383e-05, 0.0004836060106754303,\n",
      "        -0.0005514305084943771, 0.0002861078828573227, -0.0023582950234413147, 0.0014577098190784454,\n",
      "        -0.00301181897521019, 0.0013820603489875793, 0.001698032021522522, -0.0023099277168512344,\n",
      "        0.00013427436351776123, 0.0003200508654117584, 0.0004695821553468704, -0.00012126751244068146,\n",
      "        0.0013820603489875793, 0.00013427436351776123, 0.0013499874621629715, 0.0013820603489875793,\n",
      "        -0.0020143333822488785, 0.0013820603489875793, -0.0006666798144578934, -0.0004890225827693939,\n",
      "        0.0012727323919534683, 0.00013427436351776123, 0.0013820603489875793, 0.0012727323919534683,\n",
      "        -0.0008699800819158554, -0.00035593658685684204, 0.0018391162157058716, -0.00038089416921138763,\n",
      "        0.00012560561299324036, 0.0007626973092556, 0.0005494151264429092, -0.00044314563274383545,\n",
      "        0.00013427436351776123, 0.0004743337631225586, -0.0023099277168512344, 0.0009683538228273392,\n",
      "        -0.0012415088713169098, -0.0008699800819158554, 0.0013820603489875793, 0.00013427436351776123,\n",
      "        0.0002861078828573227, 0.0004107784479856491, 1.9060447812080383e-05, 0.0007670186460018158,\n",
      "        -0.00031214021146297455, 0.0002861078828573227, 0.0007670186460018158, 0.0009025242179632187,\n",
      "        -0.0003015603870153427, -0.0003015603870153427, -0.0015538129955530167, -0.00043242983520030975,\n",
      "        0.00022751465439796448]\n",
      "  num_agent_steps_sampled: 3000\n",
      "  num_agent_steps_trained: 92800\n",
      "  num_env_steps_sampled: 3000\n",
      "  num_env_steps_trained: 92800\n",
      "  num_target_updates: 6\n",
      "iterations_since_restore: 3\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 3000\n",
      "num_agent_steps_trained: 92800\n",
      "num_env_steps_sampled: 3000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 12.278490632754197\n",
      "num_env_steps_trained: 92800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 392.9117002481343\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.418103448275858\n",
      "  ram_util_percent: 53.064655172413794\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 243.26407647132874\n",
      "time_this_iter_s: 81.46045780181885\n",
      "time_total_s: 243.26407647132874\n",
      "timers:\n",
      "  learn_throughput: 6082.434\n",
      "  learn_time_ms: 10.522\n",
      "  load_throughput: 751078.5\n",
      "  load_time_ms: 0.085\n",
      "  sample_time_ms: 141.223\n",
      "  synch_weights_time_ms: 3.038\n",
      "  training_iteration_time_ms: 164.45\n",
      "timestamp: 1709830939\n",
      "timesteps_total: 3000\n",
      "training_iteration: 3\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 4000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 4000\n",
      "  num_agent_steps_sampled: 4000\n",
      "  num_agent_steps_trained: 124800\n",
      "  num_env_steps_sampled: 4000\n",
      "  num_env_steps_trained: 124800\n",
      "  num_target_updates: 8\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-03-41\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 4000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 1949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0014283634955063462\n",
      "        max_q: 0.032769668847322464\n",
      "        mean_q: 0.02031729556620121\n",
      "        min_q: 0.008453748188912868\n",
      "      mean_td_error: -0.0003902643802575767\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 1950.0\n",
      "      td_error: [0.0021285638213157654, -0.0013300925493240356, 0.00035220012068748474,\n",
      "        0.010415714234113693, -0.007023553363978863, -0.007023553363978863, 0.011212192475795746,\n",
      "        -0.002310466021299362, 0.0021285638213157654, 0.008673328906297684, 0.009132958948612213,\n",
      "        -0.0006110034883022308, 0.0077902209013700485, 0.009265601634979248, -0.0026965290307998657,\n",
      "        0.009395789355039597, -0.007023553363978863, -0.007023553363978863, 0.0021949317306280136,\n",
      "        -0.0006110034883022308, 0.009265601634979248, -0.006584318354725838, 0.0028085894882678986,\n",
      "        -0.0026965290307998657, 0.008549654856324196, -0.0006110034883022308, -0.0006110034883022308,\n",
      "        0.004619311541318893, -0.0035576103255152702, 0.0009915828704833984, 0.007907981052994728,\n",
      "        0.005905643105506897, -0.00576749537140131, 0.009132958948612213, -0.0035576103255152702,\n",
      "        -0.0075250593945384026, -0.0035576103255152702, 0.007907981052994728, 0.0009915828704833984,\n",
      "        0.00035220012068748474, 0.009265601634979248, -0.010066655464470387, -0.003522406332194805,\n",
      "        -0.007023553363978863, -0.012678494676947594, -0.010139630176126957, -0.0006110034883022308,\n",
      "        0.0021285638213157654, -0.009305037558078766, 0.0053219422698020935, -0.004318051040172577,\n",
      "        -0.0035576103255152702, 0.001570582389831543, -0.003740644082427025, 0.0015610028058290482,\n",
      "        -0.01395087968558073, -0.008289382793009281, -0.0035576103255152702, -0.002813812345266342,\n",
      "        -0.007824721746146679, 0.0021285638213157654, 0.006235761567950249, -0.007023553363978863,\n",
      "        -0.00576749537140131]\n",
      "  num_agent_steps_sampled: 4000\n",
      "  num_agent_steps_trained: 124800\n",
      "  num_env_steps_sampled: 4000\n",
      "  num_env_steps_trained: 124800\n",
      "  num_target_updates: 8\n",
      "iterations_since_restore: 4\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 4000\n",
      "num_agent_steps_trained: 124800\n",
      "num_env_steps_sampled: 4000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 12.186314523547356\n",
      "num_env_steps_trained: 124800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 389.9620647535154\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.479487179487181\n",
      "  ram_util_percent: 53.35641025641025\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 325.3404314517975\n",
      "time_this_iter_s: 82.07635498046875\n",
      "time_total_s: 325.3404314517975\n",
      "timers:\n",
      "  learn_throughput: 6100.695\n",
      "  learn_time_ms: 10.491\n",
      "  load_throughput: 763685.508\n",
      "  load_time_ms: 0.084\n",
      "  sample_time_ms: 139.537\n",
      "  synch_weights_time_ms: 2.986\n",
      "  training_iteration_time_ms: 162.575\n",
      "timestamp: 1709831021\n",
      "timesteps_total: 4000\n",
      "training_iteration: 4\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 5000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 5000\n",
      "  num_agent_steps_sampled: 5000\n",
      "  num_agent_steps_trained: 156800\n",
      "  num_env_steps_sampled: 5000\n",
      "  num_env_steps_trained: 156800\n",
      "  num_target_updates: 10\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-05-03\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 5000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 2449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.00099326076451689\n",
      "        max_q: 0.043892331421375275\n",
      "        mean_q: 0.027847152203321457\n",
      "        min_q: 0.021024290472269058\n",
      "      mean_td_error: -0.002116495743393898\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 2450.0\n",
      "      td_error: [0.00339324027299881, -0.003548296168446541, -0.0003565065562725067,\n",
      "        -0.0003565065562725067, -0.0009161271154880524, -0.0015026740729808807, -0.003548296168446541,\n",
      "        -0.0019291192293167114, -0.008198481053113937, -0.004225671291351318, -0.0007522366940975189,\n",
      "        0.0006889030337333679, 0.0017594583332538605, -0.003230297937989235, 0.0006889030337333679,\n",
      "        -0.006802404299378395, 4.038214683532715e-05, -0.0036676861345767975, -0.00728834792971611,\n",
      "        0.0017881859093904495, 0.00339324027299881, 0.00339324027299881, -0.004140906035900116,\n",
      "        0.0008608773350715637, -0.0023945271968841553, -0.0012186430394649506, 0.0004988610744476318,\n",
      "        -0.0044326577335596085, -0.0015026740729808807, -0.007198134437203407, 0.0004988610744476318,\n",
      "        -0.00578761100769043, 0.0014513898640871048, 0.0004988610744476318, 5.033612251281738e-05,\n",
      "        -0.003452705219388008, -0.004225671291351318, -0.01088118925690651, 0.0017594583332538605,\n",
      "        -0.0012186430394649506, -0.0015316680073738098, -0.0019291192293167114, -0.0032267197966575623,\n",
      "        0.0004573594778776169, 0.0022313054651021957, -0.008613865822553635, -0.01088118925690651,\n",
      "        0.0017881859093904495, -0.0003565065562725067, 4.038214683532715e-05, -0.002496916800737381,\n",
      "        -0.0003565065562725067, 0.0004988610744476318, -0.01620354875922203, -0.002023046836256981,\n",
      "        5.033612251281738e-05, -0.0019291192293167114, -0.003491543233394623, 0.0006458815187215805,\n",
      "        -0.01062646135687828, -0.008198481053113937, -0.0017118193209171295, 0.00339324027299881,\n",
      "        0.0010270476341247559]\n",
      "  num_agent_steps_sampled: 5000\n",
      "  num_agent_steps_trained: 156800\n",
      "  num_env_steps_sampled: 5000\n",
      "  num_env_steps_trained: 156800\n",
      "  num_target_updates: 10\n",
      "iterations_since_restore: 5\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 5000\n",
      "num_agent_steps_trained: 156800\n",
      "num_env_steps_sampled: 5000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 12.195246870502393\n",
      "num_env_steps_trained: 156800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 390.2478998560766\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.25\n",
      "  ram_util_percent: 53.60431034482759\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 407.3574044704437\n",
      "time_this_iter_s: 82.01697301864624\n",
      "time_total_s: 407.3574044704437\n",
      "timers:\n",
      "  learn_throughput: 6157.384\n",
      "  learn_time_ms: 10.394\n",
      "  load_throughput: 675139.477\n",
      "  load_time_ms: 0.095\n",
      "  sample_time_ms: 138.098\n",
      "  synch_weights_time_ms: 2.975\n",
      "  training_iteration_time_ms: 161.573\n",
      "timestamp: 1709831103\n",
      "timesteps_total: 5000\n",
      "training_iteration: 5\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 6000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 6000\n",
      "  num_agent_steps_sampled: 6000\n",
      "  num_agent_steps_trained: 188800\n",
      "  num_env_steps_sampled: 6000\n",
      "  num_env_steps_trained: 188800\n",
      "  num_target_updates: 12\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-06-25\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 6000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 2949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0012532639084383845\n",
      "        max_q: 0.05393753945827484\n",
      "        mean_q: 0.039046790450811386\n",
      "        min_q: 0.02915218286216259\n",
      "      mean_td_error: 0.0006890187505632639\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 2950.0\n",
      "      td_error: [0.004578232765197754, -0.0017623398452997208, -0.0013989359140396118,\n",
      "        0.0016484744846820831, 0.0030448399484157562, -0.005042180418968201, 0.005234694108366966,\n",
      "        0.0002894103527069092, 0.00095372274518013, 0.00182439386844635, 0.005175162106752396,\n",
      "        -0.00623316690325737, -0.006025910377502441, 0.004578232765197754, -0.0017623398452997208,\n",
      "        -0.0022449325770139694, 0.002708645537495613, -0.0017623398452997208, -0.0016483776271343231,\n",
      "        -0.002219889312982559, 0.0003246888518333435, 0.003972318023443222, -0.000868234783411026,\n",
      "        -0.0016483776271343231, -0.004463639110326767, 0.0033803321421146393, 0.001859515905380249,\n",
      "        0.004851184785366058, 0.005319744348526001, -0.0023081377148628235, 0.0029255561530590057,\n",
      "        -0.005157936364412308, 0.0006909668445587158, 0.0029255561530590057, -0.002219889312982559,\n",
      "        0.003972318023443222, 0.003580547869205475, -0.0017623398452997208, 0.0030612796545028687,\n",
      "        -0.0023785345256328583, 0.003972318023443222, 0.0029255561530590057, 0.0033803321421146393,\n",
      "        -0.0017623398452997208, 0.00182439386844635, -0.0006348118185997009, -0.002467237412929535,\n",
      "        0.0019390955567359924, -0.00623316690325737, 0.0002894103527069092, 0.0029255561530590057,\n",
      "        -0.01114293560385704, 0.003972318023443222, 0.003141898661851883, 0.0029255561530590057,\n",
      "        0.0006352663040161133, 0.003917040303349495, 0.003972318023443222, 0.0033803321421146393,\n",
      "        0.0033803321421146393, 0.0026371292769908905, 0.0033803321421146393, -0.0017623398452997208,\n",
      "        0.003508530557155609]\n",
      "  num_agent_steps_sampled: 6000\n",
      "  num_agent_steps_trained: 188800\n",
      "  num_env_steps_sampled: 6000\n",
      "  num_env_steps_trained: 188800\n",
      "  num_target_updates: 12\n",
      "iterations_since_restore: 6\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 6000\n",
      "num_agent_steps_trained: 188800\n",
      "num_env_steps_sampled: 6000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 12.158230715476831\n",
      "num_env_steps_trained: 188800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 389.0633828952586\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.34655172413793\n",
      "  ram_util_percent: 53.81810344827585\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 489.6232924461365\n",
      "time_this_iter_s: 82.26588797569275\n",
      "time_total_s: 489.6232924461365\n",
      "timers:\n",
      "  learn_throughput: 6128.495\n",
      "  learn_time_ms: 10.443\n",
      "  load_throughput: 555422.007\n",
      "  load_time_ms: 0.115\n",
      "  sample_time_ms: 138.3\n",
      "  synch_weights_time_ms: 3.052\n",
      "  training_iteration_time_ms: 161.586\n",
      "timestamp: 1709831185\n",
      "timesteps_total: 6000\n",
      "training_iteration: 6\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 7000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 7000\n",
      "  num_agent_steps_sampled: 7000\n",
      "  num_agent_steps_trained: 220800\n",
      "  num_env_steps_sampled: 7000\n",
      "  num_env_steps_trained: 220800\n",
      "  num_target_updates: 14\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-07-47\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 7000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 3449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0021850038319826126\n",
      "        max_q: 0.0613633468747139\n",
      "        mean_q: 0.04983144253492355\n",
      "        min_q: 0.037989530712366104\n",
      "      mean_td_error: -0.003007065039128065\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 3450.0\n",
      "      td_error: [0.0023378022015094757, -0.0021205395460128784, 0.0022382400929927826,\n",
      "        0.0029713548719882965, -0.009995292872190475, -0.0008642151951789856, -0.010430306196212769,\n",
      "        -0.0023904703557491302, 0.0015295334160327911, -0.004574041813611984, -0.005512960255146027,\n",
      "        -0.011315308511257172, -0.0018321312963962555, -0.0002572163939476013, -0.0016159936785697937,\n",
      "        -0.011864878237247467, 0.0004980005323886871, -0.006179772317409515, -0.0016159936785697937,\n",
      "        0.002704411745071411, 0.0015295334160327911, -0.002244800329208374, 0.0023378022015094757,\n",
      "        0.002704411745071411, -0.0017104148864746094, -0.0042435117065906525, -0.009404104202985764,\n",
      "        0.0030427314341068268, -0.002038281410932541, 0.002001240849494934, 0.002704411745071411,\n",
      "        -0.002802126109600067, -0.0034590624272823334, -0.010818332433700562, -0.009404104202985764,\n",
      "        -0.009385969489812851, 0.0023378022015094757, 0.0009024254977703094, 0.002704411745071411,\n",
      "        -0.004288509488105774, -0.011864878237247467, 0.0009027905762195587, -0.0008642151951789856,\n",
      "        -0.0002572163939476013, -0.009404104202985764, 0.0015295334160327911, -0.002802126109600067,\n",
      "        -0.0001019015908241272, -0.009995292872190475, -0.002538919448852539, -0.00314958393573761,\n",
      "        -0.011864878237247467, -0.0022622495889663696, -0.0002572163939476013, -0.009404104202985764,\n",
      "        0.0009027905762195587, -0.0001751333475112915, 0.0008240602910518646, -0.004288509488105774,\n",
      "        -0.004288509488105774, -0.013804219663143158, -0.0016159936785697937, -0.008015915751457214,\n",
      "        -0.0018321312963962555]\n",
      "  num_agent_steps_sampled: 7000\n",
      "  num_agent_steps_trained: 220800\n",
      "  num_env_steps_sampled: 7000\n",
      "  num_env_steps_trained: 220800\n",
      "  num_target_updates: 14\n",
      "iterations_since_restore: 7\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 7000\n",
      "num_agent_steps_trained: 220800\n",
      "num_env_steps_sampled: 7000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 12.135473008390756\n",
      "num_env_steps_trained: 220800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 388.3351362685042\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.345689655172412\n",
      "  ram_util_percent: 54.01206896551727\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 572.0430536270142\n",
      "time_this_iter_s: 82.41976118087769\n",
      "time_total_s: 572.0430536270142\n",
      "timers:\n",
      "  learn_throughput: 5934.465\n",
      "  learn_time_ms: 10.784\n",
      "  load_throughput: 711275.718\n",
      "  load_time_ms: 0.09\n",
      "  sample_time_ms: 142.196\n",
      "  synch_weights_time_ms: 3.157\n",
      "  training_iteration_time_ms: 166.874\n",
      "timestamp: 1709831267\n",
      "timesteps_total: 7000\n",
      "training_iteration: 7\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 178x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 205x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 77x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 8000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 8000\n",
      "  num_agent_steps_sampled: 8000\n",
      "  num_agent_steps_trained: 252800\n",
      "  num_env_steps_sampled: 8000\n",
      "  num_env_steps_trained: 252800\n",
      "  num_target_updates: 16\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-08-47\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 8000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 3949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0010558858048170805\n",
      "        max_q: 0.06756278872489929\n",
      "        mean_q: 0.05807064473628998\n",
      "        min_q: 0.04861956834793091\n",
      "      mean_td_error: 0.0007446873351000249\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 3950.0\n",
      "      td_error: [-0.0017291158437728882, 0.0046998560428619385, 0.0031712986528873444,\n",
      "        -0.002634745091199875, 0.0023687556385993958, 0.005250275135040283, -0.0008914880454540253,\n",
      "        -0.00401388481259346, -0.0035880133509635925, -0.0019955411553382874, -0.004324067384004593,\n",
      "        0.001807723194360733, 0.003216441720724106, -0.0014752410352230072, -0.0008914880454540253,\n",
      "        -0.0012783929705619812, 0.005256693810224533, -0.0019203834235668182, 0.005092356353998184,\n",
      "        0.0023687556385993958, 0.0023687556385993958, 0.0037324540317058563, -0.0019955411553382874,\n",
      "        0.005288530141115189, -0.003532964736223221, -0.00469791516661644, -0.0028422363102436066,\n",
      "        0.004143364727497101, 0.001807723194360733, 0.005762014538049698, -0.009920347481966019,\n",
      "        0.001917235553264618, 0.004143364727497101, 0.0021683908998966217, 0.0012986920773983002,\n",
      "        -0.0035880133509635925, 0.005250275135040283, 0.003216441720724106, 0.0023687556385993958,\n",
      "        0.005250275135040283, -0.001018024981021881, 0.005348529666662216, -0.0028422363102436066,\n",
      "        0.005762014538049698, 0.005256693810224533, -0.00023641809821128845, -0.002104293555021286,\n",
      "        -0.001513756811618805, 0.005288530141115189, -0.0025515928864479065, 0.001807723194360733,\n",
      "        -0.0019203834235668182, 0.0015401877462863922, 0.002440493553876877, -0.0017291158437728882,\n",
      "        -0.0028422363102436066, -0.0019203834235668182, -0.0019203834235668182, -0.0017291158437728882,\n",
      "        -0.00023641809821128845, 0.0021683908998966217, 0.004350438714027405, -0.0017291158437728882,\n",
      "        0.007361412048339844]\n",
      "  num_agent_steps_sampled: 8000\n",
      "  num_agent_steps_trained: 252800\n",
      "  num_env_steps_sampled: 8000\n",
      "  num_env_steps_trained: 252800\n",
      "  num_target_updates: 16\n",
      "iterations_since_restore: 8\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 8000\n",
      "num_agent_steps_trained: 252800\n",
      "num_env_steps_sampled: 8000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 16.776203858068836\n",
      "num_env_steps_trained: 252800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 536.8385234582028\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 13.585882352941178\n",
      "  ram_util_percent: 54.88823529411763\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 631.6687786579132\n",
      "time_this_iter_s: 59.62572503089905\n",
      "time_total_s: 631.6687786579132\n",
      "timers:\n",
      "  learn_throughput: 6010.538\n",
      "  learn_time_ms: 10.648\n",
      "  load_throughput: 688825.907\n",
      "  load_time_ms: 0.093\n",
      "  sample_time_ms: 140.545\n",
      "  synch_weights_time_ms: 3.053\n",
      "  training_iteration_time_ms: 164.255\n",
      "timestamp: 1709831327\n",
      "timesteps_total: 8000\n",
      "training_iteration: 8\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 111x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 186x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 198x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 9000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 9000\n",
      "  num_agent_steps_sampled: 9000\n",
      "  num_agent_steps_trained: 284800\n",
      "  num_env_steps_sampled: 9000\n",
      "  num_env_steps_trained: 284800\n",
      "  num_target_updates: 18\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-09-22\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 9000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 4449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0006392369978129864\n",
      "        max_q: 0.0719878301024437\n",
      "        mean_q: 0.06604407727718353\n",
      "        min_q: 0.06085672229528427\n",
      "      mean_td_error: -0.000928125053178519\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 4450.0\n",
      "      td_error: [0.001895718276500702, -0.0015619024634361267, -0.0017796754837036133,\n",
      "        -0.002901799976825714, -9.284168481826782e-05, 0.0011870115995407104, 0.001989789307117462,\n",
      "        -0.0019350871443748474, -0.0028647631406784058, 0.0011870115995407104, 0.0012996569275856018,\n",
      "        0.0007310956716537476, 0.0010073855519294739, -0.002901799976825714, 0.0014125928282737732,\n",
      "        -0.00234251469373703, -0.0037672072649002075, -0.0009229704737663269, -0.0017796754837036133,\n",
      "        0.002145737409591675, -0.0023116469383239746, 0.00261012464761734, 0.002145737409591675,\n",
      "        -0.0015619024634361267, -0.0007145926356315613, -0.0010912716388702393, 0.00017099082469940186,\n",
      "        -0.0023116469383239746, -0.0015619024634361267, -0.0015444755554199219, -0.0037050247192382812,\n",
      "        -0.0017796754837036133, 0.001895718276500702, -0.0005305483937263489, -0.0017778575420379639,\n",
      "        -0.0035759583115577698, 0.00261012464761734, 0.002046242356300354, -0.0015619024634361267,\n",
      "        0.002145737409591675, 0.0011870115995407104, -0.0010912716388702393, 0.0007310956716537476,\n",
      "        0.0012996569275856018, -0.00308912992477417, 0.0019150972366333008, -0.0020000115036964417,\n",
      "        -0.0017796754837036133, -0.0024595558643341064, -0.0029848702251911163, 0.0012996569275856018,\n",
      "        -0.0017796754837036133, -0.0028647631406784058, -0.0017796754837036133, -0.0037672072649002075,\n",
      "        -0.0037896521389484406, -0.0029848702251911163, -0.0035759583115577698, -0.0019350871443748474,\n",
      "        0.0011870115995407104, -0.0026163235306739807, -0.00234251469373703, -0.0030028000473976135,\n",
      "        -0.0027785226702690125]\n",
      "  num_agent_steps_sampled: 9000\n",
      "  num_agent_steps_trained: 284800\n",
      "  num_env_steps_sampled: 9000\n",
      "  num_env_steps_trained: 284800\n",
      "  num_target_updates: 18\n",
      "iterations_since_restore: 9\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 9000\n",
      "num_agent_steps_trained: 284800\n",
      "num_env_steps_sampled: 9000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 29.072024067063257\n",
      "num_env_steps_trained: 284800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 930.3047701460242\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 23.089795918367344\n",
      "  ram_util_percent: 57.68571428571428\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 666.084805727005\n",
      "time_this_iter_s: 34.4160270690918\n",
      "time_total_s: 666.084805727005\n",
      "timers:\n",
      "  learn_throughput: 6150.02\n",
      "  learn_time_ms: 10.406\n",
      "  load_throughput: 703816.088\n",
      "  load_time_ms: 0.091\n",
      "  sample_time_ms: 26.9\n",
      "  synch_weights_time_ms: 3.122\n",
      "  training_iteration_time_ms: 50.338\n",
      "timestamp: 1709831362\n",
      "timesteps_total: 9000\n",
      "training_iteration: 9\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 190x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 198x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 10000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 10000\n",
      "  num_agent_steps_sampled: 10000\n",
      "  num_agent_steps_trained: 316800\n",
      "  num_env_steps_sampled: 10000\n",
      "  num_env_steps_trained: 316800\n",
      "  num_target_updates: 20\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-09-47\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 10000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 4949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.001221142360009253\n",
      "        max_q: 0.09033042937517166\n",
      "        mean_q: 0.07698997855186462\n",
      "        min_q: 0.06793411076068878\n",
      "      mean_td_error: 0.0019270138582214713\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 4950.0\n",
      "      td_error: [0.001844756305217743, 0.0036146119236946106, 0.008196830749511719,\n",
      "        -0.010382749140262604, 0.0004151836037635803, 0.008498303592205048, 0.0014511048793792725,\n",
      "        -0.0021696090698242188, 0.0008123964071273804, 0.0036146119236946106, 0.008196830749511719,\n",
      "        -0.001582033932209015, 7.005780935287476e-05, -0.001582033932209015, 0.013110838830471039,\n",
      "        -0.0021696090698242188, -0.000605456531047821, 0.00035550445318222046, 0.008196830749511719,\n",
      "        -0.0004568621516227722, 0.008558295667171478, 0.013110838830471039, -0.0013997852802276611,\n",
      "        0.0034503787755966187, -0.000605456531047821, 0.006119348108768463, -0.004070952534675598,\n",
      "        0.004228658974170685, -0.004914872348308563, -0.0004568621516227722, 0.006105482578277588,\n",
      "        -0.0014100298285484314, 7.005780935287476e-05, 0.013110838830471039, 0.0024734213948249817,\n",
      "        0.00035550445318222046, -0.001582033932209015, 0.006770201027393341, -0.009524226188659668,\n",
      "        0.003245837986469269, -0.002215936779975891, 0.007825151085853577, -0.000605456531047821,\n",
      "        0.0009146556258201599, 0.0036146119236946106, -0.000605456531047821, -0.0036306679248809814,\n",
      "        0.00035550445318222046, 0.0036146119236946106, -0.0002197548747062683, 0.001580066978931427,\n",
      "        0.009298056364059448, -0.0036884695291519165, 0.0036146119236946106, -0.002920694649219513,\n",
      "        -0.0036884695291519165, 0.004904225468635559, 0.001844756305217743, 0.011032037436962128,\n",
      "        -0.005411043763160706, 0.005630426108837128, 0.008937358856201172, 0.0022542178630828857,\n",
      "        -0.0021696090698242188]\n",
      "  num_agent_steps_sampled: 10000\n",
      "  num_agent_steps_trained: 316800\n",
      "  num_env_steps_sampled: 10000\n",
      "  num_env_steps_trained: 316800\n",
      "  num_target_updates: 20\n",
      "iterations_since_restore: 10\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 10000\n",
      "num_agent_steps_trained: 316800\n",
      "num_env_steps_sampled: 10000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.19539096358286\n",
      "num_env_steps_trained: 316800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1254.2525108346515\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 26.930555555555557\n",
      "  ram_util_percent: 57.31388888888888\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 691.6162846088409\n",
      "time_this_iter_s: 25.531478881835938\n",
      "time_total_s: 691.6162846088409\n",
      "timers:\n",
      "  learn_throughput: 6080.45\n",
      "  learn_time_ms: 10.526\n",
      "  load_throughput: 627039.14\n",
      "  load_time_ms: 0.102\n",
      "  sample_time_ms: 28.262\n",
      "  synch_weights_time_ms: 3.124\n",
      "  training_iteration_time_ms: 51.894\n",
      "timestamp: 1709831387\n",
      "timesteps_total: 10000\n",
      "training_iteration: 10\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 204x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 184x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 198x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 11000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 11000\n",
      "  num_agent_steps_sampled: 11000\n",
      "  num_agent_steps_trained: 348800\n",
      "  num_env_steps_sampled: 11000\n",
      "  num_env_steps_trained: 348800\n",
      "  num_target_updates: 22\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-10-13\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 11000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 5449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0005365107208490372\n",
      "        max_q: 0.10106272250413895\n",
      "        mean_q: 0.0894182026386261\n",
      "        min_q: 0.08123868703842163\n",
      "      mean_td_error: -0.00041449733544141054\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 5450.0\n",
      "      td_error: [-0.002757146954536438, -0.0006203204393386841, -0.0015407651662826538,\n",
      "        -0.0029225125908851624, 0.0024518072605133057, -0.0006824508309364319, -0.0012985393404960632,\n",
      "        -0.0017485842108726501, 0.0030934885144233704, -0.00024984776973724365, 0.003432832658290863,\n",
      "        -0.0006203204393386841, -0.0008787810802459717, -0.0006824508309364319, -0.004990935325622559,\n",
      "        -0.0006203204393386841, -0.003392748534679413, -0.0017485842108726501, 0.00016590207815170288,\n",
      "        0.002782680094242096, -0.005180053412914276, -0.0006824508309364319, 0.002782680094242096,\n",
      "        -0.0008787810802459717, 0.0003475174307823181, 0.00016590207815170288, -0.0030365660786628723,\n",
      "        -0.0006203204393386841, -0.0006972402334213257, 0.002640672028064728, 0.00016590207815170288,\n",
      "        -0.0004378184676170349, -0.0006203204393386841, -0.00011351704597473145, 0.0013186633586883545,\n",
      "        0.005406737327575684, 0.0013186633586883545, 0.004644185304641724, -0.0005743801593780518,\n",
      "        0.0003475174307823181, -0.00024984776973724365, 0.0024518072605133057, 0.005406737327575684,\n",
      "        -0.0015407651662826538, -0.0044071972370147705, 0.001580066978931427, -0.003392748534679413,\n",
      "        -0.005762368440628052, 0.00016590207815170288, 0.0028649121522903442, -0.011657461524009705,\n",
      "        -0.00024984776973724365, 0.0028649121522903442, -0.00623176246881485, -0.0017485842108726501,\n",
      "        -0.0030365660786628723, 0.002782680094242096, -0.002757146954536438, 0.0030934885144233704,\n",
      "        0.004644185304641724, -0.0005993619561195374, -0.0005993619561195374, -0.006304509937763214,\n",
      "        0.0026856139302253723]\n",
      "  num_agent_steps_sampled: 11000\n",
      "  num_agent_steps_trained: 348800\n",
      "  num_env_steps_sampled: 11000\n",
      "  num_env_steps_trained: 348800\n",
      "  num_target_updates: 22\n",
      "iterations_since_restore: 11\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 11000\n",
      "num_agent_steps_trained: 348800\n",
      "num_env_steps_sampled: 11000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.0637938536374\n",
      "num_env_steps_trained: 348800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1250.0414033163968\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 27.372222222222224\n",
      "  ram_util_percent: 57.70277777777778\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 717.2331826686859\n",
      "time_this_iter_s: 25.61689805984497\n",
      "time_total_s: 717.2331826686859\n",
      "timers:\n",
      "  learn_throughput: 6119.219\n",
      "  learn_time_ms: 10.459\n",
      "  load_throughput: 600526.747\n",
      "  load_time_ms: 0.107\n",
      "  sample_time_ms: 27.635\n",
      "  synch_weights_time_ms: 3.096\n",
      "  training_iteration_time_ms: 50.999\n",
      "timestamp: 1709831413\n",
      "timesteps_total: 11000\n",
      "training_iteration: 11\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 186x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 12000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 12000\n",
      "  num_agent_steps_sampled: 12000\n",
      "  num_agent_steps_trained: 380800\n",
      "  num_env_steps_sampled: 12000\n",
      "  num_env_steps_trained: 380800\n",
      "  num_target_updates: 24\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-10-38\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 12000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 5949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.00036074972013011575\n",
      "        max_q: 0.10761123895645142\n",
      "        mean_q: 0.09798363596200943\n",
      "        min_q: 0.09151512384414673\n",
      "      mean_td_error: -0.0005315827438607812\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 5950.0\n",
      "      td_error: [-0.001955568790435791, 0.0012625902891159058, -0.0015981495380401611,\n",
      "        0.0008224770426750183, -0.0007394477725028992, 0.0008224770426750183, -0.004869714379310608,\n",
      "        0.0012815743684768677, -0.0015981495380401611, -0.0001803189516067505, -0.0001803189516067505,\n",
      "        0.0018259286880493164, -0.004566200077533722, -0.0012233704328536987, 0.0031708702445030212,\n",
      "        -0.0005044862627983093, 0.0010177642107009888, 0.0013634786009788513, -0.0001803189516067505,\n",
      "        -0.0010462477803230286, 0.0001332014799118042, -0.0019844621419906616, -0.002424672245979309,\n",
      "        -0.0017275884747505188, -0.0017275884747505188, -0.0008249804377555847, 0.0008224770426750183,\n",
      "        0.0013634786009788513, 0.0005843043327331543, 0.0018259286880493164, -0.0029760748147964478,\n",
      "        -0.0023380741477012634, -0.0015981495380401611, 0.003076605498790741, 0.0005843043327331543,\n",
      "        0.0006122291088104248, 0.001871354877948761, 0.0012625902891159058, -0.0008249804377555847,\n",
      "        0.0018259286880493164, 0.0012625902891159058, -0.0016158968210220337, -0.0010462477803230286,\n",
      "        -0.0023380741477012634, -0.0015979409217834473, -0.0017275884747505188, -0.0013471171259880066,\n",
      "        -0.0010462477803230286, -0.0018707066774368286, -0.0022526830434799194, 0.00012411177158355713,\n",
      "        0.002461642026901245, -0.000298231840133667, -0.0015981495380401611, -0.0017275884747505188,\n",
      "        -0.0017275884747505188, -0.0029760748147964478, -0.0015981495380401611, 0.0010177642107009888,\n",
      "        0.001871354877948761, -0.0019844621419906616, 0.0012625902891159058, -0.0001803189516067505,\n",
      "        -0.005548983812332153]\n",
      "  num_agent_steps_sampled: 12000\n",
      "  num_agent_steps_trained: 380800\n",
      "  num_env_steps_sampled: 12000\n",
      "  num_env_steps_trained: 380800\n",
      "  num_target_updates: 24\n",
      "iterations_since_restore: 12\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 12000\n",
      "num_agent_steps_trained: 380800\n",
      "num_env_steps_sampled: 12000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.01948190646869\n",
      "num_env_steps_trained: 380800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1248.6234210069981\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 26.972972972972972\n",
      "  ram_util_percent: 57.84324324324325\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 742.8808145523071\n",
      "time_this_iter_s: 25.647631883621216\n",
      "time_total_s: 742.8808145523071\n",
      "timers:\n",
      "  learn_throughput: 6032.271\n",
      "  learn_time_ms: 10.61\n",
      "  load_throughput: 678895.943\n",
      "  load_time_ms: 0.094\n",
      "  sample_time_ms: 26.958\n",
      "  synch_weights_time_ms: 3.112\n",
      "  training_iteration_time_ms: 50.524\n",
      "timestamp: 1709831438\n",
      "timesteps_total: 12000\n",
      "training_iteration: 12\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 198x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 204x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 13000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 13000\n",
      "  num_agent_steps_sampled: 13000\n",
      "  num_agent_steps_trained: 412800\n",
      "  num_env_steps_sampled: 13000\n",
      "  num_env_steps_trained: 412800\n",
      "  num_target_updates: 26\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-11-04\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 13000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 6449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0006057802820578218\n",
      "        max_q: 0.10985063761472702\n",
      "        mean_q: 0.0987543985247612\n",
      "        min_q: 0.08998039364814758\n",
      "      mean_td_error: -0.00200487207621336\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 6450.0\n",
      "      td_error: [-0.0033916085958480835, -0.0034411102533340454, 0.00242508202791214,\n",
      "        -0.0007327273488044739, -0.002276219427585602, -0.0037822723388671875, -0.0027988478541374207,\n",
      "        -0.0045959725975990295, -0.0032822415232658386, 0.0020412951707839966, 0.0020412951707839966,\n",
      "        -0.0007327273488044739, -0.00021192431449890137, -0.0003626421093940735, -0.005047403275966644,\n",
      "        -0.003535240888595581, -0.001596212387084961, -0.0045959725975990295, -0.0038723498582839966,\n",
      "        -0.001566462218761444, 0.0013071224093437195, -0.001596212387084961, -0.0015125647187232971,\n",
      "        -0.006331786513328552, -0.0034411102533340454, -0.0045959725975990295, -0.0032822415232658386,\n",
      "        -0.001566462218761444, 0.00242508202791214, -0.005858726799488068, -0.004420652985572815,\n",
      "        0.00242508202791214, 0.0013071224093437195, -0.0022811442613601685, 0.0020412951707839966,\n",
      "        -0.004091776907444, -0.001596212387084961, -0.0032822415232658386, -0.0033916085958480835,\n",
      "        -0.0008655861020088196, -0.002230830490589142, -0.0022811442613601685, 0.0013071224093437195,\n",
      "        4.314631223678589e-05, -0.0033916085958480835, -0.006077602505683899, -0.0033916085958480835,\n",
      "        -0.0045959725975990295, 0.0023489296436309814, -0.007952369749546051, 0.0013071224093437195,\n",
      "        -0.0022984296083450317, -0.00012534856796264648, -0.0003626421093940735, 0.0020412951707839966,\n",
      "        -0.0027355626225471497, -0.0038723498582839966, -0.002230830490589142, 0.0016386434435844421,\n",
      "        -0.0038723498582839966, -0.005047403275966644, -0.0032822415232658386, -0.0030960813164711,\n",
      "        -0.002230830490589142]\n",
      "  num_agent_steps_sampled: 13000\n",
      "  num_agent_steps_trained: 412800\n",
      "  num_env_steps_sampled: 13000\n",
      "  num_env_steps_trained: 412800\n",
      "  num_target_updates: 26\n",
      "iterations_since_restore: 13\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 13000\n",
      "num_agent_steps_trained: 412800\n",
      "num_env_steps_sampled: 13000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.66685547566215\n",
      "num_env_steps_trained: 412800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1269.339375221189\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 26.069444444444443\n",
      "  ram_util_percent: 57.98055555555556\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 768.1095857620239\n",
      "time_this_iter_s: 25.228771209716797\n",
      "time_total_s: 768.1095857620239\n",
      "timers:\n",
      "  learn_throughput: 6051.077\n",
      "  learn_time_ms: 10.577\n",
      "  load_throughput: 474602.999\n",
      "  load_time_ms: 0.135\n",
      "  sample_time_ms: 27.59\n",
      "  synch_weights_time_ms: 3.18\n",
      "  training_iteration_time_ms: 51.39\n",
      "timestamp: 1709831464\n",
      "timesteps_total: 13000\n",
      "training_iteration: 13\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 188x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 195x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 201x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 14000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 14000\n",
      "  num_agent_steps_sampled: 14000\n",
      "  num_agent_steps_trained: 444800\n",
      "  num_env_steps_sampled: 14000\n",
      "  num_env_steps_trained: 444800\n",
      "  num_target_updates: 28\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-11-29\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 14000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 6949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0006808238686062396\n",
      "        max_q: 0.11101385951042175\n",
      "        mean_q: 0.10145027190446854\n",
      "        min_q: 0.09170187264680862\n",
      "      mean_td_error: 0.00033679092302918434\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 6950.0\n",
      "      td_error: [0.0050940439105033875, -0.0036579295992851257, -0.0029296502470970154,\n",
      "        0.0021821334958076477, 0.0019207671284675598, -0.003882795572280884, -0.0009204819798469543,\n",
      "        -0.0016398057341575623, 0.002735316753387451, -0.003465712070465088, -5.704164505004883e-05,\n",
      "        0.0019410774111747742, 0.000587165355682373, -0.00416218489408493, 0.004503712058067322,\n",
      "        -0.002131834626197815, 0.0015695765614509583, -0.0009204819798469543, 0.0050940439105033875,\n",
      "        0.0027122944593429565, -0.003037460148334503, -0.0028636902570724487, 0.0042665451765060425,\n",
      "        -0.0034964382648468018, 0.004170730710029602, -0.003037460148334503, 0.0042665451765060425,\n",
      "        0.0026348531246185303, -0.003037460148334503, -0.008119411766529083, 0.0019410774111747742,\n",
      "        0.0026348531246185303, 0.0030662938952445984, -0.0026274695992469788, 0.0050940439105033875,\n",
      "        -0.003882795572280884, -0.0021207034587860107, -0.00416218489408493, 0.0050940439105033875,\n",
      "        0.004503712058067322, -0.0026274695992469788, -8.6955726146698e-05, 0.0027122944593429565,\n",
      "        -0.0021794289350509644, 0.0008444637060165405, 0.006684035062789917, -0.0028636902570724487,\n",
      "        0.0027122944593429565, 0.0025807395577430725, -0.003882795572280884, 0.0027122944593429565,\n",
      "        -8.6955726146698e-05, 0.003211274743080139, 0.0019207671284675598, -0.0036040320992469788,\n",
      "        0.0042665451765060425, -0.002131834626197815, 0.0026348531246185303, -5.704164505004883e-05,\n",
      "        -0.0034964382648468018, -0.0026274695992469788, 0.004503712058067322, 0.0026348531246185303,\n",
      "        0.0019207671284675598]\n",
      "  num_agent_steps_sampled: 14000\n",
      "  num_agent_steps_trained: 444800\n",
      "  num_env_steps_sampled: 14000\n",
      "  num_env_steps_trained: 444800\n",
      "  num_target_updates: 28\n",
      "iterations_since_restore: 14\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 14000\n",
      "num_agent_steps_trained: 444800\n",
      "num_env_steps_sampled: 14000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 38.827112216310695\n",
      "num_env_steps_trained: 444800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1242.4675909219422\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 27.616666666666664\n",
      "  ram_util_percent: 58.66111111111112\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 793.8827698230743\n",
      "time_this_iter_s: 25.773184061050415\n",
      "time_total_s: 793.8827698230743\n",
      "timers:\n",
      "  learn_throughput: 6107.399\n",
      "  learn_time_ms: 10.479\n",
      "  load_throughput: 510333.567\n",
      "  load_time_ms: 0.125\n",
      "  sample_time_ms: 28.316\n",
      "  synch_weights_time_ms: 3.077\n",
      "  training_iteration_time_ms: 51.769\n",
      "timestamp: 1709831489\n",
      "timesteps_total: 14000\n",
      "training_iteration: 14\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 108x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 142x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 15000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 15000\n",
      "  num_agent_steps_sampled: 15000\n",
      "  num_agent_steps_trained: 476800\n",
      "  num_env_steps_sampled: 15000\n",
      "  num_env_steps_trained: 476800\n",
      "  num_target_updates: 30\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-12-06\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 15000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 7449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0007320992881432176\n",
      "        max_q: 0.11506198346614838\n",
      "        mean_q: 0.10740221291780472\n",
      "        min_q: 0.09793675690889359\n",
      "      mean_td_error: -0.0016676102532073855\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 7450.0\n",
      "      td_error: [0.00136585533618927, 0.0022889748215675354, 0.001866370439529419,\n",
      "        -0.005570404231548309, -0.005570404231548309, -0.002495609223842621, 0.0021200031042099,\n",
      "        -0.002486705780029297, -0.009178504347801208, 0.0022889748215675354, 0.0022456422448158264,\n",
      "        -0.0006305277347564697, 0.0012765079736709595, -0.005570404231548309, -0.003551982343196869,\n",
      "        -0.004156820476055145, -0.000727631151676178, -0.0016009360551834106, -0.004156820476055145,\n",
      "        -7.528066635131836e-05, -0.004156820476055145, -0.0009500607848167419, -0.0016009360551834106,\n",
      "        0.0007879361510276794, -0.0016009360551834106, -0.004156820476055145, -0.009178504347801208,\n",
      "        0.0007379874587059021, 0.001866370439529419, 0.0023591965436935425, -0.0016009360551834106,\n",
      "        0.003476440906524658, -0.009178504347801208, -0.008157752454280853, 0.0019963011145591736,\n",
      "        -0.009644165635108948, 0.0004009529948234558, 0.001909114420413971, -0.0008806660771369934,\n",
      "        -0.003013722598552704, -0.004675731062889099, 0.0021200031042099, 0.0024447813630104065,\n",
      "        -0.0023828893899917603, -0.0006305277347564697, 0.0022456422448158264, -0.004156820476055145,\n",
      "        0.001866370439529419, -0.002495609223842621, -0.0016009360551834106, -0.0011629685759544373,\n",
      "        -0.00713232159614563, -0.0008806660771369934, -0.009178504347801208, 0.003885917365550995,\n",
      "        -0.001691192388534546, -0.00107613205909729, -0.00107613205909729, 0.0007379874587059021,\n",
      "        -0.009178504347801208, -0.004942640662193298, 0.0024447813630104065, 0.0019063279032707214,\n",
      "        0.0007879361510276794]\n",
      "  num_agent_steps_sampled: 15000\n",
      "  num_agent_steps_trained: 476800\n",
      "  num_env_steps_sampled: 15000\n",
      "  num_env_steps_trained: 476800\n",
      "  num_target_updates: 30\n",
      "iterations_since_restore: 15\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 15000\n",
      "num_agent_steps_trained: 476800\n",
      "num_env_steps_sampled: 15000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 27.512834702518045\n",
      "num_env_steps_trained: 476800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 880.4107104805774\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.053846153846152\n",
      "  ram_util_percent: 57.925\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 830.2496340274811\n",
      "time_this_iter_s: 36.36686420440674\n",
      "time_total_s: 830.2496340274811\n",
      "timers:\n",
      "  learn_throughput: 6425.113\n",
      "  learn_time_ms: 9.961\n",
      "  load_throughput: 548835.526\n",
      "  load_time_ms: 0.117\n",
      "  sample_time_ms: 28.497\n",
      "  synch_weights_time_ms: 3.108\n",
      "  training_iteration_time_ms: 51.555\n",
      "timestamp: 1709831526\n",
      "timesteps_total: 15000\n",
      "training_iteration: 15\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 192x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 111x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 137x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 199x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 16000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 16000\n",
      "  num_agent_steps_sampled: 16000\n",
      "  num_agent_steps_trained: 508800\n",
      "  num_env_steps_sampled: 16000\n",
      "  num_env_steps_trained: 508800\n",
      "  num_target_updates: 32\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-12-46\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 16000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 7949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.06689140200614929\n",
      "        max_q: 0.23648667335510254\n",
      "        mean_q: 0.10425157845020294\n",
      "        min_q: -0.0314970500767231\n",
      "      mean_td_error: -0.00993374828249216\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 7950.0\n",
      "      td_error: [-0.13081611692905426, -0.030243799090385437, -0.005372881889343262,\n",
      "        0.11133071780204773, 0.007951825857162476, -0.13081611692905426, -0.005372881889343262,\n",
      "        -0.10759168863296509, -0.025525689125061035, -0.019111156463623047, -0.0034067630767822266,\n",
      "        -0.02211354672908783, 0.11133071780204773, 0.01059713214635849, 0.007951825857162476,\n",
      "        0.055519357323646545, 0.007951825857162476, 0.06478116661310196, -0.10759168863296509,\n",
      "        -0.10566126555204391, -0.10759168863296509, -0.10759168863296509, -0.13081611692905426,\n",
      "        0.0018283575773239136, -0.10759168863296509, -0.13081611692905426, -0.005372881889343262,\n",
      "        0.007951825857162476, 0.08569054305553436, 0.0018283575773239136, -0.030243799090385437,\n",
      "        -0.1458098143339157, 0.06807621568441391, 0.06412148475646973, 0.01059713214635849,\n",
      "        0.11929326504468918, 0.01059713214635849, -0.008225798606872559, -0.004778370261192322,\n",
      "        0.11133071780204773, -0.10759168863296509, 0.11133071780204773, 0.0018283575773239136,\n",
      "        0.007951825857162476, 0.06388833373785019, -0.10759168863296509, 0.01059713214635849,\n",
      "        0.11133071780204773, -0.10759168863296509, 0.06807621568441391, -0.003013007342815399,\n",
      "        0.007951825857162476, -0.030243799090385437, -0.005372881889343262, 0.0018283575773239136,\n",
      "        -0.030243799090385437, 0.05559056997299194, -0.004778370261192322, -0.030020006000995636,\n",
      "        -0.019111156463623047, -0.005372881889343262, 0.01059713214635849, 0.007951825857162476,\n",
      "        -0.030020006000995636]\n",
      "  num_agent_steps_sampled: 16000\n",
      "  num_agent_steps_trained: 508800\n",
      "  num_env_steps_sampled: 16000\n",
      "  num_env_steps_trained: 508800\n",
      "  num_target_updates: 32\n",
      "iterations_since_restore: 16\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 16000\n",
      "num_agent_steps_trained: 508800\n",
      "num_env_steps_sampled: 16000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 25.16342200038953\n",
      "num_env_steps_trained: 508800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 805.229504012465\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 19.355357142857144\n",
      "  ram_util_percent: 58.433928571428574\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 870.0085821151733\n",
      "time_this_iter_s: 39.75894808769226\n",
      "time_total_s: 870.0085821151733\n",
      "timers:\n",
      "  learn_throughput: 6594.834\n",
      "  learn_time_ms: 9.705\n",
      "  load_throughput: 734232.648\n",
      "  load_time_ms: 0.087\n",
      "  sample_time_ms: 28.05\n",
      "  synch_weights_time_ms: 2.98\n",
      "  training_iteration_time_ms: 50.361\n",
      "timestamp: 1709831566\n",
      "timesteps_total: 16000\n",
      "training_iteration: 16\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 198x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 162x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 17000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 17000\n",
      "  num_agent_steps_sampled: 17000\n",
      "  num_agent_steps_trained: 540800\n",
      "  num_env_steps_sampled: 17000\n",
      "  num_env_steps_trained: 540800\n",
      "  num_target_updates: 34\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-13-30\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 17000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 8449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0009793872013688087\n",
      "        max_q: 0.2489374577999115\n",
      "        mean_q: 0.23694998025894165\n",
      "        min_q: 0.1845039576292038\n",
      "      mean_td_error: -0.0011484138667583466\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 8450.0\n",
      "      td_error: [-0.0005604773759841919, -0.0002654939889907837, -0.00012388825416564941,\n",
      "        0.006027087569236755, -0.001700282096862793, -0.0002654939889907837, -0.031077712774276733,\n",
      "        -0.0004919171333312988, -0.001700282096862793, -0.0030187666416168213, 0.001216396689414978,\n",
      "        -0.0024955421686172485, -0.0026528537273406982, -0.0002654939889907837, 0.002264469861984253,\n",
      "        -0.0006299465894699097, -0.0021791011095046997, 0.018062591552734375, -0.0028467029333114624,\n",
      "        0.0011749267578125, 0.007537931203842163, 0.002179965376853943, -0.0005604773759841919,\n",
      "        -0.0017026662826538086, 0.0006286501884460449, 0.002179965376853943, -0.0002654939889907837,\n",
      "        -0.005893886089324951, -0.0002654939889907837, -0.0006299465894699097, -0.0004092752933502197,\n",
      "        -0.0004092752933502197, 0.002264469861984253, -0.0024955421686172485, -0.0024955421686172485,\n",
      "        -0.0002654939889907837, -0.0021791011095046997, 0.0002454519271850586, -0.0006299465894699097,\n",
      "        0.002264469861984253, -0.001700282096862793, -0.005893886089324951, -0.013678207993507385,\n",
      "        -0.0021791011095046997, 0.001216396689414978, -0.0004919171333312988, -0.0017026662826538086,\n",
      "        -0.0004919171333312988, -0.0017026662826538086, 0.002264469861984253, -0.005200430750846863,\n",
      "        -0.0004919171333312988, -0.0021791011095046997, -0.0004092752933502197, -0.01750078797340393,\n",
      "        -0.001700282096862793, -0.0004092752933502197, -0.0004092752933502197, -0.0017026662826538086,\n",
      "        0.0022879838943481445, 0.0011749267578125, -0.0002654939889907837, -0.00043170154094696045,\n",
      "        0.0005283057689666748]\n",
      "  num_agent_steps_sampled: 17000\n",
      "  num_agent_steps_trained: 540800\n",
      "  num_env_steps_sampled: 17000\n",
      "  num_env_steps_trained: 540800\n",
      "  num_target_updates: 34\n",
      "iterations_since_restore: 17\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 17000\n",
      "num_agent_steps_trained: 540800\n",
      "num_env_steps_sampled: 17000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 22.486557187265756\n",
      "num_env_steps_trained: 540800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 719.5698299925042\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 17.3546875\n",
      "  ram_util_percent: 58.5109375\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 914.4971721172333\n",
      "time_this_iter_s: 44.48859000205994\n",
      "time_total_s: 914.4971721172333\n",
      "timers:\n",
      "  learn_throughput: 6263.003\n",
      "  learn_time_ms: 10.219\n",
      "  load_throughput: 623398.644\n",
      "  load_time_ms: 0.103\n",
      "  sample_time_ms: 144.852\n",
      "  synch_weights_time_ms: 3.029\n",
      "  training_iteration_time_ms: 168.26\n",
      "timestamp: 1709831610\n",
      "timesteps_total: 17000\n",
      "training_iteration: 17\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 18000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 18000\n",
      "  num_agent_steps_sampled: 18000\n",
      "  num_agent_steps_trained: 572800\n",
      "  num_env_steps_sampled: 18000\n",
      "  num_env_steps_trained: 572800\n",
      "  num_target_updates: 36\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-14-54\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 18000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 8949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0018790827598422766\n",
      "        max_q: 0.24964433908462524\n",
      "        mean_q: 0.2386985421180725\n",
      "        min_q: 0.22342664003372192\n",
      "      mean_td_error: -0.00028711557388305664\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 8950.0\n",
      "      td_error: [0.005657851696014404, -0.0007708519697189331, -0.0030148178339004517,\n",
      "        -0.0030148178339004517, -0.0015164464712142944, -0.003869280219078064, 0.0008336901664733887,\n",
      "        -0.00048013031482696533, 0.004935085773468018, -0.0030148178339004517, -0.00389784574508667,\n",
      "        -0.003688901662826538, -0.0024093538522720337, 0.004935085773468018, 6.48796558380127e-05,\n",
      "        -0.0032410770654678345, 0.0006167292594909668, -0.0016791224479675293, -0.003688901662826538,\n",
      "        -0.003688901662826538, 0.0008087158203125, 0.0006167292594909668, 0.0018682479858398438,\n",
      "        -0.00042504072189331055, -0.0030148178339004517, 0.0020262449979782104, 0.0018682479858398438,\n",
      "        0.002638772130012512, 0.0008336901664733887, -0.0017724335193634033, 0.005657851696014404,\n",
      "        -0.0004872828722000122, -0.0029378682374954224, 0.0006167292594909668, -0.0003344416618347168,\n",
      "        0.004935085773468018, 0.0018682479858398438, -0.010089054703712463, -0.0032410770654678345,\n",
      "        -0.00048013031482696533, -0.0032410770654678345, -0.0030148178339004517, -0.0007708519697189331,\n",
      "        0.0008087158203125, -0.0032410770654678345, -0.0032410770654678345, 0.0018682479858398438,\n",
      "        -0.0003344416618347168, -0.0004872828722000122, -0.00048013031482696533, -0.0004872828722000122,\n",
      "        0.0013589709997177124, 0.004757419228553772, -0.0017724335193634033, 0.0008336901664733887,\n",
      "        0.0045635998249053955, 0.0018682479858398438, 0.004757419228553772, 0.004935085773468018,\n",
      "        -0.0030148178339004517, -0.0016791224479675293, -0.0016791224479675293, -0.0015164464712142944,\n",
      "        0.0008087158203125]\n",
      "  num_agent_steps_sampled: 18000\n",
      "  num_agent_steps_trained: 572800\n",
      "  num_env_steps_sampled: 18000\n",
      "  num_env_steps_trained: 572800\n",
      "  num_target_updates: 36\n",
      "iterations_since_restore: 18\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 18000\n",
      "num_agent_steps_trained: 572800\n",
      "num_env_steps_sampled: 18000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.931709970120572\n",
      "num_env_steps_trained: 572800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 381.8147190438583\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.36638655462185\n",
      "  ram_util_percent: 58.610924369747906\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 998.3239152431488\n",
      "time_this_iter_s: 83.82674312591553\n",
      "time_total_s: 998.3239152431488\n",
      "timers:\n",
      "  learn_throughput: 6280.823\n",
      "  learn_time_ms: 10.19\n",
      "  load_throughput: 737055.069\n",
      "  load_time_ms: 0.087\n",
      "  sample_time_ms: 143.746\n",
      "  synch_weights_time_ms: 3.037\n",
      "  training_iteration_time_ms: 167.412\n",
      "timestamp: 1709831694\n",
      "timesteps_total: 18000\n",
      "training_iteration: 18\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 19000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 19000\n",
      "  num_agent_steps_sampled: 19000\n",
      "  num_agent_steps_trained: 604800\n",
      "  num_env_steps_sampled: 19000\n",
      "  num_env_steps_trained: 604800\n",
      "  num_target_updates: 38\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-16-18\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 19000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 9449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.004133335314691067\n",
      "        max_q: 0.2608600854873657\n",
      "        mean_q: 0.24475015699863434\n",
      "        min_q: 0.22593343257904053\n",
      "      mean_td_error: 0.0016192956827580929\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 9450.0\n",
      "      td_error: [0.009533613920211792, 0.0013894736766815186, 0.009533613920211792,\n",
      "        0.0013894736766815186, 0.00022241473197937012, 0.00022241473197937012, 0.0004960596561431885,\n",
      "        -0.006742894649505615, 0.008067429065704346, 0.001420140266418457, 0.008811727166175842,\n",
      "        -0.005807772278785706, 0.008067429065704346, 0.00022241473197937012, -0.006742894649505615,\n",
      "        0.010119259357452393, 0.010272741317749023, -0.004865735769271851, 0.0029812753200531006,\n",
      "        -0.00517621636390686, -0.005807772278785706, -0.0011894404888153076, 0.006314754486083984,\n",
      "        -0.004818141460418701, 0.006314754486083984, 0.00022241473197937012, 0.0013894736766815186,\n",
      "        0.009533613920211792, 0.0013894736766815186, 0.006464332342147827, 0.001420140266418457,\n",
      "        0.008811727166175842, 0.001420140266418457, 0.002792343497276306, -0.0019297003746032715,\n",
      "        0.009533613920211792, -0.004865735769271851, 0.010119259357452393, 0.008811727166175842,\n",
      "        -0.004885181784629822, 0.002543136477470398, 0.002604156732559204, -0.004818141460418701,\n",
      "        0.007099330425262451, 0.007099330425262451, 0.007099330425262451, 0.00939151644706726,\n",
      "        -0.0022675395011901855, 0.006314754486083984, -0.004865735769271851, 0.001420140266418457,\n",
      "        -0.0022675395011901855, -0.0019297003746032715, -0.0032328367233276367, -0.0022675395011901855,\n",
      "        -0.004818141460418701, -0.004865735769271851, -0.0012815892696380615, -0.004865735769271851,\n",
      "        0.006464332342147827, 0.006314754486083984, -0.004472851753234863, 0.007099330425262451,\n",
      "        -0.012317866086959839]\n",
      "  num_agent_steps_sampled: 19000\n",
      "  num_agent_steps_trained: 604800\n",
      "  num_env_steps_sampled: 19000\n",
      "  num_env_steps_trained: 604800\n",
      "  num_target_updates: 38\n",
      "iterations_since_restore: 19\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 19000\n",
      "num_agent_steps_trained: 604800\n",
      "num_env_steps_sampled: 19000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.891673830072824\n",
      "num_env_steps_trained: 604800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 380.53356256233036\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.386554621848738\n",
      "  ram_util_percent: 58.85042016806724\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1082.4365260601044\n",
      "time_this_iter_s: 84.11261081695557\n",
      "time_total_s: 1082.4365260601044\n",
      "timers:\n",
      "  learn_throughput: 5889.674\n",
      "  learn_time_ms: 10.866\n",
      "  load_throughput: 505813.936\n",
      "  load_time_ms: 0.127\n",
      "  sample_time_ms: 144.58\n",
      "  synch_weights_time_ms: 3.657\n",
      "  training_iteration_time_ms: 170.747\n",
      "timestamp: 1709831778\n",
      "timesteps_total: 19000\n",
      "training_iteration: 19\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 20000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 20000\n",
      "  num_agent_steps_sampled: 20000\n",
      "  num_agent_steps_trained: 636800\n",
      "  num_env_steps_sampled: 20000\n",
      "  num_env_steps_trained: 636800\n",
      "  num_target_updates: 40\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-17-42\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 20000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 9949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.001652173581533134\n",
      "        max_q: 0.2759411931037903\n",
      "        mean_q: 0.26429998874664307\n",
      "        min_q: 0.24917438626289368\n",
      "      mean_td_error: -7.366714999079704e-05\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 9950.0\n",
      "      td_error: [0.00011813640594482422, -0.0019249022006988525, -0.003301680088043213,\n",
      "        0.0005992650985717773, 0.002578526735305786, 0.002578526735305786, -0.0035628080368041992,\n",
      "        0.003540545701980591, 0.002578526735305786, -0.00043529272079467773, -0.0035628080368041992,\n",
      "        0.0009267926216125488, 0.00011813640594482422, 0.014435887336730957, -0.002563655376434326,\n",
      "        -0.0008448660373687744, 0.0033597946166992188, 0.002578526735305786, 0.0009267926216125488,\n",
      "        -0.003244370222091675, -0.002821892499923706, 0.0009267926216125488, -0.002821892499923706,\n",
      "        -0.00043389201164245605, 0.0033597946166992188, 0.002578526735305786, 0.0009267926216125488,\n",
      "        0.002578526735305786, 0.0009267926216125488, -0.0035628080368041992, -0.002413034439086914,\n",
      "        0.003050297498703003, -0.0005346238613128662, 0.0032348930835723877, -0.0019249022006988525,\n",
      "        0.0009267926216125488, 0.0033393800258636475, 0.00011813640594482422, -0.002413034439086914,\n",
      "        -0.0010666251182556152, 0.007910460233688354, 0.0009267926216125488, -0.00043389201164245605,\n",
      "        -0.0008448660373687744, -0.0035628080368041992, -0.002413034439086914, -0.002821892499923706,\n",
      "        0.007324159145355225, 0.002578526735305786, -0.010892599821090698, -0.0010666251182556152,\n",
      "        0.002578526735305786, -0.0035628080368041992, -0.002821892499923706, 6.401538848876953e-05,\n",
      "        -0.0018381476402282715, -0.0019249022006988525, -0.002413034439086914, -0.0035628080368041992,\n",
      "        -0.002821892499923706, -0.0019249022006988525, -0.0019489824771881104, 0.0009267926216125488,\n",
      "        -0.0010419785976409912]\n",
      "  num_agent_steps_sampled: 20000\n",
      "  num_agent_steps_trained: 636800\n",
      "  num_env_steps_sampled: 20000\n",
      "  num_env_steps_trained: 636800\n",
      "  num_target_updates: 40\n",
      "iterations_since_restore: 20\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 20000\n",
      "num_agent_steps_trained: 636800\n",
      "num_env_steps_sampled: 20000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.918014312213607\n",
      "num_env_steps_trained: 636800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 381.37645799083543\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.444999999999999\n",
      "  ram_util_percent: 59.07500000000002\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1166.3607800006866\n",
      "time_this_iter_s: 83.92425394058228\n",
      "time_total_s: 1166.3607800006866\n",
      "timers:\n",
      "  learn_throughput: 6150.457\n",
      "  learn_time_ms: 10.406\n",
      "  load_throughput: 528936.859\n",
      "  load_time_ms: 0.121\n",
      "  sample_time_ms: 143.583\n",
      "  synch_weights_time_ms: 2.97\n",
      "  training_iteration_time_ms: 167.627\n",
      "timestamp: 1709831862\n",
      "timesteps_total: 20000\n",
      "training_iteration: 20\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 21000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 21000\n",
      "  num_agent_steps_sampled: 21000\n",
      "  num_agent_steps_trained: 668800\n",
      "  num_env_steps_sampled: 21000\n",
      "  num_env_steps_trained: 668800\n",
      "  num_target_updates: 42\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-19-07\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 21000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 10449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0033378235530108213\n",
      "        max_q: 0.2841554582118988\n",
      "        mean_q: 0.2730996012687683\n",
      "        min_q: 0.25288522243499756\n",
      "      mean_td_error: 0.0020386031828820705\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 10450.0\n",
      "      td_error: [0.0012545585632324219, -0.004016369581222534, -0.004016369581222534,\n",
      "        0.006606459617614746, 0.007662385702133179, 0.006004124879837036, 0.005242764949798584,\n",
      "        0.006606459617614746, 0.005242764949798584, 0.0006687641143798828, -0.0040950775146484375,\n",
      "        0.002060532569885254, 0.00395965576171875, 0.0007812976837158203, 0.0007812976837158203,\n",
      "        -0.004538387060165405, 0.0037331581115722656, 0.006606459617614746, 0.0012545585632324219,\n",
      "        0.006606459617614746, 0.0017165541648864746, 0.0007812976837158203, 0.0037331581115722656,\n",
      "        0.006606459617614746, 0.006606459617614746, 0.0007812976837158203, 0.0017165541648864746,\n",
      "        -0.004243016242980957, 0.0006687641143798828, 0.0007812976837158203, -0.004538387060165405,\n",
      "        0.0006687641143798828, -0.004538387060165405, -0.004016369581222534, 0.0007812976837158203,\n",
      "        0.0007812976837158203, 0.007293134927749634, 0.006704151630401611, 0.006606459617614746,\n",
      "        0.0012545585632324219, 0.005088180303573608, 0.013559997081756592, 0.0015543997287750244,\n",
      "        -0.004538387060165405, -0.0040950775146484375, 0.007662385702133179, -0.004016369581222534,\n",
      "        -0.004538387060165405, 0.007662385702133179, 0.0007812976837158203, 0.0006687641143798828,\n",
      "        0.007662385702133179, 0.0037331581115722656, -0.004538387060165405, 0.006606459617614746,\n",
      "        -0.0064979493618011475, -0.004538387060165405, 0.006004124879837036, 0.0007812976837158203,\n",
      "        0.007662385702133179, 0.007293134927749634, 0.007662385702133179, -0.0036596953868865967,\n",
      "        0.00395965576171875]\n",
      "  num_agent_steps_sampled: 21000\n",
      "  num_agent_steps_trained: 668800\n",
      "  num_env_steps_sampled: 21000\n",
      "  num_env_steps_trained: 668800\n",
      "  num_target_updates: 42\n",
      "iterations_since_restore: 21\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 21000\n",
      "num_agent_steps_trained: 668800\n",
      "num_env_steps_sampled: 21000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.768347702298309\n",
      "num_env_steps_trained: 668800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 376.5871264735459\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.520000000000001\n",
      "  ram_util_percent: 59.34166666666667\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1251.3563759326935\n",
      "time_this_iter_s: 84.99559593200684\n",
      "time_total_s: 1251.3563759326935\n",
      "timers:\n",
      "  learn_throughput: 5517.675\n",
      "  learn_time_ms: 11.599\n",
      "  load_throughput: 584063.22\n",
      "  load_time_ms: 0.11\n",
      "  sample_time_ms: 144.91\n",
      "  synch_weights_time_ms: 3.424\n",
      "  training_iteration_time_ms: 172.391\n",
      "timestamp: 1709831947\n",
      "timesteps_total: 21000\n",
      "training_iteration: 21\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 22000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 22000\n",
      "  num_agent_steps_sampled: 22000\n",
      "  num_agent_steps_trained: 700800\n",
      "  num_env_steps_sampled: 22000\n",
      "  num_env_steps_trained: 700800\n",
      "  num_target_updates: 44\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-20-32\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 22000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 10949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0012359196553006768\n",
      "        max_q: 0.28005868196487427\n",
      "        mean_q: 0.27104756236076355\n",
      "        min_q: 0.2554032504558563\n",
      "      mean_td_error: -0.0013375133275985718\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 10950.0\n",
      "      td_error: [0.00010612607002258301, -0.0017915666103363037, -0.00018319487571716309,\n",
      "        0.000420302152633667, -0.00018319487571716309, -0.00018319487571716309, 0.0018994808197021484,\n",
      "        -0.0029724538326263428, -0.00018319487571716309, -0.00018319487571716309,\n",
      "        3.3468008041381836e-05, -0.003518223762512207, 0.0005824565887451172, -0.003518223762512207,\n",
      "        0.0072914958000183105, -0.00018319487571716309, -0.003898411989212036, -0.0005396902561187744,\n",
      "        -0.00018319487571716309, -0.0029724538326263428, -0.013397455215454102, -0.0017915666103363037,\n",
      "        -0.00011411309242248535, -0.00011411309242248535, -0.006431996822357178, -0.00018319487571716309,\n",
      "        -0.0017915666103363037, 0.00010612607002258301, -0.003518223762512207, -0.00011411309242248535,\n",
      "        0.002030402421951294, -0.003947854042053223, -0.0025361478328704834, -0.01118558645248413,\n",
      "        -0.0007326602935791016, -0.0030260980129241943, 0.002165675163269043, -0.003898411989212036,\n",
      "        -0.003898411989212036, -0.002958148717880249, 0.00045749545097351074, 0.0005824565887451172,\n",
      "        -0.006929278373718262, -0.0025361478328704834, -0.003947854042053223, -0.001454770565032959,\n",
      "        -0.0025939643383026123, 0.002165675163269043, -0.003518223762512207, 0.0015369653701782227,\n",
      "        -0.003947854042053223, -0.0005396902561187744, 0.0005824565887451172, -0.0005396902561187744,\n",
      "        -0.0005396902561187744, -0.0025939643383026123, -0.0029724538326263428, 0.002030402421951294,\n",
      "        0.007570445537567139, -0.0005396902561187744, -0.00011411309242248535, -0.0025361478328704834,\n",
      "        -0.00018319487571716309, 0.00045749545097351074]\n",
      "  num_agent_steps_sampled: 22000\n",
      "  num_agent_steps_trained: 700800\n",
      "  num_env_steps_sampled: 22000\n",
      "  num_env_steps_trained: 700800\n",
      "  num_target_updates: 44\n",
      "iterations_since_restore: 22\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 22000\n",
      "num_agent_steps_trained: 700800\n",
      "num_env_steps_sampled: 22000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.702217308453191\n",
      "num_env_steps_trained: 700800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 374.4709538705021\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.502479338842972\n",
      "  ram_util_percent: 59.56859504132233\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1336.8277869224548\n",
      "time_this_iter_s: 85.47141098976135\n",
      "time_total_s: 1336.8277869224548\n",
      "timers:\n",
      "  learn_throughput: 5714.359\n",
      "  learn_time_ms: 11.2\n",
      "  load_throughput: 622242.596\n",
      "  load_time_ms: 0.103\n",
      "  sample_time_ms: 147.431\n",
      "  synch_weights_time_ms: 3.169\n",
      "  training_iteration_time_ms: 174.935\n",
      "timestamp: 1709832032\n",
      "timesteps_total: 22000\n",
      "training_iteration: 22\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 23000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 23000\n",
      "  num_agent_steps_sampled: 23000\n",
      "  num_agent_steps_trained: 732800\n",
      "  num_env_steps_sampled: 23000\n",
      "  num_env_steps_trained: 732800\n",
      "  num_target_updates: 46\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-21-58\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 23000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 11449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0007137640495784581\n",
      "        max_q: 0.2909931242465973\n",
      "        mean_q: 0.2791636884212494\n",
      "        min_q: 0.268858939409256\n",
      "      mean_td_error: -0.0002717208117246628\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 11450.0\n",
      "      td_error: [0.0012218058109283447, 0.002432882785797119, 0.0016708970069885254,\n",
      "        -0.00016549229621887207, 0.0009669363498687744, 0.0012218058109283447, -0.00115203857421875,\n",
      "        -0.0036087632179260254, -0.0005370676517486572, 0.0011928975582122803, 0.00133436918258667,\n",
      "        0.0022215545177459717, -0.00016549229621887207, 0.0009479224681854248, -0.002353757619857788,\n",
      "        0.00017085671424865723, -0.0005370676517486572, 0.0011928975582122803, 0.0010870397090911865,\n",
      "        0.0010870397090911865, 0.0019289255142211914, 0.0016708970069885254, 0.0012218058109283447,\n",
      "        0.0009669363498687744, -0.0030395984649658203, -0.0030395984649658203, 0.00133436918258667,\n",
      "        0.0016708970069885254, -0.00016549229621887207, 0.005047738552093506, -0.00016549229621887207,\n",
      "        -0.003825843334197998, -0.012289166450500488, -0.0013320446014404297, -0.00016549229621887207,\n",
      "        0.0019289255142211914, 0.001842886209487915, -0.00021600723266601562, 0.0011928975582122803,\n",
      "        -0.0005370676517486572, 0.0012218058109283447, -7.325410842895508e-05, -0.0003234744071960449,\n",
      "        0.00018420815467834473, 0.0029424428939819336, -0.009909212589263916, 0.0012218058109283447,\n",
      "        -0.0003234744071960449, -0.0007058382034301758, -0.015062570571899414, -0.0023496150970458984,\n",
      "        -0.00011411309242248535, 0.00133436918258667, 0.0010870397090911865, -0.0013320446014404297,\n",
      "        0.0012218058109283447, -0.00016549229621887207, -0.0005368888378143311, 0.0009479224681854248,\n",
      "        -0.00016549229621887207, 0.0016708970069885254, -0.0006830394268035889, -0.0015805065631866455,\n",
      "        0.001842886209487915]\n",
      "  num_agent_steps_sampled: 23000\n",
      "  num_agent_steps_trained: 732800\n",
      "  num_env_steps_sampled: 23000\n",
      "  num_env_steps_trained: 732800\n",
      "  num_target_updates: 46\n",
      "iterations_since_restore: 23\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 23000\n",
      "num_agent_steps_trained: 732800\n",
      "num_env_steps_sampled: 23000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.626573584534276\n",
      "num_env_steps_trained: 732800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 372.0503547050968\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.68512396694215\n",
      "  ram_util_percent: 59.71157024793389\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1422.8550820350647\n",
      "time_this_iter_s: 86.02729511260986\n",
      "time_total_s: 1422.8550820350647\n",
      "timers:\n",
      "  learn_throughput: 5678.578\n",
      "  learn_time_ms: 11.27\n",
      "  load_throughput: 595332.57\n",
      "  load_time_ms: 0.108\n",
      "  sample_time_ms: 146.024\n",
      "  synch_weights_time_ms: 3.288\n",
      "  training_iteration_time_ms: 173.159\n",
      "timestamp: 1709832118\n",
      "timesteps_total: 23000\n",
      "training_iteration: 23\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 24000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 24000\n",
      "  num_agent_steps_sampled: 24000\n",
      "  num_agent_steps_trained: 764800\n",
      "  num_env_steps_sampled: 24000\n",
      "  num_env_steps_trained: 764800\n",
      "  num_target_updates: 48\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-23-24\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 24000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 11949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0006723540718667209\n",
      "        max_q: 0.29698681831359863\n",
      "        mean_q: 0.28705793619155884\n",
      "        min_q: 0.2783171832561493\n",
      "      mean_td_error: -0.000409112311899662\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 11950.0\n",
      "      td_error: [-0.0015303194522857666, -0.004332512617111206, 0.0001646876335144043,\n",
      "        0.00014671683311462402, 0.0001646876335144043, -0.003761768341064453, -4.3898820877075195e-05,\n",
      "        -0.0005969107151031494, -4.3898820877075195e-05, -0.00037804245948791504,\n",
      "        -4.3898820877075195e-05, 0.00014671683311462402, -0.003014594316482544, 0.00027814507484436035,\n",
      "        0.0001646876335144043, 0.0009997785091400146, -0.0001704096794128418, 0.0015184879302978516,\n",
      "        0.0015184879302978516, 0.0009237825870513916, -0.0002701878547668457, -0.0008173286914825439,\n",
      "        -0.0005969107151031494, 0.0009237825870513916, 0.0001646876335144043, -0.007871091365814209,\n",
      "        -0.0008173286914825439, -0.0003961920738220215, 0.0009237825870513916, -0.003761768341064453,\n",
      "        -0.0007735192775726318, -0.004332512617111206, -4.3898820877075195e-05, -0.0015303194522857666,\n",
      "        0.007376223802566528, -0.0005969107151031494, -0.0010017454624176025, -0.0015303194522857666,\n",
      "        -4.3898820877075195e-05, -0.0007735192775726318, -0.0008173286914825439, -0.004332512617111206,\n",
      "        -0.0005969107151031494, 0.0032408535480499268, 0.0009237825870513916, 0.001189112663269043,\n",
      "        -0.0005969107151031494, 0.0009237825870513916, -4.3898820877075195e-05, 0.00027814507484436035,\n",
      "        0.001189112663269043, 0.00014671683311462402, -0.0010384321212768555, -0.0007735192775726318,\n",
      "        -0.0007735192775726318, -0.0003961920738220215, 0.00014671683311462402, 0.00014671683311462402,\n",
      "        -0.0005969107151031494, 0.001189112663269043, -0.0015303194522857666, -0.0008173286914825439,\n",
      "        0.001189112663269043, -0.0007735192775726318]\n",
      "  num_agent_steps_sampled: 24000\n",
      "  num_agent_steps_trained: 764800\n",
      "  num_env_steps_sampled: 24000\n",
      "  num_env_steps_trained: 764800\n",
      "  num_target_updates: 48\n",
      "iterations_since_restore: 24\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 24000\n",
      "num_agent_steps_trained: 764800\n",
      "num_env_steps_sampled: 24000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.667081229714809\n",
      "num_env_steps_trained: 764800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 373.3465993508739\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.661475409836068\n",
      "  ram_util_percent: 59.88442622950818\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1508.585559129715\n",
      "time_this_iter_s: 85.73047709465027\n",
      "time_total_s: 1508.585559129715\n",
      "timers:\n",
      "  learn_throughput: 5645.876\n",
      "  learn_time_ms: 11.336\n",
      "  load_throughput: 536656.25\n",
      "  load_time_ms: 0.119\n",
      "  sample_time_ms: 146.279\n",
      "  synch_weights_time_ms: 3.504\n",
      "  training_iteration_time_ms: 173.38\n",
      "timestamp: 1709832204\n",
      "timesteps_total: 24000\n",
      "training_iteration: 24\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 25000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 25000\n",
      "  num_agent_steps_sampled: 25000\n",
      "  num_agent_steps_trained: 796800\n",
      "  num_env_steps_sampled: 25000\n",
      "  num_env_steps_trained: 796800\n",
      "  num_target_updates: 50\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-24-50\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 25000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 12449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0022742387373000383\n",
      "        max_q: 0.3049439489841461\n",
      "        mean_q: 0.29165294766426086\n",
      "        min_q: 0.28028544783592224\n",
      "      mean_td_error: 0.004726615734398365\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 12450.0\n",
      "      td_error: [0.010705798864364624, 0.0032122135162353516, 0.014552414417266846,\n",
      "        0.006334394216537476, 0.010705798864364624, 0.001088261604309082, 0.0013990402221679688,\n",
      "        0.010705798864364624, 0.0013990402221679688, 0.010592520236968994, 9.298324584960938e-06,\n",
      "        -0.0002270340919494629, 0.010705798864364624, 0.010476678609848022, 0.0076094865798950195,\n",
      "        0.009231865406036377, -0.0002270340919494629, 0.0076094865798950195, 0.010193705558776855,\n",
      "        0.010705798864364624, 0.001896888017654419, 0.001896888017654419, 0.010476678609848022,\n",
      "        -0.0002270340919494629, 0.0032122135162353516, -0.0002270340919494629, 0.0030837655067443848,\n",
      "        -0.0002270340919494629, 0.001896888017654419, 0.010476678609848022, 0.0022494494915008545,\n",
      "        -0.002076268196105957, 0.0009946823120117188, 0.001896888017654419, 0.0025505423545837402,\n",
      "        0.010705798864364624, 0.010705798864364624, 0.011664241552352905, -0.0002270340919494629,\n",
      "        0.0022494494915008545, 0.0013990402221679688, 0.0013990402221679688, 0.006387591361999512,\n",
      "        0.009476035833358765, 0.0032122135162353516, -0.0002532005310058594, 0.006387591361999512,\n",
      "        -0.0002270340919494629, -0.0002270340919494629, 0.010705798864364624, -0.0002270340919494629,\n",
      "        0.010705798864364624, 0.0021987557411193848, 0.0076094865798950195, 9.298324584960938e-06,\n",
      "        0.006599903106689453, 0.010476678609848022, 0.006334394216537476, 0.0022494494915008545,\n",
      "        0.0013990402221679688, 0.005216330289840698, 0.001896888017654419, 9.298324584960938e-06,\n",
      "        9.298324584960938e-06]\n",
      "  num_agent_steps_sampled: 25000\n",
      "  num_agent_steps_trained: 796800\n",
      "  num_env_steps_sampled: 25000\n",
      "  num_env_steps_trained: 796800\n",
      "  num_target_updates: 50\n",
      "iterations_since_restore: 25\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 25000\n",
      "num_agent_steps_trained: 796800\n",
      "num_env_steps_sampled: 25000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.70888342811705\n",
      "num_env_steps_trained: 796800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 374.6842696997456\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.571074380165289\n",
      "  ram_util_percent: 59.98347107438016\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1594.0093309879303\n",
      "time_this_iter_s: 85.42377185821533\n",
      "time_total_s: 1594.0093309879303\n",
      "timers:\n",
      "  learn_throughput: 6282.557\n",
      "  learn_time_ms: 10.187\n",
      "  load_throughput: 723350.73\n",
      "  load_time_ms: 0.088\n",
      "  sample_time_ms: 143.887\n",
      "  synch_weights_time_ms: 2.96\n",
      "  training_iteration_time_ms: 167.757\n",
      "timestamp: 1709832290\n",
      "timesteps_total: 25000\n",
      "training_iteration: 25\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 26000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 26000\n",
      "  num_agent_steps_sampled: 26000\n",
      "  num_agent_steps_trained: 828800\n",
      "  num_env_steps_sampled: 26000\n",
      "  num_env_steps_trained: 828800\n",
      "  num_target_updates: 52\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-26-16\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 26000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 12949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0015270891599357128\n",
      "        max_q: 0.3075326383113861\n",
      "        mean_q: 0.29699409008026123\n",
      "        min_q: 0.2869991660118103\n",
      "      mean_td_error: -0.00027201278135180473\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 12950.0\n",
      "      td_error: [0.0029366016387939453, -0.004105597734451294, -0.0016810595989227295,\n",
      "        -0.0014173388481140137, 0.0008023381233215332, 0.0029366016387939453, -0.006332695484161377,\n",
      "        0.0008023381233215332, 0.00221291184425354, 0.0015174150466918945, -0.006500452756881714,\n",
      "        -0.0009525716304779053, -0.006332695484161377, 0.00221291184425354, 0.0008023381233215332,\n",
      "        0.0008023381233215332, 0.0029366016387939453, 0.0008023381233215332, -0.0007488131523132324,\n",
      "        0.00022307038307189941, -0.0011777877807617188, -0.006500452756881714, 0.001232147216796875,\n",
      "        0.00221291184425354, 0.0008023381233215332, -0.006332695484161377, 0.0008316338062286377,\n",
      "        0.0029366016387939453, -0.003015279769897461, -0.00014013051986694336, 0.0008023381233215332,\n",
      "        0.0029366016387939453, 0.0023828744888305664, -0.0014173388481140137, 0.0029366016387939453,\n",
      "        0.0008023381233215332, -0.006500452756881714, 0.0038747787475585938, 0.0008023381233215332,\n",
      "        0.003170520067214966, 0.005309343338012695, 0.0007309317588806152, -0.0009525716304779053,\n",
      "        0.0016352832317352295, 0.0029366016387939453, -0.006717950105667114, -0.006332695484161377,\n",
      "        0.0029366016387939453, 0.0006338357925415039, 0.00022307038307189941, 0.00221291184425354,\n",
      "        0.0029366016387939453, -0.0009525716304779053, 0.0006338357925415039, -0.0014173388481140137,\n",
      "        0.0029366016387939453, 0.00022307038307189941, -0.0009525716304779053, -0.0014173388481140137,\n",
      "        -0.0007488131523132324, -0.0008206069469451904, -0.006500452756881714, 0.0008316338062286377,\n",
      "        -0.006332695484161377]\n",
      "  num_agent_steps_sampled: 26000\n",
      "  num_agent_steps_trained: 828800\n",
      "  num_env_steps_sampled: 26000\n",
      "  num_env_steps_trained: 828800\n",
      "  num_target_updates: 52\n",
      "iterations_since_restore: 26\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 26000\n",
      "num_agent_steps_trained: 828800\n",
      "num_env_steps_sampled: 26000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.634185228395637\n",
      "num_env_steps_trained: 828800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 372.2939273086604\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.608264462809919\n",
      "  ram_util_percent: 60.09586776859504\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1679.9857127666473\n",
      "time_this_iter_s: 85.97638177871704\n",
      "time_total_s: 1679.9857127666473\n",
      "timers:\n",
      "  learn_throughput: 5488.165\n",
      "  learn_time_ms: 11.661\n",
      "  load_throughput: 532821.469\n",
      "  load_time_ms: 0.12\n",
      "  sample_time_ms: 147.383\n",
      "  synch_weights_time_ms: 3.325\n",
      "  training_iteration_time_ms: 176.233\n",
      "timestamp: 1709832376\n",
      "timesteps_total: 26000\n",
      "training_iteration: 26\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 27000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 27000\n",
      "  num_agent_steps_sampled: 27000\n",
      "  num_agent_steps_trained: 860800\n",
      "  num_env_steps_sampled: 27000\n",
      "  num_env_steps_trained: 860800\n",
      "  num_target_updates: 54\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-27-42\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 27000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 13449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.00016591016901656985\n",
      "        max_q: 0.3163471519947052\n",
      "        mean_q: 0.3018011748790741\n",
      "        min_q: 0.2974475026130676\n",
      "      mean_td_error: 0.00020991917699575424\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 13450.0\n",
      "      td_error: [-9.775161743164062e-06, -0.00036588311195373535, -0.00036588311195373535,\n",
      "        -0.00036588311195373535, -0.00036588311195373535, -0.0004889369010925293,\n",
      "        0.0010375380516052246, -9.775161743164062e-06, 0.0009991824626922607, -0.00036588311195373535,\n",
      "        0.0009991824626922607, -0.0005345344543457031, -9.626150131225586e-05, -0.0005345344543457031,\n",
      "        0.00036787986755371094, 0.0009991824626922607, 0.0009991824626922607, 0.0010375380516052246,\n",
      "        -9.775161743164062e-06, 6.341934204101562e-05, 0.0010375380516052246, -0.0002903938293457031,\n",
      "        0.0009991824626922607, -9.775161743164062e-06, -7.987022399902344e-06, 0.002224445343017578,\n",
      "        -0.0011208057403564453, 0.0010375380516052246, 0.00036787986755371094, 0.0020354390144348145,\n",
      "        0.0004163384437561035, 0.00029796361923217773, 0.0010375380516052246, 0.0009578466415405273,\n",
      "        -0.0010611414909362793, 0.0010375380516052246, 6.961822509765625e-05, 0.0009991824626922607,\n",
      "        -9.775161743164062e-06, 6.341934204101562e-05, 0.00036787986755371094, 6.505846977233887e-05,\n",
      "        -0.0010611414909362793, 6.961822509765625e-05, -0.0005345344543457031, 0.0009991824626922607,\n",
      "        0.0020072758197784424, 0.00036787986755371094, -0.0010611414909362793, -0.0008130669593811035,\n",
      "        0.0009578466415405273, 0.0009991824626922607, -0.00036588311195373535, -0.0010611414909362793,\n",
      "        0.00031644105911254883, 0.00036787986755371094, -0.00036588311195373535, -0.00039264559745788574,\n",
      "        -0.0010611414909362793, 0.0009991824626922607, -9.626150131225586e-05, -0.0003968775272369385,\n",
      "        -7.987022399902344e-06, 6.341934204101562e-05]\n",
      "  num_agent_steps_sampled: 27000\n",
      "  num_agent_steps_trained: 860800\n",
      "  num_env_steps_sampled: 27000\n",
      "  num_env_steps_trained: 860800\n",
      "  num_target_updates: 54\n",
      "iterations_since_restore: 27\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 27000\n",
      "num_agent_steps_trained: 860800\n",
      "num_env_steps_sampled: 27000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.632066411900167\n",
      "num_env_steps_trained: 860800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 372.22612518080535\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.758196721311476\n",
      "  ram_util_percent: 60.32049180327867\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1765.9718878269196\n",
      "time_this_iter_s: 85.98617506027222\n",
      "time_total_s: 1765.9718878269196\n",
      "timers:\n",
      "  learn_throughput: 5951.095\n",
      "  learn_time_ms: 10.754\n",
      "  load_throughput: 475949.39\n",
      "  load_time_ms: 0.134\n",
      "  sample_time_ms: 144.57\n",
      "  synch_weights_time_ms: 4.037\n",
      "  training_iteration_time_ms: 171.67\n",
      "timestamp: 1709832462\n",
      "timesteps_total: 27000\n",
      "training_iteration: 27\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 28000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 28000\n",
      "  num_agent_steps_sampled: 28000\n",
      "  num_agent_steps_trained: 892800\n",
      "  num_env_steps_sampled: 28000\n",
      "  num_env_steps_trained: 892800\n",
      "  num_target_updates: 56\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-29-07\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 28000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 13949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0008341794600710273\n",
      "        max_q: 0.3060581386089325\n",
      "        mean_q: 0.29800304770469666\n",
      "        min_q: 0.29398971796035767\n",
      "      mean_td_error: -0.0005188975483179092\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 13950.0\n",
      "      td_error: [-0.001424551010131836, -0.0035470128059387207, -0.001049429178237915,\n",
      "        -0.00022166967391967773, -0.0021879374980926514, 0.00383836030960083, -0.0012415051460266113,\n",
      "        -0.00022166967391967773, -0.0008552372455596924, -0.002008378505706787, -0.00022166967391967773,\n",
      "        0.0019865334033966064, -0.0021879374980926514, -0.003922820091247559, -0.00022166967391967773,\n",
      "        -0.00022166967391967773, 0.0019865334033966064, 0.0020693838596343994, -0.001424551010131836,\n",
      "        -0.0010296404361724854, -0.0002351701259613037, -0.0010296404361724854, -0.00115126371383667,\n",
      "        -0.0003750920295715332, -0.001424551010131836, -0.0006471872329711914, -0.0021879374980926514,\n",
      "        0.0020693838596343994, -0.0012876391410827637, -0.0017726123332977295, 3.0934810638427734e-05,\n",
      "        -0.0035470128059387207, -0.001424551010131836, -0.00022166967391967773, 3.0934810638427734e-05,\n",
      "        -0.003987312316894531, 0.0019865334033966064, -0.00022166967391967773, -0.001500248908996582,\n",
      "        -0.00115126371383667, -0.00115126371383667, -0.0035470128059387207, -0.00022166967391967773,\n",
      "        -0.0010296404361724854, 0.003352224826812744, -0.0014574527740478516, -0.001049429178237915,\n",
      "        -0.00022166967391967773, 0.003352224826812744, -0.001049429178237915, 0.0005525648593902588,\n",
      "        -0.001962333917617798, -0.00022166967391967773, -0.00115126371383667, -0.001424551010131836,\n",
      "        0.003352224826812744, 0.0020693838596343994, -0.0003750920295715332, 3.0934810638427734e-05,\n",
      "        -0.0010159015655517578, -0.0017726123332977295, -0.001049429178237915, 0.0005676150321960449,\n",
      "        0.002367377281188965]\n",
      "  num_agent_steps_sampled: 28000\n",
      "  num_agent_steps_trained: 892800\n",
      "  num_env_steps_sampled: 28000\n",
      "  num_env_steps_trained: 892800\n",
      "  num_target_updates: 56\n",
      "iterations_since_restore: 28\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 28000\n",
      "num_agent_steps_trained: 892800\n",
      "num_env_steps_sampled: 28000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.70772136788584\n",
      "num_env_steps_trained: 892800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 374.6470837723469\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.659504132231405\n",
      "  ram_util_percent: 60.566115702479344\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1851.4046437740326\n",
      "time_this_iter_s: 85.43275594711304\n",
      "time_total_s: 1851.4046437740326\n",
      "timers:\n",
      "  learn_throughput: 6194.083\n",
      "  learn_time_ms: 10.332\n",
      "  load_throughput: 672939.223\n",
      "  load_time_ms: 0.095\n",
      "  sample_time_ms: 144.999\n",
      "  synch_weights_time_ms: 3.058\n",
      "  training_iteration_time_ms: 169.412\n",
      "timestamp: 1709832547\n",
      "timesteps_total: 28000\n",
      "training_iteration: 28\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 29000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 29000\n",
      "  num_agent_steps_sampled: 29000\n",
      "  num_agent_steps_trained: 924800\n",
      "  num_env_steps_sampled: 29000\n",
      "  num_env_steps_trained: 924800\n",
      "  num_target_updates: 58\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-30-33\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 29000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 14449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0010193587513640523\n",
      "        max_q: 0.3140231668949127\n",
      "        mean_q: 0.30537402629852295\n",
      "        min_q: 0.298895925283432\n",
      "      mean_td_error: -0.0016038976609706879\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 14450.0\n",
      "      td_error: [-0.00395926833152771, -0.005888640880584717, -0.001394718885421753,\n",
      "        -0.00203704833984375, -0.0034449100494384766, -0.00034815073013305664, -0.002741098403930664,\n",
      "        -0.00395926833152771, -8.147954940795898e-05, -0.0004851818084716797, -0.0012873709201812744,\n",
      "        -0.0003427267074584961, -0.0034449100494384766, -0.0034449100494384766, -0.0005934536457061768,\n",
      "        -0.004656553268432617, -0.005016624927520752, -0.0006780624389648438, -0.0006780624389648438,\n",
      "        -0.0007667839527130127, -0.0006780624389648438, -0.0004851818084716797, -0.00034815073013305664,\n",
      "        -0.0005934536457061768, -0.002741098403930664, -0.0004851818084716797, -0.00395926833152771,\n",
      "        -0.00395926833152771, -0.002741098403930664, -0.0011963844299316406, 0.0006001889705657959,\n",
      "        0.0004258453845977783, -0.0005934536457061768, -0.005016624927520752, -8.147954940795898e-05,\n",
      "        -0.0005934536457061768, -0.0003427267074584961, -0.0040306150913238525, -0.0015485584735870361,\n",
      "        -0.0006780624389648438, -0.0003427267074584961, -0.0004851818084716797, -0.00395926833152771,\n",
      "        -0.0005934536457061768, -8.147954940795898e-05, -0.0005934536457061768, -0.0003427267074584961,\n",
      "        -0.00395926833152771, -0.0034449100494384766, 0.00067940354347229, -0.0005934536457061768,\n",
      "        0.0003598928451538086, -0.002741098403930664, -0.00203704833984375, -0.00034815073013305664,\n",
      "        -0.00395926833152771, -8.147954940795898e-05, -0.00034815073013305664, -0.005888640880584717,\n",
      "        0.0016818642616271973, 0.0004258453845977783, -0.00034815073013305664, -8.147954940795898e-05,\n",
      "        -0.001271754503250122]\n",
      "  num_agent_steps_sampled: 29000\n",
      "  num_agent_steps_trained: 924800\n",
      "  num_env_steps_sampled: 29000\n",
      "  num_env_steps_trained: 924800\n",
      "  num_target_updates: 58\n",
      "iterations_since_restore: 29\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 29000\n",
      "num_agent_steps_trained: 924800\n",
      "num_env_steps_sampled: 29000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.672088553440817\n",
      "num_env_steps_trained: 924800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 373.50683371010615\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.514049586776858\n",
      "  ram_util_percent: 60.68512396694217\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 1937.0968499183655\n",
      "time_this_iter_s: 85.69220614433289\n",
      "time_total_s: 1937.0968499183655\n",
      "timers:\n",
      "  learn_throughput: 6208.624\n",
      "  learn_time_ms: 10.308\n",
      "  load_throughput: 625286.41\n",
      "  load_time_ms: 0.102\n",
      "  sample_time_ms: 142.705\n",
      "  synch_weights_time_ms: 3.063\n",
      "  training_iteration_time_ms: 166.947\n",
      "timestamp: 1709832633\n",
      "timesteps_total: 29000\n",
      "training_iteration: 29\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 30000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 30000\n",
      "  num_agent_steps_sampled: 30000\n",
      "  num_agent_steps_trained: 956800\n",
      "  num_env_steps_sampled: 30000\n",
      "  num_env_steps_trained: 956800\n",
      "  num_target_updates: 60\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-31-58\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 30000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 14949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0011992999352514744\n",
      "        max_q: 0.3126329183578491\n",
      "        mean_q: 0.3034965991973877\n",
      "        min_q: 0.2920967638492584\n",
      "      mean_td_error: -0.0008940566331148148\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 14950.0\n",
      "      td_error: [0.0018010139465332031, -0.0021886229515075684, -0.007620751857757568,\n",
      "        -0.0033193230628967285, -0.0028143227100372314, 0.0029565393924713135, -0.005796641111373901,\n",
      "        0.0010238885879516602, 0.0001500844955444336, -0.00046253204345703125, 0.0029565393924713135,\n",
      "        0.0029565393924713135, 0.0036516189575195312, -0.005796641111373901, 0.0023210644721984863,\n",
      "        -0.0028143227100372314, 0.001388460397720337, -0.0021886229515075684, -0.0006284713745117188,\n",
      "        -0.0021886229515075684, -0.0071547627449035645, -0.0022374987602233887, -0.0028143227100372314,\n",
      "        -0.0022374987602233887, -0.0028143227100372314, -0.0021886229515075684, 0.0029565393924713135,\n",
      "        -0.008469164371490479, -0.0021886229515075684, -0.0022374987602233887, -0.0021886229515075684,\n",
      "        -0.0030381977558135986, 0.0023210644721984863, -0.0021886229515075684, -0.0006284713745117188,\n",
      "        0.0036516189575195312, -0.0005556046962738037, -0.0028143227100372314, 0.0029565393924713135,\n",
      "        -0.0018410086631774902, 0.0036516189575195312, 0.001388460397720337, -0.0030381977558135986,\n",
      "        -0.007620751857757568, -0.0021886229515075684, -0.0018410086631774902, -0.00046253204345703125,\n",
      "        -0.0022374987602233887, 0.0023210644721984863, -0.0020752251148223877, -0.0028143227100372314,\n",
      "        -0.0028143227100372314, -0.0021886229515075684, 0.003337949514389038, 0.0036516189575195312,\n",
      "        0.001388460397720337, 0.0008943378925323486, 0.001388460397720337, -0.0005556046962738037,\n",
      "        0.0012745559215545654, -0.0005112886428833008, 0.0029565393924713135, 0.001388460397720337,\n",
      "        -0.0021886229515075684]\n",
      "  num_agent_steps_sampled: 30000\n",
      "  num_agent_steps_trained: 956800\n",
      "  num_env_steps_sampled: 30000\n",
      "  num_env_steps_trained: 956800\n",
      "  num_target_updates: 60\n",
      "iterations_since_restore: 30\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 30000\n",
      "num_agent_steps_trained: 956800\n",
      "num_env_steps_sampled: 30000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.706790872837098\n",
      "num_env_steps_trained: 956800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 374.61730793078715\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.558677685950414\n",
      "  ram_util_percent: 60.65123966942151\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 2022.5345737934113\n",
      "time_this_iter_s: 85.43772387504578\n",
      "time_total_s: 2022.5345737934113\n",
      "timers:\n",
      "  learn_throughput: 6312.489\n",
      "  learn_time_ms: 10.139\n",
      "  load_throughput: 657446.623\n",
      "  load_time_ms: 0.097\n",
      "  sample_time_ms: 143.92\n",
      "  synch_weights_time_ms: 2.958\n",
      "  training_iteration_time_ms: 167.567\n",
      "timestamp: 1709832718\n",
      "timesteps_total: 30000\n",
      "training_iteration: 30\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 31000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 31000\n",
      "  num_agent_steps_sampled: 31000\n",
      "  num_agent_steps_trained: 988800\n",
      "  num_env_steps_sampled: 31000\n",
      "  num_env_steps_trained: 988800\n",
      "  num_target_updates: 62\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-33-24\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 31000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 15449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0020943309646099806\n",
      "        max_q: 0.3261772096157074\n",
      "        mean_q: 0.30933305621147156\n",
      "        min_q: 0.30250120162963867\n",
      "      mean_td_error: 0.002596790436655283\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 15450.0\n",
      "      td_error: [0.015978991985321045, -0.000504910945892334, -0.0011033415794372559,\n",
      "        0.0015489161014556885, -0.00044342875480651855, 0.0015489161014556885, -0.0008090436458587646,\n",
      "        -0.0011033415794372559, -0.0015380382537841797, 0.011471927165985107, 0.0019458532333374023,\n",
      "        -0.0015380382537841797, 0.001301199197769165, -0.0011033415794372559, 0.001862168312072754,\n",
      "        -0.000504910945892334, 0.001862168312072754, 0.0002524852752685547, -0.00044342875480651855,\n",
      "        0.0012119412422180176, 0.0019458532333374023, 0.0007425248622894287, -0.0010074973106384277,\n",
      "        0.0015489161014556885, 0.001843571662902832, -0.0003738701343536377, 0.0012119412422180176,\n",
      "        0.010667502880096436, 0.001862168312072754, 0.010667502880096436, 0.001862168312072754,\n",
      "        -0.0011033415794372559, -0.00044342875480651855, 0.001862168312072754, -0.0008714795112609863,\n",
      "        0.0012119412422180176, 0.0019458532333374023, 0.001862168312072754, 0.015978991985321045,\n",
      "        0.001862168312072754, 0.001862168312072754, 0.0015489161014556885, 0.001862168312072754,\n",
      "        0.0019458532333374023, 0.0015489161014556885, 0.0035819709300994873, 0.0015489161014556885,\n",
      "        0.0019458532333374023, -0.0005078315734863281, -0.0003329813480377197, -0.000504910945892334,\n",
      "        -0.000504910945892334, 0.015978991985321045, 0.010667502880096436, -0.0015380382537841797,\n",
      "        -0.00044342875480651855, -0.0015380382537841797, -0.0015380382537841797, -0.0015380382537841797,\n",
      "        0.015978991985321045, 0.015978991985321045, 0.0015489161014556885, -0.000504910945892334,\n",
      "        0.015978991985321045]\n",
      "  num_agent_steps_sampled: 31000\n",
      "  num_agent_steps_trained: 988800\n",
      "  num_env_steps_sampled: 31000\n",
      "  num_env_steps_trained: 988800\n",
      "  num_target_updates: 62\n",
      "iterations_since_restore: 31\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 31000\n",
      "num_agent_steps_trained: 988800\n",
      "num_env_steps_sampled: 31000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.68920409376868\n",
      "num_env_steps_trained: 988800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 374.05453100059776\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.562809917355374\n",
      "  ram_util_percent: 60.69090909090911\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 2108.102175951004\n",
      "time_this_iter_s: 85.56760215759277\n",
      "time_total_s: 2108.102175951004\n",
      "timers:\n",
      "  learn_throughput: 5980.649\n",
      "  learn_time_ms: 10.701\n",
      "  load_throughput: 651226.24\n",
      "  load_time_ms: 0.098\n",
      "  sample_time_ms: 145.077\n",
      "  synch_weights_time_ms: 3.854\n",
      "  training_iteration_time_ms: 171.03\n",
      "timestamp: 1709832804\n",
      "timesteps_total: 31000\n",
      "training_iteration: 31\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 32000\n",
      "connector_metrics: {}\n",
      "counters:\n",
      "  last_target_update_ts: 32000\n",
      "  num_agent_steps_sampled: 32000\n",
      "  num_agent_steps_trained: 1020800\n",
      "  num_env_steps_sampled: 32000\n",
      "  num_env_steps_trained: 1020800\n",
      "  num_target_updates: 64\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-34-49\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 32000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 15949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.00220946641638875\n",
      "        max_q: 0.3219025731086731\n",
      "        mean_q: 0.3144102096557617\n",
      "        min_q: 0.3056632876396179\n",
      "      mean_td_error: -0.0012886188924312592\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 15950.0\n",
      "      td_error: [-0.004044830799102783, -0.005508780479431152, -0.004528671503067017,\n",
      "        -0.004528671503067017, -0.0007493495941162109, 0.004929304122924805, 0.0005329549312591553,\n",
      "        -0.004528671503067017, -0.002950519323348999, -0.005508780479431152, -0.005508780479431152,\n",
      "        -0.004044830799102783, 0.0005329549312591553, 0.004929304122924805, 0.00464397668838501,\n",
      "        0.0005329549312591553, -0.00499996542930603, -0.009814620018005371, 0.0023985207080841064,\n",
      "        0.0005329549312591553, 0.0005329549312591553, 0.0048254430294036865, 0.0037370920181274414,\n",
      "        -0.004240095615386963, 0.0005329549312591553, -0.003170788288116455, -0.005508780479431152,\n",
      "        -0.005697578191757202, -0.004044830799102783, -0.004044830799102783, -6.517767906188965e-05,\n",
      "        -0.004528671503067017, -0.004321843385696411, 0.0048254430294036865, 0.0026139914989471436,\n",
      "        0.007440418004989624, -0.004044830799102783, -0.005508780479431152, 0.0005329549312591553,\n",
      "        -0.004044830799102783, 0.0005329549312591553, -0.005508780479431152, 0.0005329549312591553,\n",
      "        -0.002972841262817383, -0.005697578191757202, -0.004044830799102783, 0.005602717399597168,\n",
      "        -0.004528671503067017, 0.0048254430294036865, -0.004528671503067017, 0.0026139914989471436,\n",
      "        -0.005508780479431152, -0.003170788288116455, -0.00499996542930603, 0.0005329549312591553,\n",
      "        -0.005508780479431152, 0.001657247543334961, -0.003170788288116455, 0.0048254430294036865,\n",
      "        -0.002950519323348999, -0.005508780479431152, 0.006613045930862427, 0.0048254430294036865,\n",
      "        0.004929304122924805]\n",
      "  num_agent_steps_sampled: 32000\n",
      "  num_agent_steps_trained: 1020800\n",
      "  num_env_steps_sampled: 32000\n",
      "  num_env_steps_trained: 1020800\n",
      "  num_target_updates: 64\n",
      "iterations_since_restore: 32\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 32000\n",
      "num_agent_steps_trained: 1020800\n",
      "num_env_steps_sampled: 32000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.730398606663893\n",
      "num_env_steps_trained: 1020800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 375.3727554132446\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.499166666666666\n",
      "  ram_util_percent: 60.669166666666676\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "sampler_results:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "time_since_restore: 2193.368318796158\n",
      "time_this_iter_s: 85.26614284515381\n",
      "time_total_s: 2193.368318796158\n",
      "timers:\n",
      "  learn_throughput: 5939.902\n",
      "  learn_time_ms: 10.775\n",
      "  load_throughput: 632207.857\n",
      "  load_time_ms: 0.101\n",
      "  sample_time_ms: 143.486\n",
      "  synch_weights_time_ms: 3.089\n",
      "  training_iteration_time_ms: 169.079\n",
      "timestamp: 1709832889\n",
      "timesteps_total: 32000\n",
      "training_iteration: 32\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 33000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 33000\n",
      "  num_agent_steps_sampled: 33000\n",
      "  num_agent_steps_trained: 1052800\n",
      "  num_env_steps_sampled: 33000\n",
      "  num_env_steps_trained: 1052800\n",
      "  num_target_updates: 66\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-36-14\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 33000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 16449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0017921320395544171\n",
      "        max_q: 0.3338131606578827\n",
      "        mean_q: 0.3251096308231354\n",
      "        min_q: 0.3133258819580078\n",
      "      mean_td_error: 0.002084672451019287\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 16450.0\n",
      "      td_error: [0.001548171043395996, 0.0014522373676300049, 0.0014522373676300049,\n",
      "        0.0014067590236663818, 0.0025387704372406006, 0.0026073157787323, 0.006548583507537842,\n",
      "        -0.0005078017711639404, -0.00122147798538208, 0.00023955106735229492, -0.0013629496097564697,\n",
      "        0.001838773488998413, 0.00012150406837463379, 0.006548583507537842, 0.00023955106735229492,\n",
      "        0.006813943386077881, -0.0013629496097564697, 0.0050809383392333984, 0.0009689033031463623,\n",
      "        -0.0013629496097564697, 0.003433525562286377, 0.0035472512245178223, 0.0009649693965911865,\n",
      "        0.0014067590236663818, 0.0026073157787323, -0.00122147798538208, 0.0026073157787323,\n",
      "        0.001838773488998413, -0.00122147798538208, 0.0026073157787323, 0.0014067590236663818,\n",
      "        -0.00122147798538208, 0.006548583507537842, 0.003433525562286377, 0.00012150406837463379,\n",
      "        0.00012150406837463379, 0.006813943386077881, 0.007762521505355835, 0.007762521505355835,\n",
      "        0.003433525562286377, 0.007762521505355835, 0.003846079111099243, 0.003433525562286377,\n",
      "        0.0014067590236663818, -0.0005078017711639404, 0.0010303854942321777, -0.005504190921783447,\n",
      "        0.007762521505355835, 0.005934983491897583, 0.0026073157787323, 0.00012150406837463379,\n",
      "        0.006573140621185303, 0.0014067590236663818, 0.003433525562286377, -0.0030248165130615234,\n",
      "        0.002223491668701172, -0.00122147798538208, -0.0005078017711639404, -0.010720998048782349,\n",
      "        0.0014067590236663818, 0.005934983491897583, 0.006813943386077881, 0.003433525562286377,\n",
      "        0.003433525562286377]\n",
      "  num_agent_steps_sampled: 33000\n",
      "  num_agent_steps_trained: 1052800\n",
      "  num_env_steps_sampled: 33000\n",
      "  num_env_steps_trained: 1052800\n",
      "  num_target_updates: 66\n",
      "iterations_since_restore: 33\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 33000\n",
      "num_agent_steps_trained: 1052800\n",
      "num_env_steps_sampled: 33000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.74276912446699\n",
      "num_env_steps_trained: 1052800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 375.7686119829437\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.532231404958681\n",
      "  ram_util_percent: 60.66528925619836\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 2\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2278.5474905967712\n",
      "time_this_iter_s: 85.1791718006134\n",
      "time_total_s: 2278.5474905967712\n",
      "timers:\n",
      "  learn_throughput: 5682.882\n",
      "  learn_time_ms: 11.262\n",
      "  load_throughput: 497010.657\n",
      "  load_time_ms: 0.129\n",
      "  sample_time_ms: 145.343\n",
      "  synch_weights_time_ms: 3.465\n",
      "  training_iteration_time_ms: 172.948\n",
      "timestamp: 1709832974\n",
      "timesteps_total: 33000\n",
      "training_iteration: 33\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 34000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 34000\n",
      "  num_agent_steps_sampled: 34000\n",
      "  num_agent_steps_trained: 1084800\n",
      "  num_env_steps_sampled: 34000\n",
      "  num_env_steps_trained: 1084800\n",
      "  num_target_updates: 68\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-37-39\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 34000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 16949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.005261556711047888\n",
      "        max_q: 0.3402702808380127\n",
      "        mean_q: 0.33105146884918213\n",
      "        min_q: 0.3150993287563324\n",
      "      mean_td_error: -0.003516480792313814\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 16950.0\n",
      "      td_error: [-0.0033067166805267334, 4.839897155761719e-05, -0.017200857400894165,\n",
      "        -0.017200857400894165, 0.0013539493083953857, -0.0035031139850616455, 0.0006917119026184082,\n",
      "        4.839897155761719e-05, -0.016461044549942017, 0.0008903741836547852, 9.223818778991699e-05,\n",
      "        0.0008903741836547852, 4.839897155761719e-05, 0.0006917119026184082, -0.016461044549942017,\n",
      "        0.0008903741836547852, 0.003726661205291748, 0.004050254821777344, 0.0005164146423339844,\n",
      "        0.003368973731994629, 0.003368973731994629, -0.017200857400894165, 0.0006676912307739258,\n",
      "        -0.01477929949760437, -0.0035031139850616455, 0.0006917119026184082, 9.223818778991699e-05,\n",
      "        -0.01477929949760437, -0.017200857400894165, 0.0006511509418487549, 0.003726661205291748,\n",
      "        -0.016461044549942017, 0.000647127628326416, -0.017200857400894165, -0.017200857400894165,\n",
      "        -0.01477929949760437, 0.000647127628326416, -0.0033067166805267334, 0.0006917119026184082,\n",
      "        -0.016461044549942017, 0.003726661205291748, -0.0035031139850616455, 0.0018234848976135254,\n",
      "        0.0006917119026184082, 0.003726661205291748, 0.0008903741836547852, -0.0033067166805267334,\n",
      "        0.003726661205291748, -0.017200857400894165, -0.017200857400894165, 0.0006917119026184082,\n",
      "        0.003726661205291748, 0.0008903741836547852, 0.003368973731994629, 9.223818778991699e-05,\n",
      "        0.0008903741836547852, 0.001749873161315918, 0.0008903741836547852, 0.004577726125717163,\n",
      "        -0.0035031139850616455, -0.017200857400894165, 9.223818778991699e-05, 9.223818778991699e-05,\n",
      "        0.003726661205291748]\n",
      "  num_agent_steps_sampled: 34000\n",
      "  num_agent_steps_trained: 1084800\n",
      "  num_env_steps_sampled: 34000\n",
      "  num_env_steps_trained: 1084800\n",
      "  num_target_updates: 68\n",
      "iterations_since_restore: 34\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 34000\n",
      "num_agent_steps_trained: 1084800\n",
      "num_env_steps_sampled: 34000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.755015860315938\n",
      "num_env_steps_trained: 1084800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 376.16050753011\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.545\n",
      "  ram_util_percent: 60.645000000000024\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2363.635830640793\n",
      "time_this_iter_s: 85.0883400440216\n",
      "time_total_s: 2363.635830640793\n",
      "timers:\n",
      "  learn_throughput: 5957.739\n",
      "  learn_time_ms: 10.742\n",
      "  load_throughput: 685658.891\n",
      "  load_time_ms: 0.093\n",
      "  sample_time_ms: 146.216\n",
      "  synch_weights_time_ms: 3.119\n",
      "  training_iteration_time_ms: 171.303\n",
      "timestamp: 1709833059\n",
      "timesteps_total: 34000\n",
      "training_iteration: 34\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 35000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 35000\n",
      "  num_agent_steps_sampled: 35000\n",
      "  num_agent_steps_trained: 1116800\n",
      "  num_env_steps_sampled: 35000\n",
      "  num_env_steps_trained: 1116800\n",
      "  num_target_updates: 70\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-39-05\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 35000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 17449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0013177539221942425\n",
      "        max_q: 0.34904301166534424\n",
      "        mean_q: 0.3411712944507599\n",
      "        min_q: 0.3264796733856201\n",
      "      mean_td_error: -0.0006901226006448269\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 17450.0\n",
      "      td_error: [0.0024834871292114258, 0.0024834871292114258, 0.0033530890941619873,\n",
      "        0.0024834871292114258, 0.002202451229095459, 0.0007131993770599365, 0.005669832229614258,\n",
      "        0.0029439926147460938, -0.0008956491947174072, 0.0007131993770599365, 0.002191901206970215,\n",
      "        -0.0021963119506835938, -0.0065743327140808105, 0.005669832229614258, -0.004173606634140015,\n",
      "        -0.005168735980987549, 0.0033530890941619873, -0.0014459490776062012, -0.007132738828659058,\n",
      "        -0.007132738828659058, -0.0014459490776062012, -0.0021421611309051514, -0.0043773651123046875,\n",
      "        0.0007131993770599365, 0.004941344261169434, 0.0033530890941619873, -0.009003818035125732,\n",
      "        -0.0014459490776062012, -0.004173606634140015, -0.00983339548110962, -0.0014459490776062012,\n",
      "        0.0029439926147460938, 0.0007131993770599365, -0.004173606634140015, 0.001977860927581787,\n",
      "        0.0029180943965911865, -0.0043773651123046875, -0.0021963119506835938, -0.0014459490776062012,\n",
      "        -0.004173606634140015, -0.004173606634140015, -0.0014459490776062012, 0.0007131993770599365,\n",
      "        0.0007131993770599365, -0.008054584264755249, 0.0007131993770599365, 0.0033530890941619873,\n",
      "        -0.000589907169342041, 0.005669832229614258, -0.0018621087074279785, 0.0033530890941619873,\n",
      "        0.0016684532165527344, 0.0029180943965911865, 0.0007131993770599365, 0.0024834871292114258,\n",
      "        -0.004173606634140015, -0.0043773651123046875, -0.0014459490776062012, 0.0033530890941619873,\n",
      "        -0.0029142796993255615, -0.007132738828659058, -0.004173606634140015, 0.0007131993770599365,\n",
      "        0.0029439926147460938]\n",
      "  num_agent_steps_sampled: 35000\n",
      "  num_agent_steps_trained: 1116800\n",
      "  num_env_steps_sampled: 35000\n",
      "  num_env_steps_trained: 1116800\n",
      "  num_target_updates: 70\n",
      "iterations_since_restore: 35\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 35000\n",
      "num_agent_steps_trained: 1116800\n",
      "num_env_steps_sampled: 35000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.6800553219112\n",
      "num_env_steps_trained: 1116800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 373.7617703011584\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.636363636363635\n",
      "  ram_util_percent: 60.645454545454555\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2449.2727885246277\n",
      "time_this_iter_s: 85.63695788383484\n",
      "time_total_s: 2449.2727885246277\n",
      "timers:\n",
      "  learn_throughput: 5686.999\n",
      "  learn_time_ms: 11.254\n",
      "  load_throughput: 441650.964\n",
      "  load_time_ms: 0.145\n",
      "  sample_time_ms: 144.661\n",
      "  synch_weights_time_ms: 4.972\n",
      "  training_iteration_time_ms: 173.761\n",
      "timestamp: 1709833145\n",
      "timesteps_total: 35000\n",
      "training_iteration: 35\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 97x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 164x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 36000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 36000\n",
      "  num_agent_steps_sampled: 36000\n",
      "  num_agent_steps_trained: 1148800\n",
      "  num_env_steps_sampled: 36000\n",
      "  num_env_steps_trained: 1148800\n",
      "  num_target_updates: 72\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-40-01\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 36000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 17949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.005392635241150856\n",
      "        max_q: 0.3672082722187042\n",
      "        mean_q: 0.3504972755908966\n",
      "        min_q: 0.33803603053092957\n",
      "      mean_td_error: -0.004150641616433859\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 17950.0\n",
      "      td_error: [-0.010768800973892212, -0.010768800973892212, -0.003187328577041626,\n",
      "        -0.010768800973892212, -0.012301266193389893, 0.011321455240249634, -0.011907309293746948,\n",
      "        -0.0050747692584991455, 0.011320561170578003, -0.014442622661590576, -0.012301266193389893,\n",
      "        -0.00037720799446105957, -2.3066997528076172e-05, -0.0050747692584991455,\n",
      "        -0.0037303566932678223, 0.014488399028778076, 0.0009118318557739258, -0.010768800973892212,\n",
      "        0.011321455240249634, -0.010768800973892212, -0.010768800973892212, -0.006865262985229492,\n",
      "        -0.013948589563369751, -0.010768800973892212, -8.0108642578125e-05, -0.003187328577041626,\n",
      "        -0.012301266193389893, -0.014442622661590576, 0.011321455240249634, -2.3066997528076172e-05,\n",
      "        0.01244470477104187, -0.010768800973892212, -0.008651763200759888, 0.011527657508850098,\n",
      "        -0.014442622661590576, 0.011321455240249634, -0.0037303566932678223, -0.010768800973892212,\n",
      "        -0.014442622661590576, 0.011321455240249634, -0.010768800973892212, 0.00030687451362609863,\n",
      "        -0.012301266193389893, -0.006865262985229492, 0.0009118318557739258, 0.011527657508850098,\n",
      "        -0.011907309293746948, 0.011527657508850098, -0.010768800973892212, 0.011321455240249634,\n",
      "        -0.006865262985229492, -0.010768800973892212, -0.010768800973892212, 0.01244470477104187,\n",
      "        -0.011666089296340942, 0.011527657508850098, -0.0022316277027130127, -0.0050747692584991455,\n",
      "        -0.0128268301486969, -0.010768800973892212, -0.010285615921020508, -0.014442622661590576,\n",
      "        -0.014442622661590576, -0.012301266193389893]\n",
      "  num_agent_steps_sampled: 36000\n",
      "  num_agent_steps_trained: 1148800\n",
      "  num_env_steps_sampled: 36000\n",
      "  num_env_steps_trained: 1148800\n",
      "  num_target_updates: 72\n",
      "iterations_since_restore: 36\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 36000\n",
      "num_agent_steps_trained: 1148800\n",
      "num_env_steps_sampled: 36000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.896962663505857\n",
      "num_env_steps_trained: 1148800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 572.7028052321874\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 14.188607594936707\n",
      "  ram_util_percent: 60.69620253164556\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2505.167427301407\n",
      "time_this_iter_s: 55.894638776779175\n",
      "time_total_s: 2505.167427301407\n",
      "timers:\n",
      "  learn_throughput: 6440.483\n",
      "  learn_time_ms: 9.937\n",
      "  load_throughput: 826718.374\n",
      "  load_time_ms: 0.077\n",
      "  sample_time_ms: 27.601\n",
      "  synch_weights_time_ms: 3.183\n",
      "  training_iteration_time_ms: 50.511\n",
      "timestamp: 1709833201\n",
      "timesteps_total: 36000\n",
      "training_iteration: 36\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 199x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 204x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 203x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 37000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 37000\n",
      "  num_agent_steps_sampled: 37000\n",
      "  num_agent_steps_trained: 1180800\n",
      "  num_env_steps_sampled: 37000\n",
      "  num_env_steps_trained: 1180800\n",
      "  num_target_updates: 74\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-40-26\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 37000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 18449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0025905126240104437\n",
      "        max_q: 0.396148681640625\n",
      "        mean_q: 0.36042335629463196\n",
      "        min_q: 0.3473011255264282\n",
      "      mean_td_error: -0.0007336437702178955\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 18450.0\n",
      "      td_error: [-0.007474303245544434, -0.008835554122924805, 0.007318347692489624,\n",
      "        -0.0010571777820587158, -0.007474303245544434, 0.0015698671340942383, -0.0010571777820587158,\n",
      "        0.009323060512542725, -0.008942365646362305, 0.009323060512542725, -0.008130460977554321,\n",
      "        -0.008835554122924805, 0.0071325600147247314, -0.007474303245544434, -0.00033539533615112305,\n",
      "        -0.008144199848175049, -0.004855304956436157, -0.0010571777820587158, -0.008642911911010742,\n",
      "        0.004385828971862793, -0.008835554122924805, -0.008835554122924805, -0.008835554122924805,\n",
      "        0.004385828971862793, 0.0015698671340942383, 0.007318347692489624, -0.009144365787506104,\n",
      "        0.0018975436687469482, -0.007475167512893677, -0.0010571777820587158, 0.0018975436687469482,\n",
      "        -0.007475167512893677, -0.0014121830463409424, -0.007474303245544434, 0.0071325600147247314,\n",
      "        -0.008835554122924805, 0.008980721235275269, -0.00033539533615112305, 0.033484458923339844,\n",
      "        0.004385828971862793, 0.0015698671340942383, 0.009323060512542725, -0.001389831304550171,\n",
      "        0.007318347692489624, -0.007474303245544434, 0.004385828971862793, 0.007318347692489624,\n",
      "        -0.00033539533615112305, 0.0015698671340942383, 0.007318347692489624, -0.008942365646362305,\n",
      "        0.0003465116024017334, -0.009144365787506104, -0.008835554122924805, -0.00033539533615112305,\n",
      "        0.007318347692489624, -0.008835554122924805, 0.007318347692489624, -0.005662262439727783,\n",
      "        -0.007474303245544434, 0.007318347692489624, 0.0008291304111480713, -0.007474303245544434,\n",
      "        -0.0010571777820587158]\n",
      "  num_agent_steps_sampled: 37000\n",
      "  num_agent_steps_trained: 1180800\n",
      "  num_env_steps_sampled: 37000\n",
      "  num_env_steps_trained: 1180800\n",
      "  num_target_updates: 74\n",
      "iterations_since_restore: 37\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 37000\n",
      "num_agent_steps_trained: 1180800\n",
      "num_env_steps_sampled: 37000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.40013481121414\n",
      "num_env_steps_trained: 1180800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1260.8043139588524\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 25.605555555555558\n",
      "  ram_util_percent: 60.294444444444444\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2530.5659413337708\n",
      "time_this_iter_s: 25.39851403236389\n",
      "time_total_s: 2530.5659413337708\n",
      "timers:\n",
      "  learn_throughput: 6322.123\n",
      "  learn_time_ms: 10.123\n",
      "  load_throughput: 735641.151\n",
      "  load_time_ms: 0.087\n",
      "  sample_time_ms: 27.164\n",
      "  synch_weights_time_ms: 2.975\n",
      "  training_iteration_time_ms: 50.056\n",
      "timestamp: 1709833226\n",
      "timesteps_total: 37000\n",
      "training_iteration: 37\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 204x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 197x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 203x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 198x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 38000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 38000\n",
      "  num_agent_steps_sampled: 38000\n",
      "  num_agent_steps_trained: 1212800\n",
      "  num_env_steps_sampled: 38000\n",
      "  num_env_steps_trained: 1212800\n",
      "  num_target_updates: 76\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-40-52\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 38000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 18949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0020523718558251858\n",
      "        max_q: 0.3737589120864868\n",
      "        mean_q: 0.36297115683555603\n",
      "        min_q: 0.3452971577644348\n",
      "      mean_td_error: 0.0018270313739776611\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 18950.0\n",
      "      td_error: [0.004075437784194946, -0.006310760974884033, -0.006310760974884033,\n",
      "        0.005092918872833252, 0.009708583354949951, 0.008231818675994873, 0.0046086907386779785,\n",
      "        0.0046086907386779785, 0.0069498419761657715, 0.0046086907386779785, 0.001182258129119873,\n",
      "        0.001528233289718628, 0.001528233289718628, -0.009138405323028564, 0.0044155120849609375,\n",
      "        0.0015603899955749512, 0.005092918872833252, 0.007562071084976196, -0.006310760974884033,\n",
      "        -0.009138405323028564, 0.0029061436653137207, -0.006310760974884033, 0.001528233289718628,\n",
      "        0.00590592622756958, 0.003407508134841919, 0.0030894875526428223, 0.0046086907386779785,\n",
      "        -0.006472587585449219, 0.008231818675994873, -0.006310760974884033, 0.008231818675994873,\n",
      "        0.008231818675994873, 0.00590592622756958, 7.56978988647461e-05, -0.006310760974884033,\n",
      "        0.001182258129119873, 0.008164435625076294, 0.008231818675994873, 0.0030894875526428223,\n",
      "        0.0010417401790618896, 7.56978988647461e-05, -0.006310760974884033, 0.0046086907386779785,\n",
      "        0.008231818675994873, 0.0028200745582580566, 0.00590592622756958, 0.0029061436653137207,\n",
      "        0.008231818675994873, -0.0009099841117858887, 0.0029061436653137207, 0.009708583354949951,\n",
      "        0.005039781332015991, 7.56978988647461e-05, -0.006752908229827881, 0.0046086907386779785,\n",
      "        -0.006310760974884033, -0.006310760974884033, 7.56978988647461e-05, 0.008164435625076294,\n",
      "        -0.0017090141773223877, 0.001528233289718628, 7.56978988647461e-05, 0.0046086907386779785,\n",
      "        -0.006310760974884033]\n",
      "  num_agent_steps_sampled: 38000\n",
      "  num_agent_steps_trained: 1212800\n",
      "  num_env_steps_sampled: 38000\n",
      "  num_env_steps_trained: 1212800\n",
      "  num_target_updates: 76\n",
      "iterations_since_restore: 38\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 38000\n",
      "num_agent_steps_trained: 1212800\n",
      "num_env_steps_sampled: 38000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.500802550289855\n",
      "num_env_steps_trained: 1212800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1264.0256816092754\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 24.73055555555555\n",
      "  ram_util_percent: 60.30000000000002\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2555.89972448349\n",
      "time_this_iter_s: 25.33378314971924\n",
      "time_total_s: 2555.89972448349\n",
      "timers:\n",
      "  learn_throughput: 6365.495\n",
      "  learn_time_ms: 10.054\n",
      "  load_throughput: 819900.599\n",
      "  load_time_ms: 0.078\n",
      "  sample_time_ms: 26.954\n",
      "  synch_weights_time_ms: 3.025\n",
      "  training_iteration_time_ms: 49.996\n",
      "timestamp: 1709833252\n",
      "timesteps_total: 38000\n",
      "training_iteration: 38\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 39000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 39000\n",
      "  num_agent_steps_sampled: 39000\n",
      "  num_agent_steps_trained: 1244800\n",
      "  num_env_steps_sampled: 39000\n",
      "  num_env_steps_trained: 1244800\n",
      "  num_target_updates: 78\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-41-17\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 39000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 19449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0020056264474987984\n",
      "        max_q: 0.3831375539302826\n",
      "        mean_q: 0.3716277480125427\n",
      "        min_q: 0.36310985684394836\n",
      "      mean_td_error: 0.002563037443906069\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 19450.0\n",
      "      td_error: [-0.0025841593742370605, 0.0110379159450531, 0.003112882375717163,\n",
      "        0.0012104809284210205, 0.0110379159450531, 0.0006064474582672119, 0.008971154689788818,\n",
      "        0.0110379159450531, 0.0006850957870483398, 0.0012104809284210205, 0.0006064474582672119,\n",
      "        -0.0025841593742370605, 0.0012104809284210205, 0.0013838708400726318, 0.0006850957870483398,\n",
      "        0.0012104809284210205, 0.004526019096374512, 0.003112882375717163, -0.00010535120964050293,\n",
      "        -0.00040858983993530273, 0.0006064474582672119, 0.005247741937637329, 0.0006064474582672119,\n",
      "        -0.002861320972442627, -0.0025841593742370605, 0.0012104809284210205, -0.00010535120964050293,\n",
      "        -0.0025841593742370605, -0.0023246407508850098, 0.0006064474582672119, 0.0030815303325653076,\n",
      "        0.0110379159450531, 0.0006064474582672119, -0.008469700813293457, 0.0013838708400726318,\n",
      "        0.0110379159450531, 0.00585290789604187, 0.02314057946205139, 0.0110379159450531,\n",
      "        -0.0006421208381652832, 0.004749476909637451, 0.0006064474582672119, 0.0060159265995025635,\n",
      "        -0.0020688772201538086, 0.004305541515350342, 0.0006850957870483398, 0.0006064474582672119,\n",
      "        0.00221937894821167, 0.0024913251399993896, 0.004305541515350342, 0.009823620319366455,\n",
      "        0.010142356157302856, 0.007705718278884888, 0.0006850957870483398, 0.0013838708400726318,\n",
      "        -0.0025841593742370605, -0.0025841593742370605, -0.0025841593742370605, -0.0025841593742370605,\n",
      "        0.0006064474582672119, 0.0006850957870483398, 0.0012104809284210205, 0.0018375217914581299,\n",
      "        0.004526019096374512]\n",
      "  num_agent_steps_sampled: 39000\n",
      "  num_agent_steps_trained: 1244800\n",
      "  num_env_steps_sampled: 39000\n",
      "  num_env_steps_trained: 1244800\n",
      "  num_target_updates: 78\n",
      "iterations_since_restore: 39\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 39000\n",
      "num_agent_steps_trained: 1244800\n",
      "num_env_steps_sampled: 39000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.36177730412765\n",
      "num_env_steps_trained: 1244800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1259.5768737320848\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 24.583783783783787\n",
      "  ram_util_percent: 60.367567567567576\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2581.3224725723267\n",
      "time_this_iter_s: 25.42274808883667\n",
      "time_total_s: 2581.3224725723267\n",
      "timers:\n",
      "  learn_throughput: 6338.844\n",
      "  learn_time_ms: 10.096\n",
      "  load_throughput: 857895.353\n",
      "  load_time_ms: 0.075\n",
      "  sample_time_ms: 27.319\n",
      "  synch_weights_time_ms: 3.022\n",
      "  training_iteration_time_ms: 50.314\n",
      "timestamp: 1709833277\n",
      "timesteps_total: 39000\n",
      "training_iteration: 39\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 204x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 204x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 192x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 40000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 40000\n",
      "  num_agent_steps_sampled: 40000\n",
      "  num_agent_steps_trained: 1276800\n",
      "  num_env_steps_sampled: 40000\n",
      "  num_env_steps_trained: 1276800\n",
      "  num_target_updates: 80\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-41-43\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 40000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 19949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.001110588782466948\n",
      "        max_q: 0.388935923576355\n",
      "        mean_q: 0.38198092579841614\n",
      "        min_q: 0.3680419623851776\n",
      "      mean_td_error: -0.0009740027599036694\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 19950.0\n",
      "      td_error: [0.0003008842468261719, 0.001907646656036377, -0.0012403428554534912,\n",
      "        -1.3649463653564453e-05, -0.004509180784225464, -0.003615260124206543, -0.0012403428554534912,\n",
      "        -0.003615260124206543, -0.0012403428554534912, -0.003615260124206543, 0.002183586359024048,\n",
      "        0.00011229515075683594, -1.3649463653564453e-05, -1.3649463653564453e-05,\n",
      "        0.0031486153602600098, -3.8951635360717773e-05, 0.001907646656036377, 0.004121303558349609,\n",
      "        -0.00021699070930480957, -0.00021699070930480957, -0.003615260124206543, -1.3649463653564453e-05,\n",
      "        -0.003615260124206543, 0.001907646656036377, 0.0008228421211242676, 0.0002904534339904785,\n",
      "        0.00011271238327026367, -0.003615260124206543, 0.0008228421211242676, 0.0002904534339904785,\n",
      "        0.00011229515075683594, -0.003615260124206543, -0.00021699070930480957, 0.00013399124145507812,\n",
      "        0.0016391873359680176, 0.001907646656036377, 0.001907646656036377, 0.00011229515075683594,\n",
      "        0.00011229515075683594, -0.003615260124206543, -0.003615260124206543, -0.04445755481719971,\n",
      "        0.00011229515075683594, -1.3649463653564453e-05, 0.001907646656036377, -0.004509180784225464,\n",
      "        -1.3649463653564453e-05, 0.001907646656036377, 0.002183586359024048, 0.0012542009353637695,\n",
      "        -0.004325836896896362, 0.0008228421211242676, 0.00011229515075683594, 0.004121303558349609,\n",
      "        -1.3649463653564453e-05, 0.0012542009353637695, -0.0008576810359954834, 0.00011229515075683594,\n",
      "        0.001907646656036377, 0.0008228421211242676, 0.0008228421211242676, 0.0008228421211242676,\n",
      "        -0.004325836896896362, -0.004325836896896362]\n",
      "  num_agent_steps_sampled: 40000\n",
      "  num_agent_steps_trained: 1276800\n",
      "  num_env_steps_sampled: 40000\n",
      "  num_env_steps_trained: 1276800\n",
      "  num_target_updates: 80\n",
      "iterations_since_restore: 40\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 40000\n",
      "num_agent_steps_trained: 1276800\n",
      "num_env_steps_sampled: 40000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.172098949880926\n",
      "num_env_steps_trained: 1276800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1253.5071663961896\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 25.144444444444442\n",
      "  ram_util_percent: 60.53055555555555\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2606.8690145015717\n",
      "time_this_iter_s: 25.546541929244995\n",
      "time_total_s: 2606.8690145015717\n",
      "timers:\n",
      "  learn_throughput: 6414.627\n",
      "  learn_time_ms: 9.977\n",
      "  load_throughput: 672096.785\n",
      "  load_time_ms: 0.095\n",
      "  sample_time_ms: 27.826\n",
      "  synch_weights_time_ms: 3.055\n",
      "  training_iteration_time_ms: 50.991\n",
      "timestamp: 1709833303\n",
      "timesteps_total: 40000\n",
      "training_iteration: 40\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 41000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 41000\n",
      "  num_agent_steps_sampled: 41000\n",
      "  num_agent_steps_trained: 1308800\n",
      "  num_env_steps_sampled: 41000\n",
      "  num_env_steps_trained: 1308800\n",
      "  num_target_updates: 82\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-42-08\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 41000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 20449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0017692451365292072\n",
      "        max_q: 0.38845571875572205\n",
      "        mean_q: 0.37944406270980835\n",
      "        min_q: 0.36254939436912537\n",
      "      mean_td_error: -0.004828981123864651\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 20450.0\n",
      "      td_error: [-0.0077530741691589355, 0.0016629993915557861, -0.002557694911956787,\n",
      "        -0.015729159116744995, -0.005450993776321411, -0.008964240550994873, -0.005653351545333862,\n",
      "        -0.0016335546970367432, -0.0077530741691589355, -0.005298256874084473, -0.005835205316543579,\n",
      "        -0.008964240550994873, -0.017676591873168945, -0.006813377141952515, -0.003330141305923462,\n",
      "        0.001982271671295166, 0.001576155424118042, -0.008964240550994873, -0.008964240550994873,\n",
      "        -0.006813377141952515, 0.0016629993915557861, -0.0030882656574249268, -0.0021930336952209473,\n",
      "        -0.0077530741691589355, -0.01216655969619751, -0.005835205316543579, -0.0016335546970367432,\n",
      "        -0.006813377141952515, -0.0025548040866851807, -0.010383307933807373, -0.008964240550994873,\n",
      "        0.0016629993915557861, -0.0021930336952209473, -0.005835205316543579, 0.0016629993915557861,\n",
      "        -0.005450993776321411, -0.017676591873168945, -0.0009328722953796387, -0.0077530741691589355,\n",
      "        0.0016629993915557861, -0.0077530741691589355, -0.006813377141952515, -0.008964240550994873,\n",
      "        -0.008964240550994873, 0.0016629993915557861, -0.002557694911956787, -0.005835205316543579,\n",
      "        -0.010498881340026855, -0.01292833685874939, 0.0016629993915557861, 0.0016629993915557861,\n",
      "        -0.005796372890472412, -0.0021930336952209473, -0.010383307933807373, -0.0021930336952209473,\n",
      "        0.0016629993915557861, -0.005835205316543579, -0.0077530741691589355, -0.002557694911956787,\n",
      "        0.001576155424118042, -0.0021930336952209473, 0.0016629993915557861, 0.003975480794906616,\n",
      "        -0.0021930336952209473]\n",
      "  num_agent_steps_sampled: 41000\n",
      "  num_agent_steps_trained: 1308800\n",
      "  num_env_steps_sampled: 41000\n",
      "  num_env_steps_trained: 1308800\n",
      "  num_target_updates: 82\n",
      "iterations_since_restore: 41\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 41000\n",
      "num_agent_steps_trained: 1308800\n",
      "num_env_steps_sampled: 41000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.26092371468359\n",
      "num_env_steps_trained: 1308800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1256.349558869875\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 25.769444444444442\n",
      "  ram_util_percent: 60.458333333333336\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2632.357634305954\n",
      "time_this_iter_s: 25.488619804382324\n",
      "time_total_s: 2632.357634305954\n",
      "timers:\n",
      "  learn_throughput: 6399.381\n",
      "  learn_time_ms: 10.001\n",
      "  load_throughput: 830041.608\n",
      "  load_time_ms: 0.077\n",
      "  sample_time_ms: 27.943\n",
      "  synch_weights_time_ms: 3.048\n",
      "  training_iteration_time_ms: 50.901\n",
      "timestamp: 1709833328\n",
      "timesteps_total: 41000\n",
      "training_iteration: 41\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 204x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 198x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 42000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 42000\n",
      "  num_agent_steps_sampled: 42000\n",
      "  num_agent_steps_trained: 1340800\n",
      "  num_env_steps_sampled: 42000\n",
      "  num_env_steps_trained: 1340800\n",
      "  num_target_updates: 84\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-42-34\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 42000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 20949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.002410422544926405\n",
      "        max_q: 0.3984551429748535\n",
      "        mean_q: 0.3907965421676636\n",
      "        min_q: 0.3724864423274994\n",
      "      mean_td_error: 0.009513759054243565\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 20950.0\n",
      "      td_error: [0.0009258687496185303, 0.0030577480792999268, 0.002690613269805908,\n",
      "        0.0030577480792999268, 0.002399444580078125, 0.017252624034881592, 0.005656778812408447,\n",
      "        0.00417405366897583, 0.006207674741744995, 0.00021445751190185547, 0.0072043538093566895,\n",
      "        0.00417405366897583, 0.006645470857620239, 0.002977430820465088, 0.006645470857620239,\n",
      "        0.00417405366897583, 0.002391517162322998, 0.006356239318847656, 0.3838491439819336,\n",
      "        0.0030577480792999268, 0.008063137531280518, 0.00021445751190185547, 0.0030577480792999268,\n",
      "        0.0030577480792999268, 0.000344008207321167, 0.006356239318847656, 0.000344008207321167,\n",
      "        0.006645470857620239, 0.008063137531280518, 0.00021445751190185547, -0.005762994289398193,\n",
      "        0.0030577480792999268, 0.006356239318847656, 0.00417405366897583, 0.006645470857620239,\n",
      "        0.00417405366897583, 0.0030577480792999268, 0.0030577480792999268, 0.006645470857620239,\n",
      "        0.0030577480792999268, 0.002690613269805908, 0.006645470857620239, 0.006645470857620239,\n",
      "        0.00417405366897583, 0.004174321889877319, 0.006645470857620239, -0.015198975801467896,\n",
      "        0.00417405366897583, 0.00935453176498413, 0.00417405366897583, 0.00417405366897583,\n",
      "        0.002391517162322998, 0.00021445751190185547, 0.006645470857620239, 0.00021445751190185547,\n",
      "        -0.0015350282192230225, 0.00417405366897583, 0.00021445751190185547, 0.002690613269805908,\n",
      "        0.006645470857620239, 0.00021445751190185547, -0.0030241310596466064, 0.00021445751190185547,\n",
      "        0.008231043815612793]\n",
      "  num_agent_steps_sampled: 42000\n",
      "  num_agent_steps_trained: 1340800\n",
      "  num_env_steps_sampled: 42000\n",
      "  num_env_steps_trained: 1340800\n",
      "  num_target_updates: 84\n",
      "iterations_since_restore: 42\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 42000\n",
      "num_agent_steps_trained: 1340800\n",
      "num_env_steps_sampled: 42000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.17286467254004\n",
      "num_env_steps_trained: 1340800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1253.5316695212812\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 24.344444444444445\n",
      "  ram_util_percent: 60.425000000000004\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2657.9048631191254\n",
      "time_this_iter_s: 25.547228813171387\n",
      "time_total_s: 2657.9048631191254\n",
      "timers:\n",
      "  learn_throughput: 6436.082\n",
      "  learn_time_ms: 9.944\n",
      "  load_throughput: 661496.934\n",
      "  load_time_ms: 0.097\n",
      "  sample_time_ms: 28.039\n",
      "  synch_weights_time_ms: 9.102\n",
      "  training_iteration_time_ms: 57.156\n",
      "timestamp: 1709833354\n",
      "timesteps_total: 42000\n",
      "training_iteration: 42\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 192x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 43000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 43000\n",
      "  num_agent_steps_sampled: 43000\n",
      "  num_agent_steps_trained: 1372800\n",
      "  num_env_steps_sampled: 43000\n",
      "  num_env_steps_trained: 1372800\n",
      "  num_target_updates: 86\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-42-59\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 43000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 21449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0006191912107169628\n",
      "        max_q: 0.4026201367378235\n",
      "        mean_q: 0.3992297351360321\n",
      "        min_q: 0.39109933376312256\n",
      "      mean_td_error: -0.0004627760499715805\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 21450.0\n",
      "      td_error: [-0.0018555819988250732, -0.0013977289199829102, 0.00048172473907470703,\n",
      "        0.002294570207595825, -0.0017940700054168701, 0.00048172473907470703, -0.00026616454124450684,\n",
      "        -0.0006318986415863037, -0.0006318986415863037, 0.0012399554252624512, 0.00048172473907470703,\n",
      "        0.0012399554252624512, -0.0018555819988250732, 0.0014029443264007568, 0.0012399554252624512,\n",
      "        -0.0024957358837127686, 0.0012399554252624512, -0.0018555819988250732, 0.0012399554252624512,\n",
      "        0.0012399554252624512, -0.005077719688415527, 0.00048172473907470703, -0.0018555819988250732,\n",
      "        0.0012690722942352295, -0.0033173561096191406, -0.0006318986415863037, -0.0036025047302246094,\n",
      "        -0.0006318986415863037, 0.00048172473907470703, -0.0031059682369232178, -0.0006318986415863037,\n",
      "        -0.0031059682369232178, 0.003943055868148804, 0.00048172473907470703, -0.0018555819988250732,\n",
      "        0.0012399554252624512, 0.00048172473907470703, -0.0006318986415863037, -0.006043583154678345,\n",
      "        0.0014029443264007568, -0.0006318986415863037, -0.00026616454124450684, -0.0022935569286346436,\n",
      "        -0.0023304522037506104, -0.0012271702289581299, -0.0018555819988250732, -0.0013977289199829102,\n",
      "        0.002294570207595825, -0.0024957358837127686, 0.003943055868148804, -0.006043583154678345,\n",
      "        0.003943055868148804, -0.0018555819988250732, 0.004480540752410889, -0.0024957358837127686,\n",
      "        -0.0006318986415863037, -0.0006025135517120361, -0.0006318986415863037, -0.0024957358837127686,\n",
      "        0.003943055868148804, 0.0005759298801422119, 0.002294570207595825, -0.0022935569286346436,\n",
      "        -0.0006318986415863037]\n",
      "  num_agent_steps_sampled: 43000\n",
      "  num_agent_steps_trained: 1372800\n",
      "  num_env_steps_sampled: 43000\n",
      "  num_env_steps_trained: 1372800\n",
      "  num_target_updates: 86\n",
      "iterations_since_restore: 43\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 43000\n",
      "num_agent_steps_trained: 1372800\n",
      "num_env_steps_sampled: 43000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.21385930883243\n",
      "num_env_steps_trained: 1372800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1254.8434978826378\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 24.589189189189188\n",
      "  ram_util_percent: 60.508108108108104\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2683.423674106598\n",
      "time_this_iter_s: 25.518810987472534\n",
      "time_total_s: 2683.423674106598\n",
      "timers:\n",
      "  learn_throughput: 6417.955\n",
      "  learn_time_ms: 9.972\n",
      "  load_throughput: 770038.6\n",
      "  load_time_ms: 0.083\n",
      "  sample_time_ms: 27.515\n",
      "  synch_weights_time_ms: 3.08\n",
      "  training_iteration_time_ms: 50.624\n",
      "timestamp: 1709833379\n",
      "timesteps_total: 43000\n",
      "training_iteration: 43\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 204x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 44000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 44000\n",
      "  num_agent_steps_sampled: 44000\n",
      "  num_agent_steps_trained: 1404800\n",
      "  num_env_steps_sampled: 44000\n",
      "  num_env_steps_trained: 1404800\n",
      "  num_target_updates: 88\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-43-25\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 44000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 21949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0012911171652376652\n",
      "        max_q: 0.4095599055290222\n",
      "        mean_q: 0.39832669496536255\n",
      "        min_q: 0.38868317008018494\n",
      "      mean_td_error: 0.00014102552086114883\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 21950.0\n",
      "      td_error: [-0.0018042922019958496, -0.0006735622882843018, 0.00011786818504333496,\n",
      "        -0.002629786729812622, -0.0014140307903289795, -0.0013675391674041748, -0.00016921758651733398,\n",
      "        -0.00016921758651733398, -0.003859400749206543, -0.0013033747673034668, -0.002629786729812622,\n",
      "        -0.003054499626159668, -0.001453489065170288, 0.00011786818504333496, -0.002629786729812622,\n",
      "        -0.00016921758651733398, 0.00011786818504333496, 0.00011786818504333496, -0.002629786729812622,\n",
      "        0.00011786818504333496, 0.004979044198989868, -0.002629786729812622, -0.0013042688369750977,\n",
      "        0.006857424974441528, -0.0013675391674041748, -0.002629786729812622, -0.00016921758651733398,\n",
      "        0.00011786818504333496, 0.004979044198989868, -0.000984787940979004, -0.00016921758651733398,\n",
      "        -0.0013675391674041748, 0.004979044198989868, 0.004979044198989868, -0.00023421645164489746,\n",
      "        0.011079400777816772, -0.002629786729812622, -0.0025130808353424072, 0.004979044198989868,\n",
      "        -0.002629786729812622, 0.004979044198989868, -0.003054499626159668, 0.004979044198989868,\n",
      "        0.004979044198989868, 0.004979044198989868, -0.0009436607360839844, 0.00022852420806884766,\n",
      "        -0.0013675391674041748, -0.00016921758651733398, 0.004979044198989868, -0.0005559921264648438,\n",
      "        -0.000984787940979004, -0.0014399290084838867, 0.0004836618900299072, -0.0012490451335906982,\n",
      "        -0.012079089879989624, 0.004979044198989868, -0.0022581517696380615, -0.002629786729812622,\n",
      "        0.00011786818504333496, -0.0013675391674041748, -0.002629786729812622, 0.004979044198989868,\n",
      "        0.005118042230606079]\n",
      "  num_agent_steps_sampled: 44000\n",
      "  num_agent_steps_trained: 1404800\n",
      "  num_env_steps_sampled: 44000\n",
      "  num_env_steps_trained: 1404800\n",
      "  num_target_updates: 88\n",
      "iterations_since_restore: 44\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 44000\n",
      "num_agent_steps_trained: 1404800\n",
      "num_env_steps_sampled: 44000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 39.221981682118596\n",
      "num_env_steps_trained: 1404800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 1255.103413827795\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 24.741666666666664\n",
      "  ram_util_percent: 60.57222222222221\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2708.937893152237\n",
      "time_this_iter_s: 25.514219045639038\n",
      "time_total_s: 2708.937893152237\n",
      "timers:\n",
      "  learn_throughput: 6340.715\n",
      "  learn_time_ms: 10.093\n",
      "  load_throughput: 753820.432\n",
      "  load_time_ms: 0.085\n",
      "  sample_time_ms: 27.98\n",
      "  synch_weights_time_ms: 3.105\n",
      "  training_iteration_time_ms: 51.153\n",
      "timestamp: 1709833405\n",
      "timesteps_total: 44000\n",
      "training_iteration: 44\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 200x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 143x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 45000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 45000\n",
      "  num_agent_steps_sampled: 45000\n",
      "  num_agent_steps_trained: 1436800\n",
      "  num_env_steps_sampled: 45000\n",
      "  num_env_steps_trained: 1436800\n",
      "  num_target_updates: 90\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-44-35\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 45000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 22449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.00213381159119308\n",
      "        max_q: 0.40382906794548035\n",
      "        mean_q: 0.39794570207595825\n",
      "        min_q: 0.3827630281448364\n",
      "      mean_td_error: -0.0021368470042943954\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 22450.0\n",
      "      td_error: [-0.009256899356842041, -0.005979716777801514, -0.005979716777801514,\n",
      "        0.003012746572494507, 0.0020699501037597656, 0.0008755624294281006, -0.007779449224472046,\n",
      "        -0.009001225233078003, 0.0016637146472930908, -0.007857978343963623, -0.007779449224472046,\n",
      "        0.0024024248123168945, 0.00042304396629333496, -0.005979716777801514, -0.005979716777801514,\n",
      "        -0.008901745080947876, -0.009001225233078003, 0.0025312602519989014, 0.0025312602519989014,\n",
      "        -0.005979716777801514, 0.003012746572494507, -0.01172792911529541, 0.0020699501037597656,\n",
      "        0.0025312602519989014, -0.0016989707946777344, -0.011393606662750244, 0.0005324184894561768,\n",
      "        -0.009001225233078003, 0.0020699501037597656, 0.002502530813217163, -0.005979716777801514,\n",
      "        0.002502530813217163, -0.005979716777801514, 0.0025312602519989014, -0.00750085711479187,\n",
      "        0.003012746572494507, 0.002502530813217163, 0.0024024248123168945, -0.005979716777801514,\n",
      "        0.0005324184894561768, 0.0008755624294281006, 0.0025312602519989014, -0.008808910846710205,\n",
      "        0.002502530813217163, -0.005979716777801514, 0.00203743577003479, -0.010501623153686523,\n",
      "        -0.009001225233078003, 0.0015127360820770264, 0.0024024248123168945, -0.007779449224472046,\n",
      "        0.0005324184894561768, 0.002502530813217163, 0.0024024248123168945, 0.003012746572494507,\n",
      "        0.0025312602519989014, -0.005979716777801514, 0.0024024248123168945, 0.002502530813217163,\n",
      "        0.0024024248123168945, -0.009001225233078003, 0.002502530813217163, -0.005979716777801514,\n",
      "        0.0006456971168518066]\n",
      "  num_agent_steps_sampled: 45000\n",
      "  num_agent_steps_trained: 1436800\n",
      "  num_env_steps_sampled: 45000\n",
      "  num_env_steps_trained: 1436800\n",
      "  num_target_updates: 90\n",
      "iterations_since_restore: 45\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 45000\n",
      "num_agent_steps_trained: 1436800\n",
      "num_env_steps_sampled: 45000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 14.135442191145062\n",
      "num_env_steps_trained: 1436800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 452.334150116642\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 12.390099009900991\n",
      "  ram_util_percent: 60.70099009900993\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2779.6995871067047\n",
      "time_this_iter_s: 70.76169395446777\n",
      "time_total_s: 2779.6995871067047\n",
      "timers:\n",
      "  learn_throughput: 5566.625\n",
      "  learn_time_ms: 11.497\n",
      "  load_throughput: 643575.776\n",
      "  load_time_ms: 0.099\n",
      "  sample_time_ms: 141.645\n",
      "  synch_weights_time_ms: 4.72\n",
      "  training_iteration_time_ms: 170.271\n",
      "timestamp: 1709833475\n",
      "timesteps_total: 45000\n",
      "training_iteration: 45\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 46000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 46000\n",
      "  num_agent_steps_sampled: 46000\n",
      "  num_agent_steps_trained: 1468800\n",
      "  num_env_steps_sampled: 46000\n",
      "  num_env_steps_trained: 1468800\n",
      "  num_target_updates: 92\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-46-00\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 46000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 22949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0030904808081686497\n",
      "        max_q: 0.44358155131340027\n",
      "        mean_q: 0.42629069089889526\n",
      "        min_q: 0.4163547158241272\n",
      "      mean_td_error: 0.003346752841025591\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 22950.0\n",
      "      td_error: [0.0054094791412353516, 0.000457763671875, 0.0009286999702453613,\n",
      "        0.001915961503982544, 0.0035280585289001465, 0.0054094791412353516, 0.0035280585289001465,\n",
      "        0.006971806287765503, 0.0026405751705169678, 0.000457763671875, 0.0054094791412353516,\n",
      "        0.0026405751705169678, 0.0054094791412353516, 0.01002568006515503, 0.0009286999702453613,\n",
      "        0.009750723838806152, 0.000457763671875, -0.005474358797073364, 0.009750723838806152,\n",
      "        0.006971806287765503, 0.0066325366497039795, 0.0026405751705169678, -0.0052193403244018555,\n",
      "        0.0026405751705169678, 0.0038631558418273926, 0.000457763671875, 0.009750723838806152,\n",
      "        0.0043829381465911865, 0.0009286999702453613, -0.009012937545776367, 0.0007586777210235596,\n",
      "        -0.005474358797073364, 0.0035280585289001465, 0.0054094791412353516, 0.0035280585289001465,\n",
      "        0.0026405751705169678, 0.0035280585289001465, 0.0035280585289001465, 0.0043829381465911865,\n",
      "        0.0043829381465911865, 0.000457763671875, 0.0009286999702453613, 0.0054094791412353516,\n",
      "        0.0043829381465911865, 0.0026405751705169678, 0.018907129764556885, 0.0007586777210235596,\n",
      "        0.0007586777210235596, 0.009750723838806152, 0.009750723838806152, 0.0026405751705169678,\n",
      "        0.0054094791412353516, 0.009750723838806152, 0.0054094791412353516, 0.009750723838806152,\n",
      "        2.0176172256469727e-05, -0.006466209888458252, 0.0034652352333068848, 0.001915961503982544,\n",
      "        0.007722258567810059, -0.0052193403244018555, 0.0009286999702453613, 0.0011955797672271729,\n",
      "        0.0035280585289001465]\n",
      "  num_agent_steps_sampled: 46000\n",
      "  num_agent_steps_trained: 1468800\n",
      "  num_env_steps_sampled: 46000\n",
      "  num_env_steps_trained: 1468800\n",
      "  num_target_updates: 92\n",
      "iterations_since_restore: 46\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 46000\n",
      "num_agent_steps_trained: 1468800\n",
      "num_env_steps_sampled: 46000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.891261473445335\n",
      "num_env_steps_trained: 1468800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 380.5203671502507\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.336974789915967\n",
      "  ram_util_percent: 60.656302521008435\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2863.812241077423\n",
      "time_this_iter_s: 84.11265397071838\n",
      "time_total_s: 2863.812241077423\n",
      "timers:\n",
      "  learn_throughput: 6184.906\n",
      "  learn_time_ms: 10.348\n",
      "  load_throughput: 741534.409\n",
      "  load_time_ms: 0.086\n",
      "  sample_time_ms: 143.706\n",
      "  synch_weights_time_ms: 3.026\n",
      "  training_iteration_time_ms: 167.733\n",
      "timestamp: 1709833560\n",
      "timesteps_total: 46000\n",
      "training_iteration: 46\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 183x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 101x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 131x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 47000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 47000\n",
      "  num_agent_steps_sampled: 47000\n",
      "  num_agent_steps_trained: 1500800\n",
      "  num_env_steps_sampled: 47000\n",
      "  num_env_steps_trained: 1500800\n",
      "  num_target_updates: 94\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-46-55\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 47000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 23449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0015987955266609788\n",
      "        max_q: 0.43593600392341614\n",
      "        mean_q: 0.4228536784648895\n",
      "        min_q: 0.41372498869895935\n",
      "      mean_td_error: 0.0016523618251085281\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 23450.0\n",
      "      td_error: [0.0055817365646362305, 0.003042548894882202, -0.004122436046600342,\n",
      "        0.0011636018753051758, -0.004162698984146118, 0.0011636018753051758, -0.0029945075511932373,\n",
      "        0.0011135339736938477, 0.0011135339736938477, 0.0002753734588623047, 0.003042548894882202,\n",
      "        0.0002753734588623047, 0.007021963596343994, 0.007021963596343994, 0.0009196698665618896,\n",
      "        -0.0029153525829315186, -0.0015622973442077637, 0.0010462701320648193, 0.003042548894882202,\n",
      "        0.0011135339736938477, -0.004122436046600342, 0.0033841729164123535, 0.0025641024112701416,\n",
      "        0.0002753734588623047, -0.005618274211883545, -0.004122436046600342, 0.0011135339736938477,\n",
      "        0.0025641024112701416, 0.0011636018753051758, 0.0024996399879455566, -0.004162698984146118,\n",
      "        -0.0015622973442077637, 0.0025641024112701416, 0.003042548894882202, 0.003042548894882202,\n",
      "        0.0002753734588623047, 0.003042548894882202, 0.0011135339736938477, 0.0031179487705230713,\n",
      "        0.003042548894882202, 0.0011135339736938477, 0.003042548894882202, 0.01793953776359558,\n",
      "        0.003042548894882202, 0.0024996399879455566, -0.004122436046600342, 0.0033841729164123535,\n",
      "        0.0025641024112701416, 0.007021963596343994, -0.0029588937759399414, 0.003042548894882202,\n",
      "        0.0025641024112701416, 0.0011135339736938477, 0.0031179487705230713, 0.003042548894882202,\n",
      "        0.0069151222705841064, 0.0011135339736938477, 0.0002753734588623047, 0.0025641024112701416,\n",
      "        0.003042548894882202, -0.004122436046600342, 0.007021963596343994, 0.007021963596343994,\n",
      "        0.0011135339736938477]\n",
      "  num_agent_steps_sampled: 47000\n",
      "  num_agent_steps_trained: 1500800\n",
      "  num_env_steps_sampled: 47000\n",
      "  num_env_steps_trained: 1500800\n",
      "  num_target_updates: 94\n",
      "iterations_since_restore: 47\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 47000\n",
      "num_agent_steps_trained: 1500800\n",
      "num_env_steps_sampled: 47000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.907318199885665\n",
      "num_env_steps_trained: 1500800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 573.0341823963413\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 14.99367088607595\n",
      "  ram_util_percent: 60.79240506329114\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2919.674215078354\n",
      "time_this_iter_s: 55.861974000930786\n",
      "time_total_s: 2919.674215078354\n",
      "timers:\n",
      "  learn_throughput: 6418.738\n",
      "  learn_time_ms: 9.971\n",
      "  load_throughput: 860094.38\n",
      "  load_time_ms: 0.074\n",
      "  sample_time_ms: 26.65\n",
      "  synch_weights_time_ms: 3.79\n",
      "  training_iteration_time_ms: 50.359\n",
      "timestamp: 1709833615\n",
      "timesteps_total: 47000\n",
      "training_iteration: 47\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 202x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 192x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 137x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 48000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 48000\n",
      "  num_agent_steps_sampled: 48000\n",
      "  num_agent_steps_trained: 1532800\n",
      "  num_env_steps_sampled: 48000\n",
      "  num_env_steps_trained: 1532800\n",
      "  num_target_updates: 96\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-47-41\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 48000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 23949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.001983669586479664\n",
      "        max_q: 0.43667128682136536\n",
      "        mean_q: 0.4242667555809021\n",
      "        min_q: 0.41841620206832886\n",
      "      mean_td_error: 0.002410577144473791\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 23950.0\n",
      "      td_error: [-0.0005560219287872314, 0.001736372709274292, -0.0013699233531951904,\n",
      "        0.0037553906440734863, 0.005786776542663574, 0.003063976764678955, 0.005526810884475708,\n",
      "        0.003063976764678955, 0.003063976764678955, -0.00033473968505859375, -0.0004615187644958496,\n",
      "        0.005786776542663574, 0.005786776542663574, 0.0026932954788208008, -0.0013699233531951904,\n",
      "        -0.0013699233531951904, -0.00033473968505859375, 0.005786776542663574, 0.0027861297130584717,\n",
      "        -0.0003104209899902344, -0.0003104209899902344, -0.0004615187644958496, 0.0026932954788208008,\n",
      "        0.0026932954788208008, 0.005773454904556274, -0.0004615187644958496, 0.0026932954788208008,\n",
      "        0.005773454904556274, 0.0026932954788208008, 0.0046926140785217285, 0.0026932954788208008,\n",
      "        -0.0013699233531951904, 0.005786776542663574, -0.0004615187644958496, 0.005773454904556274,\n",
      "        0.004470765590667725, 0.003063976764678955, 0.0026932954788208008, 0.0037553906440734863,\n",
      "        0.0026932954788208008, 0.0026932954788208008, 0.0016858577728271484, -0.0004615187644958496,\n",
      "        0.0009702742099761963, 0.0046926140785217285, 0.0026932954788208008, 0.0026932954788208008,\n",
      "        0.0026932954788208008, 0.005786776542663574, 0.005017459392547607, -0.0004615187644958496,\n",
      "        0.004019886255264282, -0.0004615187644958496, 0.0026932954788208008, -0.0033537447452545166,\n",
      "        0.003063976764678955, 0.0026932954788208008, 0.003063976764678955, -0.0004615187644958496,\n",
      "        0.005526810884475708, 0.0026932954788208008, 0.0007081031799316406, 0.0026932954788208008,\n",
      "        0.005786776542663574]\n",
      "  num_agent_steps_sampled: 48000\n",
      "  num_agent_steps_trained: 1532800\n",
      "  num_env_steps_sampled: 48000\n",
      "  num_env_steps_trained: 1532800\n",
      "  num_target_updates: 96\n",
      "iterations_since_restore: 48\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 48000\n",
      "num_agent_steps_trained: 1532800\n",
      "num_env_steps_sampled: 48000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 21.899628100361717\n",
      "num_env_steps_trained: 1532800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 700.788099211575\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 16.390769230769234\n",
      "  ram_util_percent: 60.78000000000001\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 2965.355387210846\n",
      "time_this_iter_s: 45.681172132492065\n",
      "time_total_s: 2965.355387210846\n",
      "timers:\n",
      "  learn_throughput: 6024.662\n",
      "  learn_time_ms: 10.623\n",
      "  load_throughput: 702159.184\n",
      "  load_time_ms: 0.091\n",
      "  sample_time_ms: 144.237\n",
      "  synch_weights_time_ms: 3.114\n",
      "  training_iteration_time_ms: 169.03\n",
      "timestamp: 1709833661\n",
      "timesteps_total: 48000\n",
      "training_iteration: 48\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 49000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 49000\n",
      "  num_agent_steps_sampled: 49000\n",
      "  num_agent_steps_trained: 1564800\n",
      "  num_env_steps_sampled: 49000\n",
      "  num_env_steps_trained: 1564800\n",
      "  num_target_updates: 98\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-49-04\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 49000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 24449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0032560275867581367\n",
      "        max_q: 0.4398573338985443\n",
      "        mean_q: 0.4236726760864258\n",
      "        min_q: 0.4168059229850769\n",
      "      mean_td_error: 0.0009626131504774094\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 24450.0\n",
      "      td_error: [0.008899778127670288, 0.0079784095287323, 0.0029378533363342285,\n",
      "        0.009520798921585083, -0.0003432333469390869, 0.009520798921585083, 0.009520798921585083,\n",
      "        -0.004112124443054199, 0.0008447170257568359, 0.009520798921585083, 0.0009866058826446533,\n",
      "        0.000839918851852417, 0.009520798921585083, 0.0008447170257568359, -0.0030488967895507812,\n",
      "        -0.004112124443054199, -0.004112124443054199, 0.0010401010513305664, 0.008419662714004517,\n",
      "        -0.0031192898750305176, 0.0009866058826446533, -0.004206299781799316, -0.004112124443054199,\n",
      "        0.0008447170257568359, -0.0032942593097686768, 0.0008447170257568359, -0.004206299781799316,\n",
      "        -0.0032942593097686768, 0.009520798921585083, 0.0009144246578216553, 0.006393313407897949,\n",
      "        0.0015751123428344727, -0.004112124443054199, 0.009520798921585083, -0.004112124443054199,\n",
      "        -0.004341483116149902, 0.0014372766017913818, 0.009520798921585083, -0.004206299781799316,\n",
      "        -0.0003432333469390869, 0.008899778127670288, -0.004112124443054199, 0.0009866058826446533,\n",
      "        0.00672382116317749, 0.0009144246578216553, 0.0008447170257568359, -0.0031192898750305176,\n",
      "        -0.0031192898750305176, -0.0031192898750305176, -0.00558018684387207, -0.004112124443054199,\n",
      "        0.000839918851852417, -0.0031192898750305176, -0.004112124443054199, -0.0031192898750305176,\n",
      "        0.000839918851852417, -0.0030488967895507812, 0.008419662714004517, -0.0064394474029541016,\n",
      "        0.009520798921585083, -0.0031192898750305176, -0.0031192898750305176, 0.009098798036575317,\n",
      "        -0.0031192898750305176]\n",
      "  num_agent_steps_sampled: 49000\n",
      "  num_agent_steps_trained: 1564800\n",
      "  num_env_steps_sampled: 49000\n",
      "  num_env_steps_trained: 1564800\n",
      "  num_target_updates: 98\n",
      "iterations_since_restore: 49\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 49000\n",
      "num_agent_steps_trained: 1564800\n",
      "num_env_steps_sampled: 49000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 12.094079873820082\n",
      "num_env_steps_trained: 1564800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 387.0105559622426\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 13.09491525423729\n",
      "  ram_util_percent: 61.17796610169491\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3048.0584621429443\n",
      "time_this_iter_s: 82.70307493209839\n",
      "time_total_s: 3048.0584621429443\n",
      "timers:\n",
      "  learn_throughput: 5832.738\n",
      "  learn_time_ms: 10.973\n",
      "  load_throughput: 535478.667\n",
      "  load_time_ms: 0.12\n",
      "  sample_time_ms: 107.665\n",
      "  synch_weights_time_ms: 3.298\n",
      "  training_iteration_time_ms: 134.655\n",
      "timestamp: 1709833744\n",
      "timesteps_total: 49000\n",
      "training_iteration: 49\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 50000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 50000\n",
      "  num_agent_steps_sampled: 50000\n",
      "  num_agent_steps_trained: 1596800\n",
      "  num_env_steps_sampled: 50000\n",
      "  num_env_steps_trained: 1596800\n",
      "  num_target_updates: 100\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-50-11\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 50000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 24949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0018592403503134847\n",
      "        max_q: 0.4286917448043823\n",
      "        mean_q: 0.419027715921402\n",
      "        min_q: 0.4134562611579895\n",
      "      mean_td_error: -0.00033232150599360466\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 24950.0\n",
      "      td_error: [0.0004877746105194092, -0.0030017197132110596, -0.004877209663391113,\n",
      "        -0.0030017197132110596, -0.004877209663391113, 0.005827903747558594, -0.004877209663391113,\n",
      "        0.00714603066444397, 0.005827903747558594, 0.005827903747558594, -0.004877209663391113,\n",
      "        0.0011028945446014404, 0.0014673471450805664, -0.002762526273727417, 0.0005069971084594727,\n",
      "        -0.0013425350189208984, -0.003387928009033203, 0.0011028945446014404, 0.005827903747558594,\n",
      "        -0.004877209663391113, -0.004877209663391113, 0.0004877746105194092, 0.005827903747558594,\n",
      "        0.0005069971084594727, -0.004877209663391113, 0.0005069971084594727, 0.0005069971084594727,\n",
      "        0.005827903747558594, 0.0005069971084594727, 0.0011028945446014404, 0.0004877746105194092,\n",
      "        0.005827903747558594, 0.0012081265449523926, -0.028598010540008545, 0.0004877746105194092,\n",
      "        5.0455331802368164e-05, 0.002332240343093872, 0.0011028945446014404, 0.005827903747558594,\n",
      "        0.0004877746105194092, 0.005827903747558594, -0.004877209663391113, -0.0030017197132110596,\n",
      "        0.0011028945446014404, 0.005767196416854858, -0.0030017197132110596, 0.0005069971084594727,\n",
      "        -0.0030017197132110596, 0.005827903747558594, 0.0004877746105194092, -0.004877209663391113,\n",
      "        0.0004877746105194092, 0.0004877746105194092, -0.004877209663391113, -0.004877209663391113,\n",
      "        0.0005069971084594727, -0.004877209663391113, 0.005827903747558594, -0.0030017197132110596,\n",
      "        0.0005681216716766357, -0.004877209663391113, -0.0009855329990386963, 0.0005069971084594727,\n",
      "        0.0011028945446014404]\n",
      "  num_agent_steps_sampled: 50000\n",
      "  num_agent_steps_trained: 1596800\n",
      "  num_env_steps_sampled: 50000\n",
      "  num_env_steps_trained: 1596800\n",
      "  num_target_updates: 100\n",
      "iterations_since_restore: 50\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 50000\n",
      "num_agent_steps_trained: 1596800\n",
      "num_env_steps_sampled: 50000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 14.827357673737108\n",
      "num_env_steps_trained: 1596800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 474.47544555958746\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 16.346875\n",
      "  ram_util_percent: 61.585416666666674\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3115.5206110477448\n",
      "time_this_iter_s: 67.46214890480042\n",
      "time_total_s: 3115.5206110477448\n",
      "timers:\n",
      "  learn_throughput: 5953.563\n",
      "  learn_time_ms: 10.75\n",
      "  load_throughput: 516122.776\n",
      "  load_time_ms: 0.124\n",
      "  sample_time_ms: 111.142\n",
      "  synch_weights_time_ms: 3.315\n",
      "  training_iteration_time_ms: 137.431\n",
      "timestamp: 1709833811\n",
      "timesteps_total: 50000\n",
      "training_iteration: 50\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 69x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 51000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 51000\n",
      "  num_agent_steps_sampled: 51000\n",
      "  num_agent_steps_trained: 1628800\n",
      "  num_env_steps_sampled: 51000\n",
      "  num_env_steps_trained: 1628800\n",
      "  num_target_updates: 102\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-51-31\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 51000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 25449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0013068413827568293\n",
      "        max_q: 0.4390053451061249\n",
      "        mean_q: 0.4271889925003052\n",
      "        min_q: 0.41957888007164\n",
      "      mean_td_error: -0.07524152845144272\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 25450.0\n",
      "      td_error: [-0.0012325048446655273, -4.986374378204346, -0.004299730062484741,\n",
      "        0.006989657878875732, 0.0028803646564483643, 0.013625919818878174, -0.0038616061210632324,\n",
      "        0.001188516616821289, 0.013625919818878174, 0.003377586603164673, 0.001188516616821289,\n",
      "        0.001188516616821289, -0.0038616061210632324, 0.0028803646564483643, -0.002787083387374878,\n",
      "        -0.0012325048446655273, 0.013625919818878174, -0.0012325048446655273, 0.012634694576263428,\n",
      "        -0.0038616061210632324, 0.007517814636230469, -0.0025219619274139404, 0.0028263628482818604,\n",
      "        -0.0012325048446655273, 0.001188516616821289, 0.0077860355377197266, 0.005718648433685303,\n",
      "        -0.0022644400596618652, 0.006989657878875732, 0.013625919818878174, -0.0038616061210632324,\n",
      "        -0.0038616061210632324, 0.001188516616821289, 0.003377586603164673, 0.0028803646564483643,\n",
      "        0.0028263628482818604, -0.0012325048446655273, -0.0022644400596618652, 0.001724332571029663,\n",
      "        0.013625919818878174, 0.0028803646564483643, 0.013625919818878174, -0.0012325048446655273,\n",
      "        0.012634694576263428, -0.003546297550201416, -0.0025347471237182617, -0.0014593005180358887,\n",
      "        0.013625919818878174, 0.0028803646564483643, -0.0038616061210632324, 0.0028803646564483643,\n",
      "        -0.0012325048446655273, 0.001724332571029663, 0.001188516616821289, -0.004299730062484741,\n",
      "        0.0008358657360076904, -0.0012325048446655273, -0.0038616061210632324, 0.0028263628482818604,\n",
      "        0.013625919818878174, 0.013625919818878174, 0.0028803646564483643, 0.0028803646564483643,\n",
      "        0.001188516616821289]\n",
      "  num_agent_steps_sampled: 51000\n",
      "  num_agent_steps_trained: 1628800\n",
      "  num_env_steps_sampled: 51000\n",
      "  num_env_steps_trained: 1628800\n",
      "  num_target_updates: 102\n",
      "iterations_since_restore: 51\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 51000\n",
      "num_agent_steps_trained: 1628800\n",
      "num_env_steps_sampled: 51000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 12.532088703272048\n",
      "num_env_steps_trained: 1628800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 401.02683850470555\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 12.044247787610619\n",
      "  ram_util_percent: 60.88407079646019\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3195.3339490890503\n",
      "time_this_iter_s: 79.81333804130554\n",
      "time_total_s: 3195.3339490890503\n",
      "timers:\n",
      "  learn_throughput: 5589.413\n",
      "  learn_time_ms: 11.45\n",
      "  load_throughput: 614268.778\n",
      "  load_time_ms: 0.104\n",
      "  sample_time_ms: 144.838\n",
      "  synch_weights_time_ms: 3.327\n",
      "  training_iteration_time_ms: 172.664\n",
      "timestamp: 1709833891\n",
      "timesteps_total: 51000\n",
      "training_iteration: 51\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 52000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 52000\n",
      "  num_agent_steps_sampled: 52000\n",
      "  num_agent_steps_trained: 1660800\n",
      "  num_env_steps_sampled: 52000\n",
      "  num_env_steps_trained: 1660800\n",
      "  num_target_updates: 104\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-52-56\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 52000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 25949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0025896078441292048\n",
      "        max_q: 0.447037011384964\n",
      "        mean_q: 0.43547874689102173\n",
      "        min_q: 0.42784321308135986\n",
      "      mean_td_error: 0.003625208046287298\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 25950.0\n",
      "      td_error: [-0.00178450345993042, 0.0037241578102111816, 0.004560023546218872,\n",
      "        0.01361575722694397, 0.004560023546218872, 0.004560023546218872, 0.003732651472091675,\n",
      "        -0.002685755491256714, 0.004560023546218872, 0.003315061330795288, 0.004560023546218872,\n",
      "        0.013825148344039917, 0.004841446876525879, 0.004560023546218872, 0.004560023546218872,\n",
      "        -0.0007567703723907471, 0.004560023546218872, 0.01361575722694397, 0.004560023546218872,\n",
      "        -0.0006757080554962158, -0.0006757080554962158, 0.004366129636764526, -0.00178450345993042,\n",
      "        0.014406561851501465, 0.004560023546218872, 0.004560023546218872, -0.00178450345993042,\n",
      "        -0.0036300718784332275, -0.0006757080554962158, 0.003315061330795288, 0.013825148344039917,\n",
      "        -0.0036300718784332275, 0.00013890862464904785, 0.004366129636764526, -0.0006757080554962158,\n",
      "        0.004560023546218872, 0.004657536745071411, 0.004560023546218872, -0.0006757080554962158,\n",
      "        0.01361575722694397, -0.0006757080554962158, 0.003892570734024048, 0.003732651472091675,\n",
      "        0.004560023546218872, 0.014406561851501465, 0.013825148344039917, -0.00178450345993042,\n",
      "        -0.0036300718784332275, -0.0012715458869934082, -0.0006757080554962158, 0.004366129636764526,\n",
      "        0.01361575722694397, -0.00178450345993042, 0.004560023546218872, 0.004366129636764526,\n",
      "        -0.0025634765625, 0.015680670738220215, 0.0005313754081726074, 0.004096090793609619,\n",
      "        0.002492368221282959, -0.001730591058731079, -0.00178450345993042, -0.00178450345993042,\n",
      "        0.004366129636764526]\n",
      "  num_agent_steps_sampled: 52000\n",
      "  num_agent_steps_trained: 1660800\n",
      "  num_env_steps_sampled: 52000\n",
      "  num_env_steps_trained: 1660800\n",
      "  num_target_updates: 104\n",
      "iterations_since_restore: 52\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 52000\n",
      "num_agent_steps_trained: 1660800\n",
      "num_env_steps_sampled: 52000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.827590136208121\n",
      "num_env_steps_trained: 1660800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 378.4828843586599\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.559166666666666\n",
      "  ram_util_percent: 60.58250000000001\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3279.899752140045\n",
      "time_this_iter_s: 84.56580305099487\n",
      "time_total_s: 3279.899752140045\n",
      "timers:\n",
      "  learn_throughput: 5444.872\n",
      "  learn_time_ms: 11.754\n",
      "  load_throughput: 628801.724\n",
      "  load_time_ms: 0.102\n",
      "  sample_time_ms: 149.217\n",
      "  synch_weights_time_ms: 3.421\n",
      "  training_iteration_time_ms: 177.824\n",
      "timestamp: 1709833976\n",
      "timesteps_total: 52000\n",
      "training_iteration: 52\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 53000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 53000\n",
      "  num_agent_steps_sampled: 53000\n",
      "  num_agent_steps_trained: 1692800\n",
      "  num_env_steps_sampled: 53000\n",
      "  num_env_steps_trained: 1692800\n",
      "  num_target_updates: 106\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-54-21\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 53000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 26449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.000520542380400002\n",
      "        max_q: 0.4595424234867096\n",
      "        mean_q: 0.4577625095844269\n",
      "        min_q: 0.45432257652282715\n",
      "      mean_td_error: 0.000608264934271574\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 26450.0\n",
      "      td_error: [-0.0013627707958221436, 0.0016242563724517822, -0.0006952583789825439,\n",
      "        0.0005353093147277832, -0.00047090649604797363, 0.0012680292129516602, 0.0008972287178039551,\n",
      "        0.0005353093147277832, 0.001724928617477417, 0.0016242563724517822, 0.0007029473781585693,\n",
      "        0.0008972287178039551, 0.0019419193267822266, -0.001186072826385498, 0.0004948675632476807,\n",
      "        0.0007029473781585693, 0.0016242563724517822, -0.001186072826385498, 0.0011703968048095703,\n",
      "        0.0004948675632476807, 0.0005353093147277832, 0.0011703968048095703, 0.0005353093147277832,\n",
      "        -0.001186072826385498, 0.0004948675632476807, 0.0004948675632476807, 0.0012680292129516602,\n",
      "        -0.0014514923095703125, 0.0010823607444763184, 0.0007410347461700439, 0.0012680292129516602,\n",
      "        0.0010823607444763184, 0.0011703968048095703, -0.00047090649604797363, 0.0004794597625732422,\n",
      "        0.0017397701740264893, -0.0006952583789825439, 0.0011703968048095703, -0.00047090649604797363,\n",
      "        0.0016242563724517822, -0.00047090649604797363, 0.0005353093147277832, -3.120303153991699e-05,\n",
      "        0.0001958608627319336, 0.00015923380851745605, 0.0007029473781585693, -0.001186072826385498,\n",
      "        -0.0004566013813018799, 0.0011703968048095703, 0.0010823607444763184, 0.0007029473781585693,\n",
      "        0.0011703968048095703, 0.001092374324798584, 0.0005353093147277832, 0.0016242563724517822,\n",
      "        0.0004948675632476807, 0.0012762248516082764, 0.0004948675632476807, 0.0011703968048095703,\n",
      "        0.0016242563724517822, 0.0016242563724517822, 0.0016242563724517822, 0.0007029473781585693,\n",
      "        0.0011703968048095703]\n",
      "  num_agent_steps_sampled: 53000\n",
      "  num_agent_steps_trained: 1692800\n",
      "  num_env_steps_sampled: 53000\n",
      "  num_env_steps_trained: 1692800\n",
      "  num_target_updates: 106\n",
      "iterations_since_restore: 53\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 53000\n",
      "num_agent_steps_trained: 1692800\n",
      "num_env_steps_sampled: 53000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 11.734051844669356\n",
      "num_env_steps_trained: 1692800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 375.4896590294194\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 10.61404958677686\n",
      "  ram_util_percent: 60.67272727272729\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3365.1395301818848\n",
      "time_this_iter_s: 85.2397780418396\n",
      "time_total_s: 3365.1395301818848\n",
      "timers:\n",
      "  learn_throughput: 6023.946\n",
      "  learn_time_ms: 10.624\n",
      "  load_throughput: 694528.994\n",
      "  load_time_ms: 0.092\n",
      "  sample_time_ms: 144.965\n",
      "  synch_weights_time_ms: 3.022\n",
      "  training_iteration_time_ms: 169.636\n",
      "timestamp: 1709834061\n",
      "timesteps_total: 53000\n",
      "training_iteration: 53\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 51x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 114x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 185x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 79x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 83x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 54000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 54000\n",
      "  num_agent_steps_sampled: 54000\n",
      "  num_agent_steps_trained: 1724800\n",
      "  num_env_steps_sampled: 54000\n",
      "  num_env_steps_trained: 1724800\n",
      "  num_target_updates: 108\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-55-19\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 54000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 26949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.002818729029968381\n",
      "        max_q: 0.46623682975769043\n",
      "        mean_q: 0.45708227157592773\n",
      "        min_q: 0.4446500837802887\n",
      "      mean_td_error: -0.0013477648608386517\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 26950.0\n",
      "      td_error: [-0.009988933801651001, -0.0029817819595336914, -0.0035758912563323975,\n",
      "        -0.011751443147659302, -0.0013254284858703613, 0.007231801748275757, -0.0029817819595336914,\n",
      "        0.005063265562057495, 0.00659024715423584, -0.011859238147735596, -0.0013254284858703613,\n",
      "        0.004381507635116577, -0.011751443147659302, -0.011751443147659302, -0.0013254284858703613,\n",
      "        0.007231801748275757, -0.002340942621231079, -0.010246306657791138, 0.004381507635116577,\n",
      "        0.004381507635116577, -0.008724182844161987, -0.013556361198425293, -0.0035455822944641113,\n",
      "        0.0043121278285980225, 0.0043121278285980225, -0.0025956928730010986, -0.002340942621231079,\n",
      "        -0.011751443147659302, -0.0035455822944641113, 0.007181078195571899, -0.0013254284858703613,\n",
      "        -0.0013254284858703613, 0.004381507635116577, 0.007231801748275757, -0.0029817819595336914,\n",
      "        -0.0013254284858703613, -0.009988933801651001, -0.009988933801651001, -0.0029817819595336914,\n",
      "        0.005063265562057495, -0.011751443147659302, -0.009988933801651001, -0.0013254284858703613,\n",
      "        -0.009988933801651001, -0.0013254284858703613, 0.004381507635116577, 0.004381507635116577,\n",
      "        0.00659024715423584, 0.006990164518356323, -0.013556361198425293, 0.00659024715423584,\n",
      "        0.004381507635116577, -0.008828550577163696, 0.00659024715423584, -0.0013254284858703613,\n",
      "        -0.0013254284858703613, -0.011859238147735596, 0.005063265562057495, 0.004381507635116577,\n",
      "        0.00659024715423584, 0.0043121278285980225, 0.007693439722061157, 0.007181078195571899,\n",
      "        -0.002669423818588257]\n",
      "  num_agent_steps_sampled: 54000\n",
      "  num_agent_steps_trained: 1724800\n",
      "  num_env_steps_sampled: 54000\n",
      "  num_env_steps_trained: 1724800\n",
      "  num_target_updates: 108\n",
      "iterations_since_restore: 54\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 54000\n",
      "num_agent_steps_trained: 1724800\n",
      "num_env_steps_sampled: 54000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.250461007159778\n",
      "num_env_steps_trained: 1724800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 552.0147522291129\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 28.99156626506024\n",
      "  ram_util_percent: 65.3578313253012\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3423.133218050003\n",
      "time_this_iter_s: 57.993687868118286\n",
      "time_total_s: 3423.133218050003\n",
      "timers:\n",
      "  learn_throughput: 4995.821\n",
      "  learn_time_ms: 12.811\n",
      "  load_throughput: 643884.519\n",
      "  load_time_ms: 0.099\n",
      "  sample_time_ms: 92.212\n",
      "  synch_weights_time_ms: 4.654\n",
      "  training_iteration_time_ms: 121.992\n",
      "timestamp: 1709834119\n",
      "timesteps_total: 54000\n",
      "training_iteration: 54\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 87x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 87x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 55000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 55000\n",
      "  num_agent_steps_sampled: 55000\n",
      "  num_agent_steps_trained: 1756800\n",
      "  num_env_steps_sampled: 55000\n",
      "  num_env_steps_trained: 1756800\n",
      "  num_target_updates: 110\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-56-17\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 55000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 27449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0005087075405754149\n",
      "        max_q: 0.4698428213596344\n",
      "        mean_q: 0.4558449983596802\n",
      "        min_q: 0.45118001103401184\n",
      "      mean_td_error: -0.00015900284051895142\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 27450.0\n",
      "      td_error: [-0.00016021728515625, 0.0008430778980255127, -0.0007170736789703369,\n",
      "        0.0009921491146087646, -0.00025659799575805664, -0.00025659799575805664, 0.0014612674713134766,\n",
      "        -0.0013830959796905518, -0.00025659799575805664, 0.00021216273307800293, -0.00025659799575805664,\n",
      "        -0.0021410584449768066, 0.0009921491146087646, -0.00021824240684509277, -0.00025659799575805664,\n",
      "        0.0009921491146087646, 0.00021216273307800293, -0.0018232762813568115, -0.0018232762813568115,\n",
      "        6.851553916931152e-05, -0.0018232762813568115, 0.00046509504318237305, 0.0004749894142150879,\n",
      "        -0.0018232762813568115, -0.00025659799575805664, -0.0013501942157745361, 0.00046509504318237305,\n",
      "        -0.00025659799575805664, 0.00046509504318237305, -0.00025659799575805664,\n",
      "        0.00046509504318237305, -0.00021824240684509277, -0.0018232762813568115, 0.0009921491146087646,\n",
      "        -0.000818789005279541, 0.00021216273307800293, 0.011005550622940063, 0.00046509504318237305,\n",
      "        -0.0013830959796905518, -0.00025659799575805664, -0.0021410584449768066, 0.00046509504318237305,\n",
      "        -0.000818789005279541, 0.0009921491146087646, 0.0009921491146087646, -0.0013830959796905518,\n",
      "        -0.002080589532852173, -0.00016021728515625, 0.00046509504318237305, 0.00046509504318237305,\n",
      "        -0.005751520395278931, -0.0010440051555633545, 0.00021216273307800293, 0.0009921491146087646,\n",
      "        -0.00021824240684509277, -0.0018232762813568115, -0.0018232762813568115, 0.0007613897323608398,\n",
      "        0.0007773339748382568, -0.0018232762813568115, 0.00021216273307800293, 0.0009921491146087646,\n",
      "        -0.00021824240684509277, 0.000814288854598999]\n",
      "  num_agent_steps_sampled: 55000\n",
      "  num_agent_steps_trained: 1756800\n",
      "  num_env_steps_sampled: 55000\n",
      "  num_env_steps_trained: 1756800\n",
      "  num_target_updates: 110\n",
      "iterations_since_restore: 55\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 55000\n",
      "num_agent_steps_trained: 1756800\n",
      "num_env_steps_sampled: 55000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.320800573469384\n",
      "num_env_steps_trained: 1756800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 554.2656183510203\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 38.176829268292686\n",
      "  ram_util_percent: 69.84512195121953\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3480.8876416683197\n",
      "time_this_iter_s: 57.75442361831665\n",
      "time_total_s: 3480.8876416683197\n",
      "timers:\n",
      "  learn_throughput: 6193.611\n",
      "  learn_time_ms: 10.333\n",
      "  load_throughput: 493356.839\n",
      "  load_time_ms: 0.13\n",
      "  sample_time_ms: 83.769\n",
      "  synch_weights_time_ms: 3.217\n",
      "  training_iteration_time_ms: 108.664\n",
      "timestamp: 1709834177\n",
      "timesteps_total: 55000\n",
      "training_iteration: 55\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 56000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 56000\n",
      "  num_agent_steps_sampled: 56000\n",
      "  num_agent_steps_trained: 1788800\n",
      "  num_env_steps_sampled: 56000\n",
      "  num_env_steps_trained: 1788800\n",
      "  num_target_updates: 112\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-57-13\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 56000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 27949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0011412411695346236\n",
      "        max_q: 0.46046024560928345\n",
      "        mean_q: 0.456365168094635\n",
      "        min_q: 0.45079630613327026\n",
      "      mean_td_error: 4.327856004238129e-06\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 27950.0\n",
      "      td_error: [-0.0017177164554595947, -0.0013232827186584473, -0.00015553832054138184,\n",
      "        -0.00015553832054138184, 0.0013994276523590088, 0.0013994276523590088, 0.0005394518375396729,\n",
      "        0.004559934139251709, 0.004559934139251709, 0.0013994276523590088, -0.0004527568817138672,\n",
      "        -0.0013232827186584473, -0.00015553832054138184, -0.0013232827186584473, 0.004559934139251709,\n",
      "        0.004559934139251709, -0.0002942681312561035, 0.0007779598236083984, 0.003890126943588257,\n",
      "        -0.0006372332572937012, -0.0013232827186584473, -0.0002942681312561035, -0.00015553832054138184,\n",
      "        0.00040224194526672363, -0.004164248704910278, 0.0013994276523590088, -0.00031179189682006836,\n",
      "        -0.0002942681312561035, 0.004559934139251709, -0.0013232827186584473, -0.0013232827186584473,\n",
      "        -0.0002942681312561035, -0.0013232827186584473, 0.004559934139251709, -0.00015553832054138184,\n",
      "        -0.00015553832054138184, -0.0013232827186584473, 0.004559934139251709, -0.0013232827186584473,\n",
      "        0.004559934139251709, 0.004559934139251709, -0.0064765214920043945, -0.00681072473526001,\n",
      "        -0.0024781227111816406, 0.004559934139251709, -0.0003904402256011963, 0.0013994276523590088,\n",
      "        -0.00015553832054138184, -0.004164248704910278, -0.004164248704910278, 0.0013994276523590088,\n",
      "        0.004559934139251709, 0.0013994276523590088, -0.00015553832054138184, 0.004559934139251709,\n",
      "        -0.004164248704910278, -0.01349729299545288, -0.0002942681312561035, 0.0013994276523590088,\n",
      "        -0.004164248704910278, -0.00015553832054138184, -0.0004527568817138672, 0.0013994276523590088,\n",
      "        -0.0038195252418518066]\n",
      "  num_agent_steps_sampled: 56000\n",
      "  num_agent_steps_trained: 1788800\n",
      "  num_env_steps_sampled: 56000\n",
      "  num_env_steps_trained: 1788800\n",
      "  num_target_updates: 112\n",
      "iterations_since_restore: 56\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 56000\n",
      "num_agent_steps_trained: 1788800\n",
      "num_env_steps_sampled: 56000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.81473770139627\n",
      "num_env_steps_trained: 1788800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 570.0716064446807\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.767500000000002\n",
      "  ram_util_percent: 70.46000000000001\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3537.038983821869\n",
      "time_this_iter_s: 56.151342153549194\n",
      "time_total_s: 3537.038983821869\n",
      "timers:\n",
      "  learn_throughput: 6205.911\n",
      "  learn_time_ms: 10.313\n",
      "  load_throughput: 537515.931\n",
      "  load_time_ms: 0.119\n",
      "  sample_time_ms: 90.193\n",
      "  synch_weights_time_ms: 3.094\n",
      "  training_iteration_time_ms: 115.054\n",
      "timestamp: 1709834233\n",
      "timesteps_total: 56000\n",
      "training_iteration: 56\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 57000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 57000\n",
      "  num_agent_steps_sampled: 57000\n",
      "  num_agent_steps_trained: 1820800\n",
      "  num_env_steps_sampled: 57000\n",
      "  num_env_steps_trained: 1820800\n",
      "  num_target_updates: 114\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-58-09\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 57000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 28449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.002887460170313716\n",
      "        max_q: 0.47004464268684387\n",
      "        mean_q: 0.4606682360172272\n",
      "        min_q: 0.4504159092903137\n",
      "      mean_td_error: -0.07717125862836838\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 28450.0\n",
      "      td_error: [0.00023725628852844238, 0.00023725628852844238, 0.005029439926147461,\n",
      "        0.005884408950805664, -0.0005365312099456787, 0.005122005939483643, 0.005884408950805664,\n",
      "        0.000639498233795166, 0.000639498233795166, 0.005029439926147461, 0.006199955940246582,\n",
      "        0.0004890263080596924, 0.005029439926147461, 0.006199955940246582, 0.0007051527500152588,\n",
      "        0.005122005939483643, 0.005029439926147461, 0.005122005939483643, 0.000639498233795166,\n",
      "        0.000639498233795166, 0.0004890263080596924, -0.006273061037063599, -0.006273061037063599,\n",
      "        0.003730297088623047, 0.004814893007278442, -0.00735849142074585, -0.007706403732299805,\n",
      "        0.005884408950805664, 0.004368633031845093, 0.005884408950805664, 0.005884408950805664,\n",
      "        0.0004890263080596924, -4.99936056137085, -0.006347835063934326, -0.00735849142074585,\n",
      "        -0.006273061037063599, 0.005029439926147461, 0.005095481872558594, -0.00735849142074585,\n",
      "        0.005884408950805664, -0.006273061037063599, -0.006273061037063599, 0.000639498233795166,\n",
      "        -0.006273061037063599, 0.005029439926147461, 0.0004890263080596924, 0.005884408950805664,\n",
      "        0.0004890263080596924, 0.0004890263080596924, 0.005029439926147461, 0.005029439926147461,\n",
      "        0.005029439926147461, -0.00735849142074585, 0.000639498233795166, 0.005029439926147461,\n",
      "        -0.006273061037063599, 0.0004890263080596924, -0.004657655954360962, -0.00735849142074585,\n",
      "        0.009371340274810791, -0.006273061037063599, 0.005884408950805664, 0.005029439926147461,\n",
      "        0.000639498233795166]\n",
      "  num_agent_steps_sampled: 57000\n",
      "  num_agent_steps_trained: 1820800\n",
      "  num_env_steps_sampled: 57000\n",
      "  num_env_steps_trained: 1820800\n",
      "  num_target_updates: 114\n",
      "iterations_since_restore: 57\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 57000\n",
      "num_agent_steps_trained: 1820800\n",
      "num_env_steps_sampled: 57000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.77770641967782\n",
      "num_env_steps_trained: 1820800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 568.8866054296902\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.514999999999997\n",
      "  ram_util_percent: 71.09750000000001\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3593.307519674301\n",
      "time_this_iter_s: 56.26853585243225\n",
      "time_total_s: 3593.307519674301\n",
      "timers:\n",
      "  learn_throughput: 5997.097\n",
      "  learn_time_ms: 10.672\n",
      "  load_throughput: 635500.606\n",
      "  load_time_ms: 0.101\n",
      "  sample_time_ms: 76.54\n",
      "  synch_weights_time_ms: 4.028\n",
      "  training_iteration_time_ms: 102.298\n",
      "timestamp: 1709834289\n",
      "timesteps_total: 57000\n",
      "training_iteration: 57\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 93x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 58000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 58000\n",
      "  num_agent_steps_sampled: 58000\n",
      "  num_agent_steps_trained: 1852800\n",
      "  num_env_steps_sampled: 58000\n",
      "  num_env_steps_trained: 1852800\n",
      "  num_target_updates: 116\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_18-59-05\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 58000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 28949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0009807515889406204\n",
      "        max_q: 0.4701439440250397\n",
      "        mean_q: 0.4665907025337219\n",
      "        min_q: 0.455010324716568\n",
      "      mean_td_error: 0.0008473824709653854\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 28950.0\n",
      "      td_error: [0.0013638734817504883, 0.002920985221862793, -0.009522199630737305,\n",
      "        0.001319974660873413, 0.0013638734817504883, 0.002324014902114868, 0.00017154216766357422,\n",
      "        -0.010040581226348877, 0.002920985221862793, 0.0005120337009429932, 0.002920985221862793,\n",
      "        0.0015659630298614502, 0.002038419246673584, 0.0015338659286499023, 0.002038419246673584,\n",
      "        0.0008487403392791748, 0.0008487403392791748, 0.0013638734817504883, 0.0013638734817504883,\n",
      "        0.002920985221862793, 0.004456281661987305, 0.0025290250778198242, 0.0015338659286499023,\n",
      "        0.0017689168453216553, 0.002038419246673584, 0.0008487403392791748, 0.0005120337009429932,\n",
      "        0.0008487403392791748, 0.002038419246673584, 0.0013638734817504883, 0.0013638734817504883,\n",
      "        0.002038419246673584, 0.001346886157989502, 0.0013638734817504883, 0.002038419246673584,\n",
      "        0.0008487403392791748, 0.0025290250778198242, 0.002920985221862793, 0.0013638734817504883,\n",
      "        0.002920985221862793, 0.002920985221862793, 0.0013638734817504883, 0.0020278096199035645,\n",
      "        0.0013638734817504883, 0.002038419246673584, -0.00947985053062439, 0.0008487403392791748,\n",
      "        -0.00947985053062439, 0.0009059011936187744, 0.002038419246673584, 0.0015338659286499023,\n",
      "        0.002038419246673584, 0.0018950402736663818, 0.0013638734817504883, 0.0018950402736663818,\n",
      "        -0.0006697773933410645, 0.0015338659286499023, 0.0018950402736663818, 0.0008487403392791748,\n",
      "        0.002920985221862793, 0.0025290250778198242, 0.002920985221862793, -0.00947985053062439,\n",
      "        0.0010071396827697754]\n",
      "  num_agent_steps_sampled: 58000\n",
      "  num_agent_steps_trained: 1852800\n",
      "  num_env_steps_sampled: 58000\n",
      "  num_env_steps_trained: 1852800\n",
      "  num_target_updates: 116\n",
      "iterations_since_restore: 58\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 58000\n",
      "num_agent_steps_trained: 1852800\n",
      "num_env_steps_sampled: 58000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.940781456287727\n",
      "num_env_steps_trained: 1852800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 574.1050066012073\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.425316455696205\n",
      "  ram_util_percent: 71.38354430379746\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3649.065430879593\n",
      "time_this_iter_s: 55.75791120529175\n",
      "time_total_s: 3649.065430879593\n",
      "timers:\n",
      "  learn_throughput: 5990.78\n",
      "  learn_time_ms: 10.683\n",
      "  load_throughput: 510139.597\n",
      "  load_time_ms: 0.125\n",
      "  sample_time_ms: 94.508\n",
      "  synch_weights_time_ms: 4.686\n",
      "  training_iteration_time_ms: 121.265\n",
      "timestamp: 1709834345\n",
      "timesteps_total: 58000\n",
      "training_iteration: 58\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 59000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 59000\n",
      "  num_agent_steps_sampled: 59000\n",
      "  num_agent_steps_trained: 1884800\n",
      "  num_env_steps_sampled: 59000\n",
      "  num_env_steps_trained: 1884800\n",
      "  num_target_updates: 118\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-00-01\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 59000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 29449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.024713777005672455\n",
      "        max_q: 0.5791735649108887\n",
      "        mean_q: 0.5167108774185181\n",
      "        min_q: 0.49354857206344604\n",
      "      mean_td_error: 0.046694137156009674\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 29450.0\n",
      "      td_error: [0.033592402935028076, 0.027601391077041626, 0.04362380504608154,\n",
      "        0.044821321964263916, 0.10965728759765625, 0.027601391077041626, 0.027601391077041626,\n",
      "        0.0464664101600647, 0.027601391077041626, 0.044821321964263916, 0.0464664101600647,\n",
      "        0.027601391077041626, 0.027601391077041626, 0.10808378458023071, 0.0464664101600647,\n",
      "        0.044821321964263916, 0.04362380504608154, 0.0464664101600647, 0.027601391077041626,\n",
      "        0.029050350189208984, 0.10808378458023071, 0.10808378458023071, 0.025187522172927856,\n",
      "        0.035067617893218994, 0.04320141673088074, 0.044370830059051514, 0.027601391077041626,\n",
      "        0.033592402935028076, 0.0464664101600647, 0.044821321964263916, 0.04362380504608154,\n",
      "        0.04362380504608154, 0.027601391077041626, 0.027601391077041626, 0.11064684391021729,\n",
      "        0.10808378458023071, 0.0464664101600647, 0.044424593448638916, 0.0464664101600647,\n",
      "        0.044821321964263916, 0.0464664101600647, 0.044424593448638916, 0.027601391077041626,\n",
      "        0.04317256808280945, 0.033592402935028076, 0.033592402935028076, 0.027601391077041626,\n",
      "        0.10808378458023071, 0.033592402935028076, 0.033592402935028076, 0.0464664101600647,\n",
      "        0.027601391077041626, 0.033592402935028076, 0.04677098989486694, 0.04677098989486694,\n",
      "        0.044821321964263916, 0.0464664101600647, 0.027601391077041626, 0.0464664101600647,\n",
      "        0.033592402935028076, 0.044821321964263916, 0.029050350189208984, 0.033592402935028076,\n",
      "        0.10808378458023071]\n",
      "  num_agent_steps_sampled: 59000\n",
      "  num_agent_steps_trained: 1884800\n",
      "  num_env_steps_sampled: 59000\n",
      "  num_env_steps_trained: 1884800\n",
      "  num_target_updates: 118\n",
      "iterations_since_restore: 59\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 59000\n",
      "num_agent_steps_trained: 1884800\n",
      "num_env_steps_sampled: 59000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.75311555600802\n",
      "num_env_steps_trained: 1884800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 568.0996977922566\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.32\n",
      "  ram_util_percent: 71.41375000000001\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3705.411838054657\n",
      "time_this_iter_s: 56.34640717506409\n",
      "time_total_s: 3705.411838054657\n",
      "timers:\n",
      "  learn_throughput: 5954.303\n",
      "  learn_time_ms: 10.749\n",
      "  load_throughput: 637311.149\n",
      "  load_time_ms: 0.1\n",
      "  sample_time_ms: 84.17\n",
      "  synch_weights_time_ms: 3.102\n",
      "  training_iteration_time_ms: 109.2\n",
      "timestamp: 1709834401\n",
      "timesteps_total: 59000\n",
      "training_iteration: 59\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 93x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 60000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 60000\n",
      "  num_agent_steps_sampled: 60000\n",
      "  num_agent_steps_trained: 1916800\n",
      "  num_env_steps_sampled: 60000\n",
      "  num_env_steps_trained: 1916800\n",
      "  num_target_updates: 120\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-00-58\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 60000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 29949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0017736867303028703\n",
      "        max_q: 0.49078208208084106\n",
      "        mean_q: 0.48716771602630615\n",
      "        min_q: 0.4799163043498993\n",
      "      mean_td_error: -0.0021241484209895134\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 29950.0\n",
      "      td_error: [-0.0013376474380493164, -0.0005843639373779297, -0.0013376474380493164,\n",
      "        -0.002401679754257202, -0.0001328587532043457, -0.002149134874343872, -0.001127690076828003,\n",
      "        -0.001957625150680542, -0.002149134874343872, -0.006047636270523071, -0.0001328587532043457,\n",
      "        -0.0010630786418914795, -0.0013376474380493164, -0.002401679754257202, -0.0351463258266449,\n",
      "        -0.001127690076828003, -0.001127690076828003, -0.0001328587532043457, -0.004333555698394775,\n",
      "        -0.001127690076828003, -0.0013376474380493164, -0.0001328587532043457, -0.004333555698394775,\n",
      "        -0.002149134874343872, -0.002149134874343872, -0.004333555698394775, -0.002149134874343872,\n",
      "        0.001178741455078125, -0.0013376474380493164, -0.001957625150680542, -0.002401679754257202,\n",
      "        -0.004333555698394775, 0.001178741455078125, -0.002149134874343872, -0.001957625150680542,\n",
      "        -0.0013376474380493164, -0.002149134874343872, -0.000985860824584961, 0.0007048845291137695,\n",
      "        -0.0013376474380493164, 0.0007048845291137695, -0.001127690076828003, -0.0013376474380493164,\n",
      "        -0.0001328587532043457, -0.002149134874343872, -0.0013376474380493164, -0.001127690076828003,\n",
      "        -0.004333555698394775, 0.0008583664894104004, -0.0013376474380493164, -0.0005843639373779297,\n",
      "        -0.006047636270523071, -0.0045545995235443115, -0.0013376474380493164, -0.002149134874343872,\n",
      "        -0.001127690076828003, -0.001127690076828003, -0.0013376474380493164, 0.001178741455078125,\n",
      "        -0.002149134874343872, -0.0029749274253845215, 0.0009470582008361816, -0.002149134874343872,\n",
      "        -0.0005843639373779297]\n",
      "  num_agent_steps_sampled: 60000\n",
      "  num_agent_steps_trained: 1916800\n",
      "  num_env_steps_sampled: 60000\n",
      "  num_env_steps_trained: 1916800\n",
      "  num_target_updates: 120\n",
      "iterations_since_restore: 60\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 60000\n",
      "num_agent_steps_trained: 1916800\n",
      "num_env_steps_sampled: 60000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.7662927344895\n",
      "num_env_steps_trained: 1916800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 568.521367503664\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 20.805\n",
      "  ram_util_percent: 71.63125000000001\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3761.716339111328\n",
      "time_this_iter_s: 56.30450105667114\n",
      "time_total_s: 3761.716339111328\n",
      "timers:\n",
      "  learn_throughput: 6292.483\n",
      "  learn_time_ms: 10.171\n",
      "  load_throughput: 553817.735\n",
      "  load_time_ms: 0.116\n",
      "  sample_time_ms: 88.06\n",
      "  synch_weights_time_ms: 3.08\n",
      "  training_iteration_time_ms: 112.448\n",
      "timestamp: 1709834458\n",
      "timesteps_total: 60000\n",
      "training_iteration: 60\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 61000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 61000\n",
      "  num_agent_steps_sampled: 61000\n",
      "  num_agent_steps_trained: 1948800\n",
      "  num_env_steps_sampled: 61000\n",
      "  num_env_steps_trained: 1948800\n",
      "  num_target_updates: 122\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-01-53\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 61000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 30449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.003915612120181322\n",
      "        max_q: 0.4868561327457428\n",
      "        mean_q: 0.4797411262989044\n",
      "        min_q: 0.47407081723213196\n",
      "      mean_td_error: -0.07741356641054153\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 30450.0\n",
      "      td_error: [0.0006999969482421875, -0.0025091469287872314, -0.0020360946655273438,\n",
      "        0.0062028467655181885, -0.0020360946655273438, 0.007196933031082153, 0.007196933031082153,\n",
      "        -4.999358654022217, 0.00064125657081604, -0.0020360946655273438, 0.00064125657081604,\n",
      "        0.007196933031082153, 0.007196933031082153, 0.00064125657081604, -0.0025091469287872314,\n",
      "        -0.0025091469287872314, -0.0025091469287872314, -0.0009718537330627441, 0.007196933031082153,\n",
      "        -0.002385079860687256, -0.0016773641109466553, 0.00044989585876464844, 0.007196933031082153,\n",
      "        -0.0012124478816986084, -0.0025091469287872314, -0.0006550252437591553, -0.0012124478816986084,\n",
      "        -0.0020360946655273438, -0.0012124478816986084, -0.004520922899246216, 0.00044989585876464844,\n",
      "        0.007196933031082153, -0.0020360946655273438, 0.010254472494125366, -0.00027817487716674805,\n",
      "        0.00044989585876464844, 0.007070571184158325, -0.0005366206169128418, 0.00064125657081604,\n",
      "        0.007070571184158325, -0.0025091469287872314, 0.00044989585876464844, 0.00064125657081604,\n",
      "        -0.0020360946655273438, -0.0020360946655273438, 0.00044989585876464844, 0.007196933031082153,\n",
      "        -0.0025091469287872314, 0.00064125657081604, -0.0020360946655273438, 0.00044989585876464844,\n",
      "        0.00064125657081604, -0.0012124478816986084, -0.0020360946655273438, -0.0009718537330627441,\n",
      "        -0.0020360946655273438, -0.0009718537330627441, 0.007196933031082153, -0.0020360946655273438,\n",
      "        0.007196933031082153, -0.002027958631515503, -0.0020360946655273438, -0.0012124478816986084,\n",
      "        -0.0025091469287872314]\n",
      "  num_agent_steps_sampled: 61000\n",
      "  num_agent_steps_trained: 1948800\n",
      "  num_env_steps_sampled: 61000\n",
      "  num_env_steps_trained: 1948800\n",
      "  num_target_updates: 122\n",
      "iterations_since_restore: 61\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 61000\n",
      "num_agent_steps_trained: 1948800\n",
      "num_env_steps_sampled: 61000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.99235124828247\n",
      "num_env_steps_trained: 1948800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 575.7552399450391\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.64615384615384\n",
      "  ram_util_percent: 71.95128205128206\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3817.314868211746\n",
      "time_this_iter_s: 55.59852910041809\n",
      "time_total_s: 3817.314868211746\n",
      "timers:\n",
      "  learn_throughput: 6143.559\n",
      "  learn_time_ms: 10.417\n",
      "  load_throughput: 750448.577\n",
      "  load_time_ms: 0.085\n",
      "  sample_time_ms: 82.192\n",
      "  synch_weights_time_ms: 3.063\n",
      "  training_iteration_time_ms: 106.576\n",
      "timestamp: 1709834513\n",
      "timesteps_total: 61000\n",
      "training_iteration: 61\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 62000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 62000\n",
      "  num_agent_steps_sampled: 62000\n",
      "  num_agent_steps_trained: 1980800\n",
      "  num_env_steps_sampled: 62000\n",
      "  num_env_steps_trained: 1980800\n",
      "  num_target_updates: 124\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-02-51\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 62000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 30949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.006227883975952864\n",
      "        max_q: 0.49149826169013977\n",
      "        mean_q: 0.4807301461696625\n",
      "        min_q: 0.4651494026184082\n",
      "      mean_td_error: 0.003321746364235878\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 30950.0\n",
      "      td_error: [0.013194859027862549, -0.009220033884048462, 0.0005957484245300293,\n",
      "        -0.009220033884048462, 0.0012637674808502197, 0.0005957484245300293, 0.0005957484245300293,\n",
      "        0.012719035148620605, 0.013089269399642944, 0.0005957484245300293, 0.013082236051559448,\n",
      "        0.009703397750854492, 0.009703397750854492, 0.013082236051559448, 0.009703397750854492,\n",
      "        -0.009220033884048462, 0.009703397750854492, -0.009220033884048462, -0.01008036732673645,\n",
      "        0.001796424388885498, 0.009703397750854492, -0.009220033884048462, 0.010157018899917603,\n",
      "        -0.009220033884048462, 0.013089269399642944, 0.01382550597190857, 0.013089269399642944,\n",
      "        0.01309320330619812, 0.009703397750854492, -0.00798371434211731, 0.013089269399642944,\n",
      "        -0.009024351835250854, 0.0012637674808502197, 0.0005957484245300293, -0.00923129916191101,\n",
      "        -0.00923129916191101, -0.008039295673370361, -0.00923129916191101, 0.012719035148620605,\n",
      "        0.013089269399642944, 0.009703397750854492, 0.009703397750854492, -0.007570475339889526,\n",
      "        0.013089269399642944, -0.00798371434211731, -0.009220033884048462, 0.0062406957149505615,\n",
      "        0.013099581003189087, -0.00923129916191101, 0.013089269399642944, 0.013089269399642944,\n",
      "        -0.008252859115600586, 0.013089269399642944, 0.01293957233428955, 0.013089269399642944,\n",
      "        0.013082236051559448, -0.009220033884048462, 0.009703397750854492, -0.00798371434211731,\n",
      "        0.009703397750854492, -0.00923129916191101, 0.01309320330619812, 0.013089269399642944,\n",
      "        -0.009220033884048462]\n",
      "  num_agent_steps_sampled: 62000\n",
      "  num_agent_steps_trained: 1980800\n",
      "  num_env_steps_sampled: 62000\n",
      "  num_env_steps_trained: 1980800\n",
      "  num_target_updates: 124\n",
      "iterations_since_restore: 62\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 62000\n",
      "num_agent_steps_trained: 1980800\n",
      "num_env_steps_sampled: 62000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.387587290896718\n",
      "num_env_steps_trained: 1980800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 556.402793308695\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 31.471951219512192\n",
      "  ram_util_percent: 72.36951219512193\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3874.8471031188965\n",
      "time_this_iter_s: 57.53223490715027\n",
      "time_total_s: 3874.8471031188965\n",
      "timers:\n",
      "  learn_throughput: 6145.937\n",
      "  learn_time_ms: 10.413\n",
      "  load_throughput: 714874.716\n",
      "  load_time_ms: 0.09\n",
      "  sample_time_ms: 83.706\n",
      "  synch_weights_time_ms: 3.172\n",
      "  training_iteration_time_ms: 108.892\n",
      "timestamp: 1709834571\n",
      "timesteps_total: 62000\n",
      "training_iteration: 62\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 63000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 63000\n",
      "  num_agent_steps_sampled: 63000\n",
      "  num_agent_steps_trained: 2012800\n",
      "  num_env_steps_sampled: 63000\n",
      "  num_env_steps_trained: 2012800\n",
      "  num_target_updates: 126\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-03-47\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 63000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 31449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.002696235664188862\n",
      "        max_q: 0.5041376948356628\n",
      "        mean_q: 0.4949052631855011\n",
      "        min_q: 0.48318910598754883\n",
      "      mean_td_error: 0.0007043308578431606\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 31450.0\n",
      "      td_error: [0.0011737346649169922, 0.0010545849800109863, -0.005716532468795776,\n",
      "        0.0010545849800109863, 0.0032104849815368652, -0.0016558468341827393, 0.0010545849800109863,\n",
      "        0.0032104849815368652, 0.009650468826293945, 0.0011737346649169922, 0.0032104849815368652,\n",
      "        -0.003461122512817383, 0.009650468826293945, 0.0011737346649169922, -0.001829385757446289,\n",
      "        0.009650468826293945, -0.0016558468341827393, 0.001316756010055542, 0.009650468826293945,\n",
      "        0.003205806016921997, 0.009380340576171875, 0.003205806016921997, 0.0010545849800109863,\n",
      "        0.009380340576171875, -0.0016558468341827393, -0.005649358034133911, -0.005716532468795776,\n",
      "        -0.005716532468795776, 0.0032104849815368652, 0.0010545849800109863, 0.009650468826293945,\n",
      "        0.0010545849800109863, -0.00593075156211853, -0.0016558468341827393, 0.0010545849800109863,\n",
      "        0.0011737346649169922, 0.0010545849800109863, -0.0016558468341827393, -0.0036346912384033203,\n",
      "        0.0003077685832977295, 0.0011737346649169922, 0.0032104849815368652, -0.005716532468795776,\n",
      "        0.009650468826293945, 0.0032104849815368652, -0.0016558468341827393, 0.0006098449230194092,\n",
      "        0.0010545849800109863, 0.0010545849800109863, -0.005716532468795776, -0.01134219765663147,\n",
      "        -0.005716532468795776, 0.0022037923336029053, 0.0010545849800109863, -0.0016558468341827393,\n",
      "        -0.0016558468341827393, -0.0016558468341827393, 0.0010545849800109863, 0.009650468826293945,\n",
      "        -0.005716532468795776, 0.0010545849800109863, 0.0032104849815368652, -0.0016558468341827393,\n",
      "        -0.005716532468795776]\n",
      "  num_agent_steps_sampled: 63000\n",
      "  num_agent_steps_trained: 2012800\n",
      "  num_env_steps_sampled: 63000\n",
      "  num_env_steps_trained: 2012800\n",
      "  num_target_updates: 126\n",
      "iterations_since_restore: 63\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 63000\n",
      "num_agent_steps_trained: 2012800\n",
      "num_env_steps_sampled: 63000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.793562058410988\n",
      "num_env_steps_trained: 2012800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 569.3939858691516\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.648101265822785\n",
      "  ram_util_percent: 73.1227848101266\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3931.0663011074066\n",
      "time_this_iter_s: 56.21919798851013\n",
      "time_total_s: 3931.0663011074066\n",
      "timers:\n",
      "  learn_throughput: 6051.445\n",
      "  learn_time_ms: 10.576\n",
      "  load_throughput: 553932.018\n",
      "  load_time_ms: 0.116\n",
      "  sample_time_ms: 91.792\n",
      "  synch_weights_time_ms: 3.144\n",
      "  training_iteration_time_ms: 117.525\n",
      "timestamp: 1709834627\n",
      "timesteps_total: 63000\n",
      "training_iteration: 63\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 93x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 64000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 64000\n",
      "  num_agent_steps_sampled: 64000\n",
      "  num_agent_steps_trained: 2044800\n",
      "  num_env_steps_sampled: 64000\n",
      "  num_env_steps_trained: 2044800\n",
      "  num_target_updates: 128\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-04-44\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 64000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 31949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0030661949422210455\n",
      "        max_q: 0.5028272867202759\n",
      "        mean_q: 0.494775652885437\n",
      "        min_q: 0.47801387310028076\n",
      "      mean_td_error: -0.0017307605594396591\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 31950.0\n",
      "      td_error: [0.005513668060302734, 0.00032508373260498047, -0.006147176027297974,\n",
      "        -0.006147176027297974, 0.00032508373260498047, -0.002263963222503662, -0.010590583086013794,\n",
      "        0.005513668060302734, 0.00032508373260498047, 0.0012455880641937256, 0.00032508373260498047,\n",
      "        0.005513668060302734, 0.0011920630931854248, -0.002263963222503662, -0.005334705114364624,\n",
      "        -0.0014644861221313477, -0.010590583086013794, 0.0011920630931854248, 0.00032508373260498047,\n",
      "        0.0011920630931854248, -0.010590583086013794, 0.00032508373260498047, 0.00032508373260498047,\n",
      "        0.00032508373260498047, -5.170702934265137e-05, -0.005334705114364624, 0.00032508373260498047,\n",
      "        -0.00798293948173523, -0.010590583086013794, -0.009473472833633423, -0.005334705114364624,\n",
      "        0.00032508373260498047, 0.0020291507244110107, 0.005513668060302734, 0.00032508373260498047,\n",
      "        -0.011372387409210205, 0.005513668060302734, -0.010590583086013794, -0.005334705114364624,\n",
      "        0.00032508373260498047, 0.005513668060302734, -0.005334705114364624, 0.00032508373260498047,\n",
      "        -0.002263963222503662, 0.00032508373260498047, -0.002263963222503662, 0.0007617473602294922,\n",
      "        0.0011920630931854248, 0.0007617473602294922, -0.003198862075805664, 0.00032508373260498047,\n",
      "        -0.010590583086013794, 0.005513668060302734, -0.006147176027297974, 0.005513668060302734,\n",
      "        -0.002263963222503662, 0.005513668060302734, -0.005334705114364624, -0.010590583086013794,\n",
      "        -0.002263963222503662, 0.00032508373260498047, -0.005334705114364624, 0.0041506290435791016,\n",
      "        -0.002263963222503662]\n",
      "  num_agent_steps_sampled: 64000\n",
      "  num_agent_steps_trained: 2044800\n",
      "  num_env_steps_sampled: 64000\n",
      "  num_env_steps_trained: 2044800\n",
      "  num_target_updates: 128\n",
      "iterations_since_restore: 64\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 64000\n",
      "num_agent_steps_trained: 2044800\n",
      "num_env_steps_sampled: 64000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.672918458593816\n",
      "num_env_steps_trained: 2044800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 565.5333906750021\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 27.578750000000003\n",
      "  ram_util_percent: 73.07875\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 3987.674771308899\n",
      "time_this_iter_s: 56.60847020149231\n",
      "time_total_s: 3987.674771308899\n",
      "timers:\n",
      "  learn_throughput: 5071.03\n",
      "  learn_time_ms: 12.621\n",
      "  load_throughput: 563348.281\n",
      "  load_time_ms: 0.114\n",
      "  sample_time_ms: 83.238\n",
      "  synch_weights_time_ms: 5.001\n",
      "  training_iteration_time_ms: 112.832\n",
      "timestamp: 1709834684\n",
      "timesteps_total: 64000\n",
      "training_iteration: 64\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 93x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 65000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "  StateBufferConnector_ms: 0.0025272369384765625\n",
      "  ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "counters:\n",
      "  last_target_update_ts: 65000\n",
      "  num_agent_steps_sampled: 65000\n",
      "  num_agent_steps_trained: 2076800\n",
      "  num_env_steps_sampled: 65000\n",
      "  num_env_steps_trained: 2076800\n",
      "  num_target_updates: 130\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-05-41\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 2.5\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 2\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 65000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 32449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.005440951324999332\n",
      "        max_q: 0.49267303943634033\n",
      "        mean_q: 0.48087337613105774\n",
      "        min_q: 0.45938143134117126\n",
      "      mean_td_error: -0.002970305737107992\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 32450.0\n",
      "      td_error: [-0.0026637613773345947, 0.009653449058532715, 0.0071357786655426025,\n",
      "        0.0044622719287872314, -0.00024703145027160645, -0.0026637613773345947, -0.0028138458728790283,\n",
      "        -0.00024703145027160645, -0.01762533187866211, -0.00024703145027160645, -0.008801460266113281,\n",
      "        0.0071357786655426025, 0.008871018886566162, -0.008801460266113281, 0.007364243268966675,\n",
      "        0.00599437952041626, -0.00024703145027160645, -0.013375341892242432, 0.007364243268966675,\n",
      "        0.00599437952041626, 0.007364243268966675, -0.009603679180145264, -0.008782804012298584,\n",
      "        0.004474252462387085, -0.00024703145027160645, 0.004474252462387085, 0.004474252462387085,\n",
      "        -0.00048729777336120605, -0.01762533187866211, 0.00599437952041626, -0.0026637613773345947,\n",
      "        -0.01762533187866211, -0.00024703145027160645, 0.007364243268966675, -0.008801460266113281,\n",
      "        -0.009285777807235718, -0.0026637613773345947, 0.007364243268966675, -0.008801460266113281,\n",
      "        -0.008801460266113281, -0.008801460266113281, 0.004474252462387085, -0.008801460266113281,\n",
      "        -0.01762533187866211, -0.008801460266113281, -0.008801460266113281, -0.01762533187866211,\n",
      "        -0.00024703145027160645, -0.01762533187866211, -0.008801460266113281, 0.0071357786655426025,\n",
      "        -0.008801460266113281, 0.007364243268966675, -0.017515331506729126, 0.0006237924098968506,\n",
      "        0.004474252462387085, 0.004474252462387085, -0.008801460266113281, -0.01762533187866211,\n",
      "        -0.008801460266113281, -0.0003746449947357178, -0.008801460266113281, -0.0026637613773345947,\n",
      "        -0.00024703145027160645]\n",
      "  num_agent_steps_sampled: 65000\n",
      "  num_agent_steps_trained: 2076800\n",
      "  num_env_steps_sampled: 65000\n",
      "  num_env_steps_trained: 2076800\n",
      "  num_target_updates: 130\n",
      "iterations_since_restore: 65\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 65000\n",
      "num_agent_steps_trained: 2076800\n",
      "num_env_steps_sampled: 65000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.41884095758275\n",
      "num_env_steps_trained: 2076800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 557.402910642648\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 32.69753086419753\n",
      "  ram_util_percent: 72.51975308641975\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04937605282500486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 77.96704728678063\n",
      "  mean_inference_ms: 0.9334915862301033\n",
      "  mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004041194915771484\n",
      "    StateBufferConnector_ms: 0.0025272369384765625\n",
      "    ViewRequirementAgentConnector_ms: 0.09806156158447266\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 2.5\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths:\n",
      "    - 16384\n",
      "    - 16384\n",
      "    episode_reward:\n",
      "    - 5.0\n",
      "    - 0.0\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04937605282500486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 77.96704728678063\n",
      "    mean_inference_ms: 0.9334915862301033\n",
      "    mean_raw_obs_processing_ms: 0.38346045884600005\n",
      "time_since_restore: 4045.102415561676\n",
      "time_this_iter_s: 57.4276442527771\n",
      "time_total_s: 4045.102415561676\n",
      "timers:\n",
      "  learn_throughput: 6033.261\n",
      "  learn_time_ms: 10.608\n",
      "  load_throughput: 693631.669\n",
      "  load_time_ms: 0.092\n",
      "  sample_time_ms: 93.496\n",
      "  synch_weights_time_ms: 3.26\n",
      "  training_iteration_time_ms: 119.374\n",
      "timestamp: 1709834741\n",
      "timesteps_total: 65000\n",
      "training_iteration: 65\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 66000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 66000\n",
      "  num_agent_steps_sampled: 66000\n",
      "  num_agent_steps_trained: 2108800\n",
      "  num_env_steps_sampled: 66000\n",
      "  num_env_steps_trained: 2108800\n",
      "  num_target_updates: 132\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-06-37\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 2\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 66000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 32949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.001134879537858069\n",
      "        max_q: 0.4847070276737213\n",
      "        mean_q: 0.48144736886024475\n",
      "        min_q: 0.47227463126182556\n",
      "      mean_td_error: -0.0011189049109816551\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 32950.0\n",
      "      td_error: [0.0009728074073791504, -0.0005154609680175781, -0.0012280642986297607,\n",
      "        0.0015482306480407715, -0.002398282289505005, -0.002398282289505005, -0.0012280642986297607,\n",
      "        -0.001737445592880249, 0.001314789056777954, -0.002398282289505005, -0.002398282289505005,\n",
      "        -0.0001335442066192627, -0.0005154609680175781, -0.0012280642986297607, -0.0025947093963623047,\n",
      "        -0.0005154609680175781, -0.0012280642986297607, 0.0009728074073791504, -0.0001335442066192627,\n",
      "        -0.002398282289505005, -0.002398282289505005, -0.0005154609680175781, -0.0012280642986297607,\n",
      "        -0.0018396973609924316, 0.00047907233238220215, 0.0009728074073791504, -0.002398282289505005,\n",
      "        -0.0018396973609924316, 0.0009728074073791504, -0.014682590961456299, 0.0009728074073791504,\n",
      "        -0.002398282289505005, 0.0009728074073791504, -0.002398282289505005, -0.0001335442066192627,\n",
      "        -0.001737445592880249, 0.0009728074073791504, -0.0012280642986297607, -0.004455596208572388,\n",
      "        -0.0001335442066192627, -0.002398282289505005, -0.0012280642986297607, -0.0012280642986297607,\n",
      "        -0.0025947093963623047, 0.0009728074073791504, 0.0009728074073791504, 0.0009728074073791504,\n",
      "        -0.002554655075073242, 0.0015482306480407715, -0.0018396973609924316, -0.0001335442066192627,\n",
      "        -0.0001335442066192627, -0.0001335442066192627, -0.0018396973609924316, -0.0012280642986297607,\n",
      "        -0.0005154609680175781, -0.002398282289505005, -0.0018396973609924316, -0.0005154609680175781,\n",
      "        -0.00016742944717407227, -0.0018396973609924316, -0.0007481575012207031, -0.0012280642986297607,\n",
      "        -0.0012280642986297607]\n",
      "  num_agent_steps_sampled: 66000\n",
      "  num_agent_steps_trained: 2108800\n",
      "  num_env_steps_sampled: 66000\n",
      "  num_env_steps_trained: 2108800\n",
      "  num_target_updates: 132\n",
      "iterations_since_restore: 66\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 66000\n",
      "num_agent_steps_trained: 2108800\n",
      "num_env_steps_sampled: 66000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 18.03846124154753\n",
      "num_env_steps_trained: 2108800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 577.230759729521\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.841772151898738\n",
      "  ram_util_percent: 72.59367088607594\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 2\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4100.557684421539\n",
      "time_this_iter_s: 55.45526885986328\n",
      "time_total_s: 4100.557684421539\n",
      "timers:\n",
      "  learn_throughput: 6128.607\n",
      "  learn_time_ms: 10.443\n",
      "  load_throughput: 645432.691\n",
      "  load_time_ms: 0.099\n",
      "  sample_time_ms: 80.335\n",
      "  synch_weights_time_ms: 3.101\n",
      "  training_iteration_time_ms: 105.007\n",
      "timestamp: 1709834797\n",
      "timesteps_total: 66000\n",
      "training_iteration: 66\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 67000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 67000\n",
      "  num_agent_steps_sampled: 67000\n",
      "  num_agent_steps_trained: 2140800\n",
      "  num_env_steps_sampled: 67000\n",
      "  num_env_steps_trained: 2140800\n",
      "  num_target_updates: 134\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-07-34\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 67000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 33449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0016292502405121922\n",
      "        max_q: 0.479280024766922\n",
      "        mean_q: 0.47620123624801636\n",
      "        min_q: 0.46755245327949524\n",
      "      mean_td_error: -0.001796714961528778\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 33450.0\n",
      "      td_error: [0.000557631254196167, -0.0028267204761505127, 0.0010294616222381592,\n",
      "        -0.0005529224872589111, -0.0016477108001708984, -0.0034269392490386963, -0.0028267204761505127,\n",
      "        0.000557631254196167, -0.001543283462524414, 0.0010294616222381592, -0.00015804171562194824,\n",
      "        0.001010596752166748, -0.0018725395202636719, -0.0028267204761505127, -0.0034269392490386963,\n",
      "        -0.0010088086128234863, 0.000557631254196167, -0.0028267204761505127, -0.0010088086128234863,\n",
      "        -0.0034269392490386963, -0.0028267204761505127, -0.0034269392490386963, -0.0034269392490386963,\n",
      "        -0.0017667114734649658, 0.0003833174705505371, -0.0034269392490386963, -0.0010088086128234863,\n",
      "        -0.003858894109725952, 0.000557631254196167, -0.0034269392490386963, -0.0028267204761505127,\n",
      "        -0.001543283462524414, -0.0010088086128234863, -0.00042301416397094727, 0.000557631254196167,\n",
      "        0.000557631254196167, -0.0034054219722747803, -0.0028267204761505127, -0.0059753358364105225,\n",
      "        0.000557631254196167, -0.0034269392490386963, -0.001543283462524414, -0.0028267204761505127,\n",
      "        -0.0028267204761505127, -0.0016477108001708984, 0.000557631254196167, -0.0017667114734649658,\n",
      "        -0.0034269392490386963, -0.001543283462524414, -0.0016104280948638916, -0.0010088086128234863,\n",
      "        -0.0028267204761505127, -0.0028267204761505127, 0.000557631254196167, -0.0032275915145874023,\n",
      "        -0.0028267204761505127, -0.0028267204761505127, -0.003935366868972778, -0.0017667114734649658,\n",
      "        -0.0017667114734649658, -0.001543283462524414, -0.00015804171562194824, -0.0034269392490386963,\n",
      "        -0.004144191741943359]\n",
      "  num_agent_steps_sampled: 67000\n",
      "  num_agent_steps_trained: 2140800\n",
      "  num_env_steps_sampled: 67000\n",
      "  num_env_steps_trained: 2140800\n",
      "  num_target_updates: 134\n",
      "iterations_since_restore: 67\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 67000\n",
      "num_agent_steps_trained: 2140800\n",
      "num_env_steps_sampled: 67000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.436182626426774\n",
      "num_env_steps_trained: 2140800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 557.9578440456568\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 33.50987654320987\n",
      "  ram_util_percent: 73.91358024691358\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4157.931434392929\n",
      "time_this_iter_s: 57.37374997138977\n",
      "time_total_s: 4157.931434392929\n",
      "timers:\n",
      "  learn_throughput: 6026.177\n",
      "  learn_time_ms: 10.62\n",
      "  load_throughput: 673445.7\n",
      "  load_time_ms: 0.095\n",
      "  sample_time_ms: 94.244\n",
      "  synch_weights_time_ms: 3.231\n",
      "  training_iteration_time_ms: 120.683\n",
      "timestamp: 1709834854\n",
      "timesteps_total: 67000\n",
      "training_iteration: 67\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 68000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 68000\n",
      "  num_agent_steps_sampled: 68000\n",
      "  num_agent_steps_trained: 2172800\n",
      "  num_env_steps_sampled: 68000\n",
      "  num_env_steps_trained: 2172800\n",
      "  num_target_updates: 136\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-08-30\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 68000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 33949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.002334616845473647\n",
      "        max_q: 0.4774719774723053\n",
      "        mean_q: 0.4730607271194458\n",
      "        min_q: 0.4650309085845947\n",
      "      mean_td_error: -0.0022348077036440372\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 33950.0\n",
      "      td_error: [-0.0045912861824035645, -0.005165219306945801, -5.9157609939575195e-05,\n",
      "        -0.0021257400512695312, -0.0001551210880279541, -0.004615336656570435, -0.005165219306945801,\n",
      "        -0.0001551210880279541, -0.00478556752204895, 0.0011532008647918701, -0.0021629035472869873,\n",
      "        -0.005165219306945801, -0.0045912861824035645, -0.0045912861824035645, -0.0028990209102630615,\n",
      "        -0.0003895759582519531, -0.0001551210880279541, -0.005165219306945801, -0.004203766584396362,\n",
      "        0.0011532008647918701, -0.0045912861824035645, -0.005165219306945801, -0.0045912861824035645,\n",
      "        -0.0028990209102630615, 0.0011532008647918701, -0.0058234333992004395, -0.0003895759582519531,\n",
      "        -0.0045912861824035645, -0.0003895759582519531, -0.0016180872917175293, 0.0011532008647918701,\n",
      "        -0.0001551210880279541, -0.0045912861824035645, -0.0001551210880279541, -0.0013072788715362549,\n",
      "        -0.0028990209102630615, 0.0011532008647918701, -0.0001551210880279541, 0.0011532008647918701,\n",
      "        -0.0021829307079315186, 0.0011532008647918701, -0.005165219306945801, -0.0001551210880279541,\n",
      "        -0.004695683717727661, 0.0011532008647918701, -0.00478556752204895, -0.004203766584396362,\n",
      "        -0.0013321936130523682, -0.005449354648590088, -0.0003895759582519531, -0.005165219306945801,\n",
      "        -0.0003895759582519531, -0.0001551210880279541, -0.0045912861824035645, -0.0001551210880279541,\n",
      "        -0.0028990209102630615, -0.0007861852645874023, -0.0028990209102630615, -0.0001551210880279541,\n",
      "        -0.0045912861824035645, -0.002242445945739746, -0.0003895759582519531, 0.0011532008647918701,\n",
      "        -0.005165219306945801]\n",
      "  num_agent_steps_sampled: 68000\n",
      "  num_agent_steps_trained: 2172800\n",
      "  num_env_steps_sampled: 68000\n",
      "  num_env_steps_trained: 2172800\n",
      "  num_target_updates: 136\n",
      "iterations_since_restore: 68\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 68000\n",
      "num_agent_steps_trained: 2172800\n",
      "num_env_steps_sampled: 68000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.757981279456864\n",
      "num_env_steps_trained: 2172800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 568.2554009426196\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.6175\n",
      "  ram_util_percent: 75.55\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4214.262713670731\n",
      "time_this_iter_s: 56.331279277801514\n",
      "time_total_s: 4214.262713670731\n",
      "timers:\n",
      "  learn_throughput: 6106.093\n",
      "  learn_time_ms: 10.481\n",
      "  load_throughput: 564177.083\n",
      "  load_time_ms: 0.113\n",
      "  sample_time_ms: 96.534\n",
      "  synch_weights_time_ms: 3.182\n",
      "  training_iteration_time_ms: 121.91\n",
      "timestamp: 1709834910\n",
      "timesteps_total: 68000\n",
      "training_iteration: 68\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 69000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 69000\n",
      "  num_agent_steps_sampled: 69000\n",
      "  num_agent_steps_trained: 2204800\n",
      "  num_env_steps_sampled: 69000\n",
      "  num_env_steps_trained: 2204800\n",
      "  num_target_updates: 138\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-09-27\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 69000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 34449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0038176667876541615\n",
      "        max_q: 0.4843050539493561\n",
      "        mean_q: 0.47757530212402344\n",
      "        min_q: 0.46706777811050415\n",
      "      mean_td_error: 0.008650042116641998\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 34450.0\n",
      "      td_error: [-0.003854811191558838, 0.0008588433265686035, 0.0012515783309936523,\n",
      "        0.006909787654876709, 0.0012515783309936523, -0.002231776714324951, 0.006472289562225342,\n",
      "        0.006472289562225342, -0.0005746185779571533, -0.002231776714324951, -0.002231776714324951,\n",
      "        -0.0015016794204711914, -0.002231776714324951, -0.002231776714324951, 0.0008588433265686035,\n",
      "        0.006472289562225342, -0.0015016794204711914, 0.0012515783309936523, 0.0012515783309936523,\n",
      "        0.006909787654876709, 0.006909787654876709, -0.002231776714324951, -0.002231776714324951,\n",
      "        -0.002231776714324951, -0.002231776714324951, -0.0015016794204711914, 0.006909787654876709,\n",
      "        0.47793132066726685, 0.0012515783309936523, 0.0012515783309936523, 0.006369858980178833,\n",
      "        -0.0036314427852630615, 0.00773996114730835, -0.003448188304901123, 0.0012515783309936523,\n",
      "        0.0012515783309936523, 0.006909787654876709, 0.0008588433265686035, 0.006909787654876709,\n",
      "        0.0012515783309936523, -0.0015016794204711914, -0.0015016794204711914, 0.0005783736705780029,\n",
      "        -0.0003943443298339844, 0.0012515783309936523, 0.0008588433265686035, 0.0012515783309936523,\n",
      "        -0.0003943443298339844, 0.0008588433265686035, -0.0015016794204711914, -0.002231776714324951,\n",
      "        -0.0015016794204711914, 0.0008588433265686035, -0.0015849471092224121, 0.0008588433265686035,\n",
      "        0.0008588433265686035, -0.0017018616199493408, 0.0009719431400299072, 0.006909787654876709,\n",
      "        0.0012515783309936523, 0.007143497467041016, -0.002231776714324951, 0.007366210222244263,\n",
      "        0.006472289562225342]\n",
      "  num_agent_steps_sampled: 69000\n",
      "  num_agent_steps_trained: 2204800\n",
      "  num_env_steps_sampled: 69000\n",
      "  num_env_steps_trained: 2204800\n",
      "  num_target_updates: 138\n",
      "iterations_since_restore: 69\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 69000\n",
      "num_agent_steps_trained: 2204800\n",
      "num_env_steps_sampled: 69000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.561409722597276\n",
      "num_env_steps_trained: 2204800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 561.9651111231128\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.467499999999998\n",
      "  ram_util_percent: 76.46125\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4271.224671602249\n",
      "time_this_iter_s: 56.961957931518555\n",
      "time_total_s: 4271.224671602249\n",
      "timers:\n",
      "  learn_throughput: 6142.393\n",
      "  learn_time_ms: 10.419\n",
      "  load_throughput: 766520.434\n",
      "  load_time_ms: 0.083\n",
      "  sample_time_ms: 83.707\n",
      "  synch_weights_time_ms: 3.143\n",
      "  training_iteration_time_ms: 108.695\n",
      "timestamp: 1709834967\n",
      "timesteps_total: 69000\n",
      "training_iteration: 69\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 85x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 70000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 70000\n",
      "  num_agent_steps_sampled: 70000\n",
      "  num_agent_steps_trained: 2236800\n",
      "  num_env_steps_sampled: 70000\n",
      "  num_env_steps_trained: 2236800\n",
      "  num_target_updates: 140\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-10-23\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 70000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 34949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.006760432384908199\n",
      "        max_q: 0.49354422092437744\n",
      "        mean_q: 0.48017969727516174\n",
      "        min_q: 0.4637187719345093\n",
      "      mean_td_error: 0.0010232306085526943\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 34950.0\n",
      "      td_error: [-0.006527632474899292, -0.006527632474899292, -0.006527632474899292,\n",
      "        0.0023330748081207275, 0.013828963041305542, 0.013828963041305542, -0.007235735654830933,\n",
      "        0.013828963041305542, 0.013828963041305542, -0.0004934072494506836, -0.006527632474899292,\n",
      "        0.013828963041305542, 0.0023330748081207275, 0.013828963041305542, -0.0076379477977752686,\n",
      "        -0.0049194395542144775, 0.0023330748081207275, -0.006527632474899292, -0.0004934072494506836,\n",
      "        0.013482630252838135, 0.013828963041305542, 0.013828963041305542, -0.009432792663574219,\n",
      "        -0.0004934072494506836, -0.006527632474899292, 0.013828963041305542, -0.00534290075302124,\n",
      "        -0.006527632474899292, 0.013828963041305542, 0.0023330748081207275, -0.006527632474899292,\n",
      "        -0.0076379477977752686, 0.013828963041305542, -0.0076379477977752686, -0.0076379477977752686,\n",
      "        0.0023330748081207275, -0.006527632474899292, 0.013828963041305542, 0.013828963041305542,\n",
      "        -0.006527632474899292, 0.013828963041305542, -0.007198691368103027, -0.0004934072494506836,\n",
      "        -0.0076379477977752686, -0.006527632474899292, 0.011014312505722046, 0.013828963041305542,\n",
      "        -0.0049194395542144775, -0.0004934072494506836, -0.0004934072494506836, -0.006527632474899292,\n",
      "        0.0023330748081207275, -1.4275312423706055e-05, -0.0004934072494506836, -0.0076379477977752686,\n",
      "        -0.006527632474899292, -0.0049194395542144775, -0.0049194395542144775, 0.0023330748081207275,\n",
      "        -0.0076379477977752686, 0.013828963041305542, 0.0010967850685119629, -0.0004934072494506836,\n",
      "        -0.006527632474899292]\n",
      "  num_agent_steps_sampled: 70000\n",
      "  num_agent_steps_trained: 2236800\n",
      "  num_env_steps_sampled: 70000\n",
      "  num_env_steps_trained: 2236800\n",
      "  num_target_updates: 140\n",
      "iterations_since_restore: 70\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 70000\n",
      "num_agent_steps_trained: 2236800\n",
      "num_env_steps_sampled: 70000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.873028080787357\n",
      "num_env_steps_trained: 2236800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 571.9368985851954\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 32.69113924050633\n",
      "  ram_util_percent: 75.10759493670886\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4327.19310259819\n",
      "time_this_iter_s: 55.96843099594116\n",
      "time_total_s: 4327.19310259819\n",
      "timers:\n",
      "  learn_throughput: 6142.632\n",
      "  learn_time_ms: 10.419\n",
      "  load_throughput: 633849.955\n",
      "  load_time_ms: 0.101\n",
      "  sample_time_ms: 89.741\n",
      "  synch_weights_time_ms: 3.11\n",
      "  training_iteration_time_ms: 115.091\n",
      "timestamp: 1709835023\n",
      "timesteps_total: 70000\n",
      "training_iteration: 70\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 147x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 72x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 71000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 71000\n",
      "  num_agent_steps_sampled: 71000\n",
      "  num_agent_steps_trained: 2268800\n",
      "  num_env_steps_sampled: 71000\n",
      "  num_env_steps_trained: 2268800\n",
      "  num_target_updates: 142\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-11-19\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 71000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 35449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0030780667439103127\n",
      "        max_q: 0.4870130121707916\n",
      "        mean_q: 0.4818571209907532\n",
      "        min_q: 0.4674142897129059\n",
      "      mean_td_error: 0.0027994844131171703\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 35450.0\n",
      "      td_error: [0.001226574182510376, 0.00038427114486694336, 0.00038427114486694336,\n",
      "        0.001226574182510376, 0.004341214895248413, 0.00038427114486694336, -0.005974292755126953,\n",
      "        0.001226574182510376, -0.0025429129600524902, 0.004341214895248413, -0.005974292755126953,\n",
      "        0.007368862628936768, -0.005974292755126953, 0.004341214895248413, 0.001226574182510376,\n",
      "        0.004341214895248413, 0.001226574182510376, 0.00522187352180481, 0.007368862628936768,\n",
      "        0.00522187352180481, 0.007368862628936768, 0.007368862628936768, 0.001226574182510376,\n",
      "        0.001226574182510376, -0.005974292755126953, 0.004341214895248413, 0.004341214895248413,\n",
      "        0.004341214895248413, 0.00038427114486694336, 0.00522187352180481, 0.004341214895248413,\n",
      "        0.007368862628936768, 0.00522187352180481, 0.00038427114486694336, -0.005974292755126953,\n",
      "        0.007368862628936768, 0.003600507974624634, 0.007368862628936768, 0.007368862628936768,\n",
      "        0.007368862628936768, 0.00038427114486694336, 0.001226574182510376, 0.007368862628936768,\n",
      "        0.007368862628936768, 0.004341214895248413, 0.00038427114486694336, 0.001226574182510376,\n",
      "        0.004341214895248413, 0.001226574182510376, 0.004341214895248413, 0.00522187352180481,\n",
      "        -0.006446540355682373, 0.001982957124710083, 0.00038427114486694336, 0.00038427114486694336,\n",
      "        0.0034312307834625244, 0.0041675567626953125, 0.004341214895248413, 0.0006463825702667236,\n",
      "        0.007368862628936768, 0.007940500974655151, 0.004341214895248413, 0.004341214895248413,\n",
      "        0.00522187352180481]\n",
      "  num_agent_steps_sampled: 71000\n",
      "  num_agent_steps_trained: 2268800\n",
      "  num_env_steps_sampled: 71000\n",
      "  num_env_steps_trained: 2268800\n",
      "  num_target_updates: 142\n",
      "iterations_since_restore: 71\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 71000\n",
      "num_agent_steps_trained: 2268800\n",
      "num_env_steps_sampled: 71000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 18.036953637423046\n",
      "num_env_steps_trained: 2268800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 577.1825163975375\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 23.759493670886076\n",
      "  ram_util_percent: 78.3139240506329\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4382.654047727585\n",
      "time_this_iter_s: 55.46094512939453\n",
      "time_total_s: 4382.654047727585\n",
      "timers:\n",
      "  learn_throughput: 6053.861\n",
      "  learn_time_ms: 10.572\n",
      "  load_throughput: 737055.069\n",
      "  load_time_ms: 0.087\n",
      "  sample_time_ms: 85.753\n",
      "  synch_weights_time_ms: 4.012\n",
      "  training_iteration_time_ms: 111.995\n",
      "timestamp: 1709835079\n",
      "timesteps_total: 71000\n",
      "training_iteration: 71\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 97x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 72000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 72000\n",
      "  num_agent_steps_sampled: 72000\n",
      "  num_agent_steps_trained: 2300800\n",
      "  num_env_steps_sampled: 72000\n",
      "  num_env_steps_trained: 2300800\n",
      "  num_target_updates: 144\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-12-14\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 72000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 35949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.003115925472229719\n",
      "        max_q: 0.48147547245025635\n",
      "        mean_q: 0.4740242660045624\n",
      "        min_q: 0.4625451862812042\n",
      "      mean_td_error: -0.0014340849593281746\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 35950.0\n",
      "      td_error: [0.0010769367218017578, 0.005876868963241577, 0.003244251012802124,\n",
      "        0.003244251012802124, 0.003244251012802124, 0.005625694990158081, -0.0051136016845703125,\n",
      "        -0.013023287057876587, -0.004455298185348511, 0.0010769367218017578, 0.0010769367218017578,\n",
      "        0.0010769367218017578, -0.0051136016845703125, -0.0055043697357177734, -0.004455298185348511,\n",
      "        0.003244251012802124, 0.003244251012802124, -0.004455298185348511, -0.004455298185348511,\n",
      "        0.0010769367218017578, 0.0002467930316925049, -0.0051136016845703125, -0.004455298185348511,\n",
      "        0.0010769367218017578, 0.005625694990158081, -0.0051136016845703125, 0.0010769367218017578,\n",
      "        -0.0051136016845703125, -0.013023287057876587, 0.005625694990158081, 0.0010769367218017578,\n",
      "        -0.004455298185348511, 0.0010769367218017578, 0.005940854549407959, -0.004473179578781128,\n",
      "        -0.013023287057876587, 0.003244251012802124, -0.0051136016845703125, -0.004455298185348511,\n",
      "        -0.013587146997451782, -0.0051136016845703125, 0.0028241872787475586, -0.0051136016845703125,\n",
      "        -0.013023287057876587, -0.0051136016845703125, 0.005625694990158081, -0.004455298185348511,\n",
      "        0.0035619139671325684, 0.0010769367218017578, 0.005625694990158081, -0.004455298185348511,\n",
      "        -0.0051136016845703125, -0.005410522222518921, -0.006203889846801758, 0.0034290552139282227,\n",
      "        -0.005380481481552124, 0.005625694990158081, 0.0010769367218017578, 0.003244251012802124,\n",
      "        -0.013023287057876587, 0.0028241872787475586, 0.005625694990158081, 0.003244251012802124,\n",
      "        0.003244251012802124]\n",
      "  num_agent_steps_sampled: 72000\n",
      "  num_agent_steps_trained: 2300800\n",
      "  num_env_steps_sampled: 72000\n",
      "  num_env_steps_trained: 2300800\n",
      "  num_target_updates: 144\n",
      "iterations_since_restore: 72\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 72000\n",
      "num_agent_steps_trained: 2300800\n",
      "num_env_steps_sampled: 72000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.967876681751576\n",
      "num_env_steps_trained: 2300800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 574.9720538160504\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.472151898734175\n",
      "  ram_util_percent: 78.62911392405064\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4438.327899932861\n",
      "time_this_iter_s: 55.67385220527649\n",
      "time_total_s: 4438.327899932861\n",
      "timers:\n",
      "  learn_throughput: 6057.235\n",
      "  learn_time_ms: 10.566\n",
      "  load_throughput: 640046.39\n",
      "  load_time_ms: 0.1\n",
      "  sample_time_ms: 92.782\n",
      "  synch_weights_time_ms: 3.142\n",
      "  training_iteration_time_ms: 118.17\n",
      "timestamp: 1709835134\n",
      "timesteps_total: 72000\n",
      "training_iteration: 72\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 73000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 73000\n",
      "  num_agent_steps_sampled: 73000\n",
      "  num_agent_steps_trained: 2332800\n",
      "  num_env_steps_sampled: 73000\n",
      "  num_env_steps_trained: 2332800\n",
      "  num_target_updates: 146\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-13-11\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 73000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 36449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.002644656226038933\n",
      "        max_q: 0.4834749102592468\n",
      "        mean_q: 0.4792855978012085\n",
      "        min_q: 0.4718911051750183\n",
      "      mean_td_error: 0.0019004200585186481\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 36450.0\n",
      "      td_error: [0.0022346973419189453, 0.0056272149085998535, 0.0022346973419189453,\n",
      "        -0.005782395601272583, 0.00021123886108398438, -0.005782395601272583, 0.005801409482955933,\n",
      "        0.0022346973419189453, 0.005801409482955933, 0.004347622394561768, 0.00021123886108398438,\n",
      "        0.0022346973419189453, 0.005801409482955933, 0.004347622394561768, 0.004347622394561768,\n",
      "        0.005801409482955933, 0.00021123886108398438, 0.00021123886108398438, 0.00021123886108398438,\n",
      "        0.004347622394561768, 0.00021123886108398438, 0.005801409482955933, 0.005801409482955933,\n",
      "        0.005801409482955933, 0.0007101595401763916, -0.004091769456863403, 0.005801409482955933,\n",
      "        0.00021123886108398438, 0.005801409482955933, 0.00021123886108398438, 0.00021123886108398438,\n",
      "        0.0022346973419189453, 0.0022346973419189453, -0.0038893818855285645, 0.00021123886108398438,\n",
      "        -0.004091769456863403, 0.004347622394561768, 0.0025967061519622803, -0.004091769456863403,\n",
      "        -3.382563591003418e-05, 0.005801409482955933, 0.005801409482955933, 0.004347622394561768,\n",
      "        0.004347622394561768, 0.005801409482955933, 0.004347622394561768, 0.00021123886108398438,\n",
      "        0.005801409482955933, 0.00021123886108398438, 0.0009101331233978271, -0.005782395601272583,\n",
      "        0.004347622394561768, 0.00021123886108398438, 0.003466665744781494, 0.00021123886108398438,\n",
      "        0.004347622394561768, 0.005801409482955933, 0.0022346973419189453, -0.005782395601272583,\n",
      "        -0.005782395601272583, 0.0022346973419189453, 0.0022346973419189453, 0.0054496824741363525,\n",
      "        0.00021123886108398438]\n",
      "  num_agent_steps_sampled: 73000\n",
      "  num_agent_steps_trained: 2332800\n",
      "  num_env_steps_sampled: 73000\n",
      "  num_env_steps_trained: 2332800\n",
      "  num_target_updates: 146\n",
      "iterations_since_restore: 73\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 73000\n",
      "num_agent_steps_trained: 2332800\n",
      "num_env_steps_sampled: 73000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.622568199878916\n",
      "num_env_steps_trained: 2332800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 563.9221823961253\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.5\n",
      "  ram_util_percent: 76.40987654320988\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4495.092199087143\n",
      "time_this_iter_s: 56.764299154281616\n",
      "time_total_s: 4495.092199087143\n",
      "timers:\n",
      "  learn_throughput: 6152.853\n",
      "  learn_time_ms: 10.402\n",
      "  load_throughput: 685483.8\n",
      "  load_time_ms: 0.093\n",
      "  sample_time_ms: 91.604\n",
      "  synch_weights_time_ms: 3.22\n",
      "  training_iteration_time_ms: 116.701\n",
      "timestamp: 1709835191\n",
      "timesteps_total: 73000\n",
      "training_iteration: 73\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 93x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 74000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 74000\n",
      "  num_agent_steps_sampled: 74000\n",
      "  num_agent_steps_trained: 2364800\n",
      "  num_env_steps_sampled: 74000\n",
      "  num_env_steps_trained: 2364800\n",
      "  num_target_updates: 148\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-14-07\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 74000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 36949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.005175617057830095\n",
      "        max_q: 0.47648167610168457\n",
      "        mean_q: 0.4731660783290863\n",
      "        min_q: 0.4600299000740051\n",
      "      mean_td_error: -0.07990187406539917\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 36950.0\n",
      "      td_error: [0.0004525482654571533, 0.000989466905593872, -9.351968765258789e-05,\n",
      "        0.0004525482654571533, 0.0004525482654571533, 0.0010941624641418457, -0.010894715785980225,\n",
      "        0.0007108747959136963, -9.351968765258789e-05, -0.011557728052139282, 0.0004525482654571533,\n",
      "        0.0007108747959136963, 0.0010941624641418457, 0.0007873773574829102, 0.0004525482654571533,\n",
      "        -0.006951481103897095, -5.006951332092285, -9.351968765258789e-05, 0.0004525482654571533,\n",
      "        -9.351968765258789e-05, -0.010880738496780396, 0.0010941624641418457, -0.010880738496780396,\n",
      "        -0.006951481103897095, 0.000989466905593872, -9.351968765258789e-05, 0.0007108747959136963,\n",
      "        0.0010941624641418457, -0.006951481103897095, 0.0010941624641418457, 0.0007108747959136963,\n",
      "        -9.351968765258789e-05, -9.351968765258789e-05, -0.006951481103897095, -0.011033117771148682,\n",
      "        0.0007108747959136963, 0.001257777214050293, -0.010880738496780396, 0.0007108747959136963,\n",
      "        0.0004525482654571533, -0.010880738496780396, 0.0009216368198394775, 0.0004525482654571533,\n",
      "        0.0010941624641418457, 0.0010941624641418457, 0.0010941624641418457, 0.0007108747959136963,\n",
      "        0.0004525482654571533, -9.351968765258789e-05, 0.0004525482654571533, 0.0010941624641418457,\n",
      "        -0.010880738496780396, 0.0007108747959136963, -0.006951481103897095, 0.0010941624641418457,\n",
      "        0.0010941624641418457, 0.0004525482654571533, 0.0007108747959136963, 0.0007108747959136963,\n",
      "        0.0004525482654571533, -0.007365405559539795, -0.006951481103897095, 0.0007108747959136963,\n",
      "        0.0007108747959136963]\n",
      "  num_agent_steps_sampled: 74000\n",
      "  num_agent_steps_trained: 2364800\n",
      "  num_env_steps_sampled: 74000\n",
      "  num_env_steps_trained: 2364800\n",
      "  num_target_updates: 148\n",
      "iterations_since_restore: 74\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 74000\n",
      "num_agent_steps_trained: 2364800\n",
      "num_env_steps_sampled: 74000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 18.07699823315537\n",
      "num_env_steps_trained: 2364800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 578.4639434609718\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.09493670886076\n",
      "  ram_util_percent: 74.70632911392406\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4550.429327249527\n",
      "time_this_iter_s: 55.33712816238403\n",
      "time_total_s: 4550.429327249527\n",
      "timers:\n",
      "  learn_throughput: 6076.225\n",
      "  learn_time_ms: 10.533\n",
      "  load_throughput: 513064.709\n",
      "  load_time_ms: 0.125\n",
      "  sample_time_ms: 77.236\n",
      "  synch_weights_time_ms: 3.142\n",
      "  training_iteration_time_ms: 102.374\n",
      "timestamp: 1709835247\n",
      "timesteps_total: 74000\n",
      "training_iteration: 74\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 98x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 75000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 75000\n",
      "  num_agent_steps_sampled: 75000\n",
      "  num_agent_steps_trained: 2396800\n",
      "  num_env_steps_sampled: 75000\n",
      "  num_env_steps_trained: 2396800\n",
      "  num_target_updates: 150\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-15-02\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 75000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 37449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.003952454775571823\n",
      "        max_q: 0.4827260375022888\n",
      "        mean_q: 0.47503185272216797\n",
      "        min_q: 0.46495118737220764\n",
      "      mean_td_error: -0.0036952910013496876\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 37450.0\n",
      "      td_error: [0.0033469200134277344, -0.014093130826950073, -0.0014309585094451904,\n",
      "        -0.003908634185791016, -0.007860362529754639, -0.0014309585094451904, -0.0014309585094451904,\n",
      "        0.0033469200134277344, -0.003908634185791016, 0.005361199378967285, -0.007860362529754639,\n",
      "        -0.003908634185791016, -0.0014309585094451904, -0.0016585290431976318, -0.007860362529754639,\n",
      "        -0.014093130826950073, -0.003908634185791016, -0.007860362529754639, -0.003908634185791016,\n",
      "        0.005362272262573242, -0.003908634185791016, -0.007860362529754639, 0.0033469200134277344,\n",
      "        -0.0014309585094451904, -0.003205209970474243, -0.003908634185791016, -0.014093130826950073,\n",
      "        -0.0016585290431976318, -0.014093130826950073, -0.0014309585094451904, 0.0033469200134277344,\n",
      "        -0.003908634185791016, 0.0036574900150299072, -0.003908634185791016, 0.0036574900150299072,\n",
      "        0.0033469200134277344, -0.003908634185791016, 0.0033469200134277344, -0.007860362529754639,\n",
      "        -0.003908634185791016, 0.005361199378967285, 0.0036574900150299072, -0.0014309585094451904,\n",
      "        -0.0014309585094451904, -0.003908634185791016, -0.0014309585094451904, -0.014093130826950073,\n",
      "        -0.0022957921028137207, -0.014093130826950073, -0.006988555192947388, -0.0014309585094451904,\n",
      "        -0.014093130826950073, -0.014093130826950073, -0.013245552778244019, -0.0014309585094451904,\n",
      "        -0.0014309585094451904, -0.007860362529754639, -0.007860362529754639, -0.0014309585094451904,\n",
      "        -0.0014309585094451904, -0.003908634185791016, -0.003908634185791016, 0.0036574900150299072,\n",
      "        -0.007860362529754639]\n",
      "  num_agent_steps_sampled: 75000\n",
      "  num_agent_steps_trained: 2396800\n",
      "  num_env_steps_sampled: 75000\n",
      "  num_env_steps_trained: 2396800\n",
      "  num_target_updates: 150\n",
      "iterations_since_restore: 75\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 75000\n",
      "num_agent_steps_trained: 2396800\n",
      "num_env_steps_sampled: 75000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 18.031198668518716\n",
      "num_env_steps_trained: 2396800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 576.9983573925989\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.543589743589738\n",
      "  ram_util_percent: 74.34358974358975\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4605.907842159271\n",
      "time_this_iter_s: 55.47851490974426\n",
      "time_total_s: 4605.907842159271\n",
      "timers:\n",
      "  learn_throughput: 6013.541\n",
      "  learn_time_ms: 10.643\n",
      "  load_throughput: 627039.14\n",
      "  load_time_ms: 0.102\n",
      "  sample_time_ms: 78.734\n",
      "  synch_weights_time_ms: 3.17\n",
      "  training_iteration_time_ms: 104.225\n",
      "timestamp: 1709835302\n",
      "timesteps_total: 75000\n",
      "training_iteration: 75\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 76000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 76000\n",
      "  num_agent_steps_sampled: 76000\n",
      "  num_agent_steps_trained: 2428800\n",
      "  num_env_steps_sampled: 76000\n",
      "  num_env_steps_trained: 2428800\n",
      "  num_target_updates: 152\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-15-58\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 76000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 37949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0010020576883107424\n",
      "        max_q: 0.4888240694999695\n",
      "        mean_q: 0.4870797395706177\n",
      "        min_q: 0.4829428791999817\n",
      "      mean_td_error: -0.00041989656165242195\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 37950.0\n",
      "      td_error: [0.0007634460926055908, -0.00341913104057312, 0.0007546544075012207,\n",
      "        -0.0008631050586700439, -0.00341913104057312, -0.0023511946201324463, 0.0007634460926055908,\n",
      "        -0.0004910528659820557, 0.0007546544075012207, 0.0007896125316619873, -0.0023511946201324463,\n",
      "        0.0007896125316619873, -0.0008631050586700439, 0.0007896125316619873, -0.0008631050586700439,\n",
      "        6.270408630371094e-05, -0.00341913104057312, -0.0008631050586700439, -0.00341913104057312,\n",
      "        -6.589293479919434e-05, -0.0023511946201324463, 0.0007634460926055908, -0.0008631050586700439,\n",
      "        0.0008727014064788818, -0.00341913104057312, 6.270408630371094e-05, 0.0007896125316619873,\n",
      "        -0.0023511946201324463, -0.0023511946201324463, 6.270408630371094e-05, 0.0007634460926055908,\n",
      "        0.0007896125316619873, 0.0006481409072875977, -0.0023511946201324463, -0.004037588834762573,\n",
      "        0.0007896125316619873, 0.00034886598587036133, 0.0007896125316619873, -0.0008631050586700439,\n",
      "        0.0007634460926055908, -0.0008631050586700439, 0.0007896125316619873, 0.011942178010940552,\n",
      "        -0.0008631050586700439, -0.0008631050586700439, 0.0007634460926055908, 0.0006478428840637207,\n",
      "        -0.0008631050586700439, -0.0023511946201324463, -0.0023511946201324463, 0.0007546544075012207,\n",
      "        0.0007634460926055908, -0.0023511946201324463, -0.0018681883811950684, 0.0007896125316619873,\n",
      "        0.0007546544075012207, -0.0008631050586700439, -0.0023511946201324463, 0.0005067586898803711,\n",
      "        -0.0023511946201324463, -0.0008631050586700439, 0.0007634460926055908, 0.0007546544075012207,\n",
      "        0.0007634460926055908]\n",
      "  num_agent_steps_sampled: 76000\n",
      "  num_agent_steps_trained: 2428800\n",
      "  num_env_steps_sampled: 76000\n",
      "  num_env_steps_trained: 2428800\n",
      "  num_target_updates: 152\n",
      "iterations_since_restore: 76\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 76000\n",
      "num_agent_steps_trained: 2428800\n",
      "num_env_steps_sampled: 76000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 18.012305059917622\n",
      "num_env_steps_trained: 2428800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 576.3937619173639\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.421518987341774\n",
      "  ram_util_percent: 73.59873417721518\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4661.444327354431\n",
      "time_this_iter_s: 55.53648519515991\n",
      "time_total_s: 4661.444327354431\n",
      "timers:\n",
      "  learn_throughput: 6124.007\n",
      "  learn_time_ms: 10.451\n",
      "  load_throughput: 591919.418\n",
      "  load_time_ms: 0.108\n",
      "  sample_time_ms: 92.673\n",
      "  synch_weights_time_ms: 3.251\n",
      "  training_iteration_time_ms: 118.185\n",
      "timestamp: 1709835358\n",
      "timesteps_total: 76000\n",
      "training_iteration: 76\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 77000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 77000\n",
      "  num_agent_steps_sampled: 77000\n",
      "  num_agent_steps_trained: 2460800\n",
      "  num_env_steps_sampled: 77000\n",
      "  num_env_steps_trained: 2460800\n",
      "  num_target_updates: 154\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-16-53\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 77000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 38449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0007592940237373114\n",
      "        max_q: 0.48691123723983765\n",
      "        mean_q: 0.4847491979598999\n",
      "        min_q: 0.4812817871570587\n",
      "      mean_td_error: -0.0001701568253338337\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 38450.0\n",
      "      td_error: [-0.0003267526626586914, -0.000882267951965332, -0.000882267951965332,\n",
      "        -0.0017844438552856445, -0.0003267526626586914, 0.000795215368270874, 0.002607017755508423,\n",
      "        -0.0003267526626586914, -0.0003267526626586914, -0.0017844438552856445, 0.000795215368270874,\n",
      "        -0.0022315382957458496, 0.0018195807933807373, -0.0003267526626586914, 0.000795215368270874,\n",
      "        -0.0037731528282165527, -0.000882267951965332, -0.0003267526626586914, 0.0018195807933807373,\n",
      "        -0.000882267951965332, -0.0022315382957458496, -0.0003267526626586914, -0.0003267526626586914,\n",
      "        -0.0022315382957458496, -0.0003267526626586914, 7.897615432739258e-06, 0.000795215368270874,\n",
      "        0.000795215368270874, -0.0003267526626586914, -0.000882267951965332, 7.897615432739258e-06,\n",
      "        -0.0003267526626586914, -0.0003267526626586914, 0.000795215368270874, -0.000882267951965332,\n",
      "        0.000795215368270874, -0.0022315382957458496, -0.0003267526626586914, 0.000795215368270874,\n",
      "        0.0018195807933807373, -0.0003267526626586914, -0.0003267526626586914, -0.0017844438552856445,\n",
      "        -0.0003267526626586914, -0.0015427172183990479, 0.000795215368270874, 0.0018195807933807373,\n",
      "        -0.0003267526626586914, -0.0022315382957458496, 0.002607017755508423, 0.000795215368270874,\n",
      "        -0.000882267951965332, -0.0003267526626586914, -0.000882267951965332, -0.0022315382957458496,\n",
      "        -0.0017844438552856445, 0.000795215368270874, 0.0018195807933807373, 0.0018195807933807373,\n",
      "        0.002025395631790161, -0.000882267951965332, 0.0018195807933807373, -0.0017844438552856445,\n",
      "        0.0018195807933807373]\n",
      "  num_agent_steps_sampled: 77000\n",
      "  num_agent_steps_trained: 2460800\n",
      "  num_env_steps_sampled: 77000\n",
      "  num_env_steps_trained: 2460800\n",
      "  num_target_updates: 154\n",
      "iterations_since_restore: 77\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 77000\n",
      "num_agent_steps_trained: 2460800\n",
      "num_env_steps_sampled: 77000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.911669728888945\n",
      "num_env_steps_trained: 2460800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 573.1734313244463\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 32.42375\n",
      "  ram_util_percent: 71.70125\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4717.292014360428\n",
      "time_this_iter_s: 55.847687005996704\n",
      "time_total_s: 4717.292014360428\n",
      "timers:\n",
      "  learn_throughput: 6139.583\n",
      "  learn_time_ms: 10.424\n",
      "  load_throughput: 813194.353\n",
      "  load_time_ms: 0.079\n",
      "  sample_time_ms: 86.031\n",
      "  synch_weights_time_ms: 3.279\n",
      "  training_iteration_time_ms: 110.901\n",
      "timestamp: 1709835413\n",
      "timesteps_total: 77000\n",
      "training_iteration: 77\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 78000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 78000\n",
      "  num_agent_steps_sampled: 78000\n",
      "  num_agent_steps_trained: 2492800\n",
      "  num_env_steps_sampled: 78000\n",
      "  num_env_steps_trained: 2492800\n",
      "  num_target_updates: 156\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-17-49\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 78000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 38949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0011815729085355997\n",
      "        max_q: 0.48613405227661133\n",
      "        mean_q: 0.48270198702812195\n",
      "        min_q: 0.4717974066734314\n",
      "      mean_td_error: 0.0002503432333469391\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 38950.0\n",
      "      td_error: [0.000904470682144165, -0.0017861425876617432, 0.000904470682144165,\n",
      "        0.0033499300479888916, 0.000904470682144165, -0.019767463207244873, 0.0033499300479888916,\n",
      "        0.0026733577251434326, 6.318092346191406e-06, 0.0004621446132659912, 6.318092346191406e-06,\n",
      "        6.318092346191406e-06, -0.00032216310501098633, -0.00042575597763061523, 0.000904470682144165,\n",
      "        0.003252387046813965, 0.0004621446132659912, -0.0017861425876617432, -0.0017861425876617432,\n",
      "        0.0004621446132659912, 0.0026733577251434326, 0.0033499300479888916, -0.0007263123989105225,\n",
      "        -0.004604965448379517, 0.0019258856773376465, 6.318092346191406e-06, -0.004604965448379517,\n",
      "        6.318092346191406e-06, 0.000904470682144165, 0.000904470682144165, 0.0026733577251434326,\n",
      "        0.00034433603286743164, -0.0017861425876617432, 0.003252387046813965, 6.318092346191406e-06,\n",
      "        0.000904470682144165, 0.0004621446132659912, 6.318092346191406e-06, 6.318092346191406e-06,\n",
      "        -0.0009764134883880615, 0.000904470682144165, -0.0017861425876617432, 0.000904470682144165,\n",
      "        0.0026733577251434326, 0.000904470682144165, 0.0033499300479888916, -0.0017861425876617432,\n",
      "        0.0033499300479888916, 0.0004621446132659912, 0.0026733577251434326, -0.0017861425876617432,\n",
      "        0.0026733577251434326, 0.0033499300479888916, -0.0017861425876617432, 0.0026733577251434326,\n",
      "        0.000904470682144165, 0.0004621446132659912, 6.318092346191406e-06, 0.000904470682144165,\n",
      "        0.000904470682144165, -0.0017861425876617432, 0.0026733577251434326, 0.0004621446132659912,\n",
      "        -0.0017861425876617432]\n",
      "  num_agent_steps_sampled: 78000\n",
      "  num_agent_steps_trained: 2492800\n",
      "  num_env_steps_sampled: 78000\n",
      "  num_env_steps_trained: 2492800\n",
      "  num_target_updates: 156\n",
      "iterations_since_restore: 78\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 78000\n",
      "num_agent_steps_trained: 2492800\n",
      "num_env_steps_sampled: 78000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.906554073030605\n",
      "num_env_steps_trained: 2492800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 573.0097303369794\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.18607594936709\n",
      "  ram_util_percent: 71.15949367088606\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4773.157182455063\n",
      "time_this_iter_s: 55.86516809463501\n",
      "time_total_s: 4773.157182455063\n",
      "timers:\n",
      "  learn_throughput: 6087.289\n",
      "  learn_time_ms: 10.514\n",
      "  load_throughput: 750238.837\n",
      "  load_time_ms: 0.085\n",
      "  sample_time_ms: 86.881\n",
      "  synch_weights_time_ms: 3.235\n",
      "  training_iteration_time_ms: 111.99\n",
      "timestamp: 1709835469\n",
      "timesteps_total: 78000\n",
      "training_iteration: 78\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 79000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 79000\n",
      "  num_agent_steps_sampled: 79000\n",
      "  num_agent_steps_trained: 2524800\n",
      "  num_env_steps_sampled: 79000\n",
      "  num_env_steps_trained: 2524800\n",
      "  num_target_updates: 158\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-18-45\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 79000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 39449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0033963220193982124\n",
      "        max_q: 0.48797741532325745\n",
      "        mean_q: 0.4768177568912506\n",
      "        min_q: 0.46932920813560486\n",
      "      mean_td_error: -0.0005049556493759155\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 39450.0\n",
      "      td_error: [-0.0038349032402038574, 0.0001856982707977295, -0.0017127692699432373,\n",
      "        -0.005209475755691528, 0.009481251239776611, -0.0017127692699432373, -0.005157917737960815,\n",
      "        -0.0017127692699432373, -0.005157917737960815, -0.003757297992706299, 0.005061089992523193,\n",
      "        0.02053818106651306, -0.005157917737960815, 0.006531238555908203, -0.005157917737960815,\n",
      "        0.0001856982707977295, 0.0056657493114471436, -0.0017127692699432373, 0.0001856982707977295,\n",
      "        -0.005157917737960815, -0.0017127692699432373, 0.0001856982707977295, -0.005157917737960815,\n",
      "        -0.0017127692699432373, 0.006531238555908203, -0.003757297992706299, -0.0017127692699432373,\n",
      "        0.006531238555908203, -0.003757297992706299, -0.0017127692699432373, -0.0017127692699432373,\n",
      "        -0.0017127692699432373, -0.005157917737960815, -0.005157917737960815, 0.006531238555908203,\n",
      "        -0.0034060776233673096, -0.004939258098602295, 0.006531238555908203, 0.0056657493114471436,\n",
      "        -0.003757297992706299, -0.005157917737960815, -0.005157917737960815, -0.003757297992706299,\n",
      "        0.0056657493114471436, -0.005157917737960815, -0.0017127692699432373, -0.003757297992706299,\n",
      "        -0.005157917737960815, 0.006313890218734741, -0.003757297992706299, 0.006531238555908203,\n",
      "        0.0001856982707977295, -0.005157917737960815, -0.005209475755691528, 0.013339906930923462,\n",
      "        0.004901409149169922, 0.0056657493114471436, -0.005157917737960815, -0.005157917737960815,\n",
      "        0.0056657493114471436, -0.005157917737960815, -0.005157917737960815, -0.005157917737960815,\n",
      "        0.0001856982707977295]\n",
      "  num_agent_steps_sampled: 79000\n",
      "  num_agent_steps_trained: 2524800\n",
      "  num_env_steps_sampled: 79000\n",
      "  num_env_steps_trained: 2524800\n",
      "  num_target_updates: 158\n",
      "iterations_since_restore: 79\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 79000\n",
      "num_agent_steps_trained: 2524800\n",
      "num_env_steps_sampled: 79000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.97410450097451\n",
      "num_env_steps_trained: 2524800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 575.1713440311843\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.548101265822783\n",
      "  ram_util_percent: 72.0860759493671\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4828.812173366547\n",
      "time_this_iter_s: 55.654990911483765\n",
      "time_total_s: 4828.812173366547\n",
      "timers:\n",
      "  learn_throughput: 5978.798\n",
      "  learn_time_ms: 10.704\n",
      "  load_throughput: 505052.598\n",
      "  load_time_ms: 0.127\n",
      "  sample_time_ms: 83.845\n",
      "  synch_weights_time_ms: 3.26\n",
      "  training_iteration_time_ms: 109.117\n",
      "timestamp: 1709835525\n",
      "timesteps_total: 79000\n",
      "training_iteration: 79\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 80000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "  StateBufferConnector_ms: 0.0026226043701171875\n",
      "  ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "counters:\n",
      "  last_target_update_ts: 80000\n",
      "  num_agent_steps_sampled: 80000\n",
      "  num_agent_steps_trained: 2556800\n",
      "  num_env_steps_sampled: 80000\n",
      "  num_env_steps_trained: 2556800\n",
      "  num_target_updates: 160\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-19-41\n",
      "done: false\n",
      "episode_len_mean: 16384.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 1.25\n",
      "episode_reward_min: 0.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 4\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 80000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 39949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.004030753392726183\n",
      "        max_q: 0.4904825687408447\n",
      "        mean_q: 0.48365506529808044\n",
      "        min_q: 0.4697754383087158\n",
      "      mean_td_error: -0.003761793952435255\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 39950.0\n",
      "      td_error: [-0.003484666347503662, -0.01242530345916748, -0.01242530345916748,\n",
      "        -0.003484666347503662, -0.005634218454360962, -0.0020085573196411133, 0.0025322437286376953,\n",
      "        0.0025322437286376953, -0.003484666347503662, -0.0020085573196411133, -0.0020085573196411133,\n",
      "        -0.0020085573196411133, -0.005634218454360962, -0.003484666347503662, 0.0025322437286376953,\n",
      "        -0.01242530345916748, -0.003484666347503662, -0.0020085573196411133, -0.003484666347503662,\n",
      "        -0.00783655047416687, -0.0033405423164367676, -0.0020085573196411133, -0.0020085573196411133,\n",
      "        -0.003484666347503662, -0.006385356187820435, -0.005634218454360962, -0.0020085573196411133,\n",
      "        -0.0020085573196411133, -0.003969252109527588, -0.0020085573196411133, -0.00783655047416687,\n",
      "        -0.0019430816173553467, -0.003484666347503662, -0.0020085573196411133, -0.005634218454360962,\n",
      "        -0.005634218454360962, -0.003969252109527588, -0.0020085573196411133, 0.0025322437286376953,\n",
      "        -0.0129014253616333, -0.005634218454360962, -0.0020085573196411133, -0.003969252109527588,\n",
      "        0.0025322437286376953, -0.004455596208572388, -0.005634218454360962, 0.0025322437286376953,\n",
      "        -0.01242530345916748, -0.00337865948677063, -0.005634218454360962, -0.01242530345916748,\n",
      "        -0.001165926456451416, -0.0035614073276519775, 0.0025322437286376953, -0.0020085573196411133,\n",
      "        -0.003484666347503662, -0.005634218454360962, -0.005634218454360962, -0.003484666347503662,\n",
      "        0.002953052520751953, -0.005634218454360962, -0.0020085573196411133, -0.005634218454360962,\n",
      "        -0.0020085573196411133]\n",
      "  num_agent_steps_sampled: 80000\n",
      "  num_agent_steps_trained: 2556800\n",
      "  num_env_steps_sampled: 80000\n",
      "  num_env_steps_trained: 2556800\n",
      "  num_target_updates: 160\n",
      "iterations_since_restore: 80\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 80000\n",
      "num_agent_steps_trained: 2556800\n",
      "num_env_steps_sampled: 80000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.76519935075571\n",
      "num_env_steps_trained: 2556800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 568.4863792241828\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.282500000000002\n",
      "  ram_util_percent: 71.87125\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.049707547912778455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 73.37556316334386\n",
      "  mean_inference_ms: 0.9391968434447644\n",
      "  mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004094839096069336\n",
      "    StateBufferConnector_ms: 0.0026226043701171875\n",
      "    ViewRequirementAgentConnector_ms: 0.09897947311401367\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 16384.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 1.25\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707547912778455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 73.37556316334386\n",
      "    mean_inference_ms: 0.9391968434447644\n",
      "    mean_raw_obs_processing_ms: 0.3856579842589537\n",
      "time_since_restore: 4885.1202692985535\n",
      "time_this_iter_s: 56.308095932006836\n",
      "time_total_s: 4885.1202692985535\n",
      "timers:\n",
      "  learn_throughput: 6139.667\n",
      "  learn_time_ms: 10.424\n",
      "  load_throughput: 603496.978\n",
      "  load_time_ms: 0.106\n",
      "  sample_time_ms: 89.355\n",
      "  synch_weights_time_ms: 3.162\n",
      "  training_iteration_time_ms: 114.153\n",
      "timestamp: 1709835581\n",
      "timesteps_total: 80000\n",
      "training_iteration: 80\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 81000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "  StateBufferConnector_ms: 0.0027036666870117188\n",
      "  ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "counters:\n",
      "  last_target_update_ts: 81000\n",
      "  num_agent_steps_sampled: 81000\n",
      "  num_agent_steps_trained: 2588800\n",
      "  num_env_steps_sampled: 81000\n",
      "  num_env_steps_trained: 2588800\n",
      "  num_target_updates: 162\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-20-38\n",
      "done: false\n",
      "episode_len_mean: 14559.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.4\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 1\n",
      "episodes_total: 5\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 81000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 40449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0015856212703511119\n",
      "        max_q: 0.49322691559791565\n",
      "        mean_q: 0.49029555916786194\n",
      "        min_q: 0.48527082800865173\n",
      "      mean_td_error: 0.001322055235505104\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 40450.0\n",
      "      td_error: [-1.1652708053588867e-05, 0.0018739104270935059, 0.001227349042892456,\n",
      "        -0.0006684362888336182, 0.001130133867263794, -0.00023365020751953125, 0.001227349042892456,\n",
      "        0.001130133867263794, 0.0018739104270935059, -0.0006684362888336182, -0.00023365020751953125,\n",
      "        0.0018739104270935059, 0.003989487886428833, 0.0018739104270935059, 0.0013331174850463867,\n",
      "        0.001227349042892456, 0.003989487886428833, 0.001227349042892456, -0.0006684362888336182,\n",
      "        0.001227349042892456, 0.0018739104270935059, 0.001227349042892456, 0.0037498176097869873,\n",
      "        0.0008367002010345459, 0.0018739104270935059, 0.0018739104270935059, -0.00023365020751953125,\n",
      "        -0.00023365020751953125, 0.0022077560424804688, 0.003989487886428833, -0.0006684362888336182,\n",
      "        0.0018739104270935059, -0.00023365020751953125, 0.001227349042892456, -0.00023365020751953125,\n",
      "        -0.00023365020751953125, -0.00023365020751953125, -0.0003495514392852783,\n",
      "        0.003989487886428833, 0.001227349042892456, 0.001227349042892456, -0.00023365020751953125,\n",
      "        -0.00023365020751953125, 0.001227349042892456, 0.003989487886428833, 0.001227349042892456,\n",
      "        0.0018739104270935059, 0.001227349042892456, -0.00023365020751953125, 0.0018739104270935059,\n",
      "        -0.0006684362888336182, 0.001130133867263794, 0.001227349042892456, 0.001227349042892456,\n",
      "        0.003989487886428833, 0.003989487886428833, 0.001130133867263794, 0.00034102797508239746,\n",
      "        0.001130133867263794, 0.003370225429534912, 0.001227349042892456, 0.003989487886428833,\n",
      "        0.003989487886428833, 0.00034102797508239746]\n",
      "  num_agent_steps_sampled: 81000\n",
      "  num_agent_steps_trained: 2588800\n",
      "  num_env_steps_sampled: 81000\n",
      "  num_env_steps_trained: 2588800\n",
      "  num_target_updates: 162\n",
      "iterations_since_restore: 81\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 81000\n",
      "num_agent_steps_trained: 2588800\n",
      "num_env_steps_sampled: 81000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.76834336115013\n",
      "num_env_steps_trained: 2588800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 568.5869875568042\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 30.10625\n",
      "  ram_util_percent: 71.4125\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04986672817487335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 70.64308427704304\n",
      "  mean_inference_ms: 0.9469005239500451\n",
      "  mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "    StateBufferConnector_ms: 0.0027036666870117188\n",
      "    ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 14559.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.4\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 1\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986672817487335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 70.64308427704304\n",
      "    mean_inference_ms: 0.9469005239500451\n",
      "    mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "time_since_restore: 4941.418519496918\n",
      "time_this_iter_s: 56.29825019836426\n",
      "time_total_s: 4941.418519496918\n",
      "timers:\n",
      "  learn_throughput: 6185.918\n",
      "  learn_time_ms: 10.346\n",
      "  load_throughput: 513457.261\n",
      "  load_time_ms: 0.125\n",
      "  sample_time_ms: 92.326\n",
      "  synch_weights_time_ms: 3.232\n",
      "  training_iteration_time_ms: 117.61\n",
      "timestamp: 1709835638\n",
      "timesteps_total: 81000\n",
      "training_iteration: 81\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 82000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "  StateBufferConnector_ms: 0.0027036666870117188\n",
      "  ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "counters:\n",
      "  last_target_update_ts: 82000\n",
      "  num_agent_steps_sampled: 82000\n",
      "  num_agent_steps_trained: 2620800\n",
      "  num_env_steps_sampled: 82000\n",
      "  num_env_steps_trained: 2620800\n",
      "  num_target_updates: 164\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-21-34\n",
      "done: false\n",
      "episode_len_mean: 14559.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.4\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 5\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 82000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 40949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0032605077140033245\n",
      "        max_q: 0.5182851552963257\n",
      "        mean_q: 0.49393779039382935\n",
      "        min_q: 0.48477599024772644\n",
      "      mean_td_error: 0.00027351872995495796\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 40950.0\n",
      "      td_error: [0.004662871360778809, -0.0018633902072906494, 0.002469480037689209,\n",
      "        0.002469480037689209, 0.004662871360778809, 0.004278123378753662, -0.006643086671829224,\n",
      "        0.002469480037689209, 0.004662871360778809, 0.002469480037689209, 0.002469480037689209,\n",
      "        0.0039179325103759766, -0.006643086671829224, 0.004662871360778809, 0.002469480037689209,\n",
      "        -0.005236148834228516, -0.00153428316116333, 0.004662871360778809, 0.002469480037689209,\n",
      "        -0.00153428316116333, -0.00153428316116333, 0.004278123378753662, -0.005236148834228516,\n",
      "        0.002469480037689209, -0.006643086671829224, -0.006643086671829224, 0.004278123378753662,\n",
      "        0.004278123378753662, -0.00153428316116333, 0.004662871360778809, -0.006643086671829224,\n",
      "        -0.005234956741333008, 0.002469480037689209, 0.002469480037689209, 0.004278123378753662,\n",
      "        -0.005236148834228516, -0.006643086671829224, 0.004662871360778809, 0.004662871360778809,\n",
      "        -0.00153428316116333, -0.006643086671829224, 0.004278123378753662, -0.005236148834228516,\n",
      "        0.004278123378753662, 0.004278123378753662, 0.0011313557624816895, -0.006643086671829224,\n",
      "        0.004662871360778809, -0.006937474012374878, 0.002469480037689209, 0.004278123378753662,\n",
      "        -0.005236148834228516, 0.004885315895080566, -0.005236148834228516, -0.006415963172912598,\n",
      "        -0.006643086671829224, 0.002469480037689209, 0.02448803186416626, 0.004662871360778809,\n",
      "        -0.006643086671829224, 0.002469480037689209, 0.002469480037689209, -0.005414873361587524,\n",
      "        -0.005236148834228516]\n",
      "  num_agent_steps_sampled: 82000\n",
      "  num_agent_steps_trained: 2620800\n",
      "  num_env_steps_sampled: 82000\n",
      "  num_env_steps_trained: 2620800\n",
      "  num_target_updates: 164\n",
      "iterations_since_restore: 82\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 82000\n",
      "num_agent_steps_trained: 2620800\n",
      "num_env_steps_sampled: 82000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.725947119699683\n",
      "num_env_steps_trained: 2620800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 567.2303078303898\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 31.973750000000003\n",
      "  ram_util_percent: 71.54125000000002\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04986672817487335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 70.64308427704304\n",
      "  mean_inference_ms: 0.9469005239500451\n",
      "  mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "    StateBufferConnector_ms: 0.0027036666870117188\n",
      "    ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 14559.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.4\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986672817487335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 70.64308427704304\n",
      "    mean_inference_ms: 0.9469005239500451\n",
      "    mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "time_since_restore: 4997.852599620819\n",
      "time_this_iter_s: 56.43408012390137\n",
      "time_total_s: 4997.852599620819\n",
      "timers:\n",
      "  learn_throughput: 5988.08\n",
      "  learn_time_ms: 10.688\n",
      "  load_throughput: 477813.2\n",
      "  load_time_ms: 0.134\n",
      "  sample_time_ms: 91.238\n",
      "  synch_weights_time_ms: 3.313\n",
      "  training_iteration_time_ms: 117.165\n",
      "timestamp: 1709835694\n",
      "timesteps_total: 82000\n",
      "training_iteration: 82\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 83000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "  StateBufferConnector_ms: 0.0027036666870117188\n",
      "  ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "counters:\n",
      "  last_target_update_ts: 83000\n",
      "  num_agent_steps_sampled: 83000\n",
      "  num_agent_steps_trained: 2652800\n",
      "  num_env_steps_sampled: 83000\n",
      "  num_env_steps_trained: 2652800\n",
      "  num_target_updates: 166\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-22-30\n",
      "done: false\n",
      "episode_len_mean: 14559.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.4\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 5\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 83000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 41449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0036342900712043047\n",
      "        max_q: 0.5265551805496216\n",
      "        mean_q: 0.48216351866722107\n",
      "        min_q: 0.4708804786205292\n",
      "      mean_td_error: -0.0023457948118448257\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 41450.0\n",
      "      td_error: [0.003710329532623291, -0.0060693323612213135, -0.0037094056606292725,\n",
      "        -0.0018827617168426514, 0.011787891387939453, 0.003710329532623291, -0.0060693323612213135,\n",
      "        -0.0060693323612213135, -0.0060693323612213135, -0.0060693323612213135, -0.0032760798931121826,\n",
      "        -0.0032760798931121826, -0.0018827617168426514, -0.0037094056606292725, -0.0060693323612213135,\n",
      "        -0.0018827617168426514, -0.0060693323612213135, -0.0060693323612213135, 0.003710329532623291,\n",
      "        0.003710329532623291, 0.003710329532623291, -0.0018827617168426514, -0.0032760798931121826,\n",
      "        -0.0018827617168426514, 0.003710329532623291, -0.0019085407257080078, -0.0035142600536346436,\n",
      "        -0.0032760798931121826, -0.005610227584838867, -0.0060693323612213135, -0.0032760798931121826,\n",
      "        -0.0060693323612213135, -0.0060693323612213135, -0.0037094056606292725, -0.0032760798931121826,\n",
      "        -0.005632340908050537, -0.0018827617168426514, -0.0018827617168426514, -0.0060693323612213135,\n",
      "        0.003710329532623291, -0.00324857234954834, -0.0018827617168426514, 0.003710329532623291,\n",
      "        0.003710329532623291, -0.0037094056606292725, -0.0018827617168426514, -0.0018827617168426514,\n",
      "        -0.0060693323612213135, -0.0060693323612213135, -0.0037094056606292725, -0.0019085407257080078,\n",
      "        -0.0032760798931121826, -0.0019085407257080078, 0.003710329532623291, -0.0060693323612213135,\n",
      "        -0.0018827617168426514, -0.0018827617168426514, -0.0018827617168426514, -0.0019085407257080078,\n",
      "        -0.0032760798931121826, -0.0018827617168426514, -0.0018827617168426514, -0.0032760798931121826,\n",
      "        -0.0060693323612213135]\n",
      "  num_agent_steps_sampled: 83000\n",
      "  num_agent_steps_trained: 2652800\n",
      "  num_env_steps_sampled: 83000\n",
      "  num_env_steps_trained: 2652800\n",
      "  num_target_updates: 166\n",
      "iterations_since_restore: 83\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 83000\n",
      "num_agent_steps_trained: 2652800\n",
      "num_env_steps_sampled: 83000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.748511829135097\n",
      "num_env_steps_trained: 2652800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 567.9523785323231\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.411250000000003\n",
      "  ram_util_percent: 72.9425\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04986672817487335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 70.64308427704304\n",
      "  mean_inference_ms: 0.9469005239500451\n",
      "  mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "    StateBufferConnector_ms: 0.0027036666870117188\n",
      "    ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 14559.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.4\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986672817487335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 70.64308427704304\n",
      "    mean_inference_ms: 0.9469005239500451\n",
      "    mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "time_since_restore: 5054.213909626007\n",
      "time_this_iter_s: 56.36131000518799\n",
      "time_total_s: 5054.213909626007\n",
      "timers:\n",
      "  learn_throughput: 6170.462\n",
      "  learn_time_ms: 10.372\n",
      "  load_throughput: 568478.306\n",
      "  load_time_ms: 0.113\n",
      "  sample_time_ms: 85.998\n",
      "  synch_weights_time_ms: 3.206\n",
      "  training_iteration_time_ms: 110.755\n",
      "timestamp: 1709835750\n",
      "timesteps_total: 83000\n",
      "training_iteration: 83\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 84000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "  StateBufferConnector_ms: 0.0027036666870117188\n",
      "  ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "counters:\n",
      "  last_target_update_ts: 84000\n",
      "  num_agent_steps_sampled: 84000\n",
      "  num_agent_steps_trained: 2684800\n",
      "  num_env_steps_sampled: 84000\n",
      "  num_env_steps_trained: 2684800\n",
      "  num_target_updates: 168\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-23-27\n",
      "done: false\n",
      "episode_len_mean: 14559.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.4\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 5\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 84000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 41949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0017135711386799812\n",
      "        max_q: 0.4901707172393799\n",
      "        mean_q: 0.48854923248291016\n",
      "        min_q: 0.4830857813358307\n",
      "      mean_td_error: -0.0006597326137125492\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 41950.0\n",
      "      td_error: [-0.0018271207809448242, -0.0007491707801818848, -0.0018271207809448242,\n",
      "        0.00047659873962402344, -0.004008829593658447, 0.0008410215377807617, 0.00047659873962402344,\n",
      "        0.00047659873962402344, 0.0008410215377807617, -0.004025012254714966, 0.0002962946891784668,\n",
      "        -0.003601253032684326, -0.003601253032684326, 0.0002962946891784668, -0.004287540912628174,\n",
      "        -0.0007491707801818848, 0.0002962946891784668, 0.00047659873962402344, 0.0002962946891784668,\n",
      "        0.00047659873962402344, 0.0002962946891784668, -0.0018271207809448242, 0.0008410215377807617,\n",
      "        0.0002962946891784668, 0.0008410215377807617, -0.003601253032684326, -0.004287540912628174,\n",
      "        0.0002962946891784668, -0.004710018634796143, -0.0018271207809448242, 0.0008410215377807617,\n",
      "        0.0008410215377807617, -0.0018271207809448242, -0.0007491707801818848, 0.0008410215377807617,\n",
      "        0.00047659873962402344, -0.0007491707801818848, 0.0008410215377807617, 0.0008410215377807617,\n",
      "        0.003421574831008911, 0.00047659873962402344, 0.0002962946891784668, -0.003601253032684326,\n",
      "        0.0002962946891784668, -0.003601253032684326, 0.00047659873962402344, 0.0008410215377807617,\n",
      "        0.0002962946891784668, -0.00010058283805847168, -0.0007491707801818848, -0.003601253032684326,\n",
      "        0.0008410215377807617, 0.00047659873962402344, -0.0018271207809448242, 0.0008410215377807617,\n",
      "        -0.0018271207809448242, 0.0002962946891784668, -0.003601253032684326, -0.0007491707801818848,\n",
      "        0.00047659873962402344, 0.0008410215377807617, -0.0018271207809448242, 0.0008410215377807617,\n",
      "        0.0002962946891784668]\n",
      "  num_agent_steps_sampled: 84000\n",
      "  num_agent_steps_trained: 2684800\n",
      "  num_env_steps_sampled: 84000\n",
      "  num_env_steps_trained: 2684800\n",
      "  num_target_updates: 168\n",
      "iterations_since_restore: 84\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 84000\n",
      "num_agent_steps_trained: 2684800\n",
      "num_env_steps_sampled: 84000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.630632773832506\n",
      "num_env_steps_trained: 2684800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 564.1802487626402\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 29.269135802469137\n",
      "  ram_util_percent: 72.48395061728395\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04986672817487335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 70.64308427704304\n",
      "  mean_inference_ms: 0.9469005239500451\n",
      "  mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "    StateBufferConnector_ms: 0.0027036666870117188\n",
      "    ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 14559.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.4\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986672817487335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 70.64308427704304\n",
      "    mean_inference_ms: 0.9469005239500451\n",
      "    mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "time_since_restore: 5110.951817512512\n",
      "time_this_iter_s: 56.73790788650513\n",
      "time_total_s: 5110.951817512512\n",
      "timers:\n",
      "  learn_throughput: 6056.155\n",
      "  learn_time_ms: 10.568\n",
      "  load_throughput: 580400.986\n",
      "  load_time_ms: 0.11\n",
      "  sample_time_ms: 84.525\n",
      "  synch_weights_time_ms: 3.272\n",
      "  training_iteration_time_ms: 109.374\n",
      "timestamp: 1709835807\n",
      "timesteps_total: 84000\n",
      "training_iteration: 84\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 85000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "  StateBufferConnector_ms: 0.0027036666870117188\n",
      "  ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "counters:\n",
      "  last_target_update_ts: 85000\n",
      "  num_agent_steps_sampled: 85000\n",
      "  num_agent_steps_trained: 2716800\n",
      "  num_env_steps_sampled: 85000\n",
      "  num_env_steps_trained: 2716800\n",
      "  num_target_updates: 170\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-24-23\n",
      "done: false\n",
      "episode_len_mean: 14559.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.4\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 5\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 85000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 42449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.003073187079280615\n",
      "        max_q: 0.48690682649612427\n",
      "        mean_q: 0.4846726655960083\n",
      "        min_q: 0.4797910153865814\n",
      "      mean_td_error: -0.0037685339339077473\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 42450.0\n",
      "      td_error: [-0.0022330284118652344, -0.0029832422733306885, -0.0022330284118652344,\n",
      "        -0.004099905490875244, -0.0022330284118652344, -0.00350305438041687, -0.00350305438041687,\n",
      "        -0.0007933378219604492, -0.00350305438041687, -0.004081904888153076, -0.006019502878189087,\n",
      "        -0.00350305438041687, -0.006019502878189087, -0.00350305438041687, -0.0029832422733306885,\n",
      "        -0.0029832422733306885, -0.00350305438041687, -0.0022330284118652344, -0.004195034503936768,\n",
      "        -0.0022330284118652344, -0.004195034503936768, -0.0010365545749664307, -0.02179431915283203,\n",
      "        -0.006126105785369873, -0.004195034503936768, -0.004195034503936768, -0.0029832422733306885,\n",
      "        -0.006019502878189087, -0.0011202692985534668, -0.0011202692985534668, -0.020531684160232544,\n",
      "        -0.006019502878189087, -0.0011202692985534668, -0.0011202692985534668, -0.0011202692985534668,\n",
      "        -0.004195034503936768, -0.0022330284118652344, -0.0022330284118652344, -0.006019502878189087,\n",
      "        -0.006019502878189087, -0.0011202692985534668, -0.00350305438041687, -0.0011202692985534668,\n",
      "        -0.006019502878189087, -0.0018883943557739258, -0.0019719302654266357, -0.007198244333267212,\n",
      "        -0.0022330284118652344, -0.006019502878189087, -0.0011202692985534668, -0.0029832422733306885,\n",
      "        -0.00350305438041687, -0.0011202692985534668, -0.0011202692985534668, -0.0011202692985534668,\n",
      "        -0.00350305438041687, -0.003977090120315552, -0.0029832422733306885, -0.004195034503936768,\n",
      "        -0.00350305438041687, -0.0011202692985534668, -0.0011202692985534668, -0.006019502878189087,\n",
      "        -0.0029832422733306885]\n",
      "  num_agent_steps_sampled: 85000\n",
      "  num_agent_steps_trained: 2716800\n",
      "  num_env_steps_sampled: 85000\n",
      "  num_env_steps_trained: 2716800\n",
      "  num_target_updates: 170\n",
      "iterations_since_restore: 85\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 85000\n",
      "num_agent_steps_trained: 2716800\n",
      "num_env_steps_sampled: 85000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.83366353833136\n",
      "num_env_steps_trained: 2716800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 570.6772332266036\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.06455696202532\n",
      "  ram_util_percent: 71.93670886075951\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04986672817487335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 70.64308427704304\n",
      "  mean_inference_ms: 0.9469005239500451\n",
      "  mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "    StateBufferConnector_ms: 0.0027036666870117188\n",
      "    ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 14559.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.4\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986672817487335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 70.64308427704304\n",
      "    mean_inference_ms: 0.9469005239500451\n",
      "    mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "time_since_restore: 5167.044584751129\n",
      "time_this_iter_s: 56.09276723861694\n",
      "time_total_s: 5167.044584751129\n",
      "timers:\n",
      "  learn_throughput: 6043.04\n",
      "  learn_time_ms: 10.591\n",
      "  load_throughput: 706595.041\n",
      "  load_time_ms: 0.091\n",
      "  sample_time_ms: 86.618\n",
      "  synch_weights_time_ms: 3.293\n",
      "  training_iteration_time_ms: 111.635\n",
      "timestamp: 1709835863\n",
      "timesteps_total: 85000\n",
      "training_iteration: 85\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 81x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 93x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 86000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "  StateBufferConnector_ms: 0.0027036666870117188\n",
      "  ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "counters:\n",
      "  last_target_update_ts: 86000\n",
      "  num_agent_steps_sampled: 86000\n",
      "  num_agent_steps_trained: 2748800\n",
      "  num_env_steps_sampled: 86000\n",
      "  num_env_steps_trained: 2748800\n",
      "  num_target_updates: 172\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-25-20\n",
      "done: false\n",
      "episode_len_mean: 14559.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.4\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 5\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 86000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 42949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.002424427308142185\n",
      "        max_q: 0.4920242428779602\n",
      "        mean_q: 0.48400208353996277\n",
      "        min_q: 0.4749705195426941\n",
      "      mean_td_error: 0.0005455478094518185\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 42950.0\n",
      "      td_error: [-0.0016896724700927734, 0.001705944538116455, 0.0009656250476837158,\n",
      "        0.008767545223236084, 0.0012643635272979736, -0.0016896724700927734, 0.0009656250476837158,\n",
      "        0.004607558250427246, 0.0009656250476837158, 0.004607558250427246, 0.0009656250476837158,\n",
      "        -0.0016896724700927734, -0.003470391035079956, -0.0016896724700927734, -0.013372093439102173,\n",
      "        0.001705944538116455, 0.0009656250476837158, 0.008767545223236084, 0.004607558250427246,\n",
      "        -0.003470391035079956, 0.0009656250476837158, -0.003470391035079956, 0.0018338263034820557,\n",
      "        0.004607558250427246, 0.0009656250476837158, 0.004607558250427246, 0.008767545223236084,\n",
      "        0.0009656250476837158, -0.01159137487411499, -0.0016896724700927734, -0.003470391035079956,\n",
      "        0.0009656250476837158, -0.003470391035079956, -0.003470391035079956, -0.003470391035079956,\n",
      "        0.0009656250476837158, -0.0016896724700927734, -0.0007655620574951172, 0.001705944538116455,\n",
      "        -0.003470391035079956, 0.004607558250427246, -0.0016896724700927734, -0.0016896724700927734,\n",
      "        -0.003470391035079956, -0.003470391035079956, 0.0009656250476837158, 0.008767545223236084,\n",
      "        0.0009656250476837158, 0.004607558250427246, 0.001705944538116455, -0.003470391035079956,\n",
      "        0.001705944538116455, -0.003470391035079956, -0.003470391035079956, 0.0009656250476837158,\n",
      "        -0.0016896724700927734, 0.008767545223236084, 0.008767545223236084, 0.004607558250427246,\n",
      "        0.0009656250476837158, -0.0016896724700927734, 0.008767545223236084, -0.0016896724700927734,\n",
      "        0.0009656250476837158]\n",
      "  num_agent_steps_sampled: 86000\n",
      "  num_agent_steps_trained: 2748800\n",
      "  num_env_steps_sampled: 86000\n",
      "  num_env_steps_trained: 2748800\n",
      "  num_target_updates: 172\n",
      "iterations_since_restore: 86\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 86000\n",
      "num_agent_steps_trained: 2748800\n",
      "num_env_steps_sampled: 86000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.730858298445092\n",
      "num_env_steps_trained: 2748800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 567.387465550243\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.32875\n",
      "  ram_util_percent: 72.97\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04986672817487335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 70.64308427704304\n",
      "  mean_inference_ms: 0.9469005239500451\n",
      "  mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "    StateBufferConnector_ms: 0.0027036666870117188\n",
      "    ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 14559.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.4\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986672817487335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 70.64308427704304\n",
      "    mean_inference_ms: 0.9469005239500451\n",
      "    mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "time_since_restore: 5223.462622880936\n",
      "time_this_iter_s: 56.41803812980652\n",
      "time_total_s: 5223.462622880936\n",
      "timers:\n",
      "  learn_throughput: 6033.071\n",
      "  learn_time_ms: 10.608\n",
      "  load_throughput: 520324.59\n",
      "  load_time_ms: 0.123\n",
      "  sample_time_ms: 89.771\n",
      "  synch_weights_time_ms: 3.301\n",
      "  training_iteration_time_ms: 115.133\n",
      "timestamp: 1709835920\n",
      "timesteps_total: 86000\n",
      "training_iteration: 86\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 87000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "  StateBufferConnector_ms: 0.0027036666870117188\n",
      "  ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "counters:\n",
      "  last_target_update_ts: 87000\n",
      "  num_agent_steps_sampled: 87000\n",
      "  num_agent_steps_trained: 2780800\n",
      "  num_env_steps_sampled: 87000\n",
      "  num_env_steps_trained: 2780800\n",
      "  num_target_updates: 174\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-26-15\n",
      "done: false\n",
      "episode_len_mean: 14559.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.4\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 5\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 87000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 43449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0024499602150171995\n",
      "        max_q: 0.487737774848938\n",
      "        mean_q: 0.4855436384677887\n",
      "        min_q: 0.48091670870780945\n",
      "      mean_td_error: 0.0038548759184777737\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 43450.0\n",
      "      td_error: [-0.007942378520965576, -0.0024465620517730713, -0.0032267868518829346,\n",
      "        -0.0040854811668396, -0.007942378520965576, -0.0011535286903381348, -0.004086226224899292,\n",
      "        -0.0032267868518829346, -0.0024465620517730713, -0.0024465620517730713, -0.0018595457077026367,\n",
      "        -0.004086226224899292, -0.0032267868518829346, -0.007974594831466675, -0.0018595457077026367,\n",
      "        0.4815366566181183, -0.0024465620517730713, -0.0032267868518829346, -0.0018595457077026367,\n",
      "        -0.004106700420379639, -0.0024465620517730713, -0.0018595457077026367, -0.0011535286903381348,\n",
      "        -0.0032267868518829346, -0.001741260290145874, -0.0032267868518829346, -0.0032267868518829346,\n",
      "        -0.0032267868518829346, -0.004086226224899292, -0.0011932849884033203, -0.007942378520965576,\n",
      "        -0.0040854811668396, -0.0018595457077026367, -0.0032267868518829346, -0.0032267868518829346,\n",
      "        -0.0032267868518829346, -0.007942378520965576, -0.007942378520965576, -0.0032267868518829346,\n",
      "        -0.004086226224899292, -0.0024465620517730713, -0.0024465620517730713, -0.0018595457077026367,\n",
      "        -0.004086226224899292, -0.0032267868518829346, -0.0024465620517730713, -0.004086226224899292,\n",
      "        -0.0032267868518829346, -0.007942378520965576, -0.0040854811668396, -0.0018595457077026367,\n",
      "        -0.0032267868518829346, -0.004086226224899292, -0.007942378520965576, -0.007942378520965576,\n",
      "        -0.0011535286903381348, -0.0032267868518829346, -0.0040854811668396, -0.0024465620517730713,\n",
      "        -0.0040854811668396, -0.004086226224899292, -0.0024465620517730713, -0.007942378520965576,\n",
      "        -0.002638518810272217]\n",
      "  num_agent_steps_sampled: 87000\n",
      "  num_agent_steps_trained: 2780800\n",
      "  num_env_steps_sampled: 87000\n",
      "  num_env_steps_trained: 2780800\n",
      "  num_target_updates: 174\n",
      "iterations_since_restore: 87\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 87000\n",
      "num_agent_steps_trained: 2780800\n",
      "num_env_steps_sampled: 87000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 18.153802898442333\n",
      "num_env_steps_trained: 2780800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 580.9216927501546\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.865384615384613\n",
      "  ram_util_percent: 73.7820512820513\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04986672817487335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 70.64308427704304\n",
      "  mean_inference_ms: 0.9469005239500451\n",
      "  mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "    StateBufferConnector_ms: 0.0027036666870117188\n",
      "    ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 14559.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.4\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986672817487335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 70.64308427704304\n",
      "    mean_inference_ms: 0.9469005239500451\n",
      "    mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "time_since_restore: 5278.56554889679\n",
      "time_this_iter_s: 55.10292601585388\n",
      "time_total_s: 5278.56554889679\n",
      "timers:\n",
      "  learn_throughput: 6191.369\n",
      "  learn_time_ms: 10.337\n",
      "  load_throughput: 585592.182\n",
      "  load_time_ms: 0.109\n",
      "  sample_time_ms: 81.705\n",
      "  synch_weights_time_ms: 3.103\n",
      "  training_iteration_time_ms: 106.641\n",
      "timestamp: 1709835975\n",
      "timesteps_total: 87000\n",
      "training_iteration: 87\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 93x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 95x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 88000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "  StateBufferConnector_ms: 0.0027036666870117188\n",
      "  ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "counters:\n",
      "  last_target_update_ts: 88000\n",
      "  num_agent_steps_sampled: 88000\n",
      "  num_agent_steps_trained: 2812800\n",
      "  num_env_steps_sampled: 88000\n",
      "  num_env_steps_trained: 2812800\n",
      "  num_target_updates: 176\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-27-10\n",
      "done: false\n",
      "episode_len_mean: 14559.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.4\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 5\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 88000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 43949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0025421378668397665\n",
      "        max_q: 0.49767884612083435\n",
      "        mean_q: 0.4937702417373657\n",
      "        min_q: 0.47286754846572876\n",
      "      mean_td_error: -0.0005890517495572567\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 43950.0\n",
      "      td_error: [0.001248091459274292, -0.006944775581359863, 0.0026901960372924805,\n",
      "        -0.006944775581359863, -0.006944775581359863, 0.0026901960372924805, 0.001248091459274292,\n",
      "        -0.0037669241428375244, 0.001319587230682373, 0.0026901960372924805, 0.0026901960372924805,\n",
      "        0.001319587230682373, 0.0026901960372924805, -0.0037669241428375244, -0.006944775581359863,\n",
      "        -0.0037669241428375244, 0.0026901960372924805, 0.0026667118072509766, -0.0037669241428375244,\n",
      "        -0.0037669241428375244, -0.006944775581359863, -0.0037669241428375244, -0.0037669241428375244,\n",
      "        0.002769976854324341, 0.002769976854324341, 0.0026901960372924805, 0.0026901960372924805,\n",
      "        0.0051531195640563965, -0.0037669241428375244, -0.0037669241428375244, 0.0026901960372924805,\n",
      "        0.001248091459274292, 0.0009376406669616699, 0.002769976854324341, 0.0021268725395202637,\n",
      "        0.001248091459274292, 0.001319587230682373, 0.002769976854324341, 0.001248091459274292,\n",
      "        -0.0037669241428375244, 0.001248091459274292, -0.006944775581359863, 0.002769976854324341,\n",
      "        -0.006944775581359863, 0.001319587230682373, -0.006944775581359863, 0.001319587230682373,\n",
      "        0.002769976854324341, 0.01316601037979126, -0.00011783838272094727, -0.0037669241428375244,\n",
      "        -0.006944775581359863, -0.010123401880264282, 0.001248091459274292, 0.001319587230682373,\n",
      "        0.0026901960372924805, -0.006944775581359863, 0.001248091459274292, 0.0026901960372924805,\n",
      "        -0.0037669241428375244, 0.002769976854324341, -0.006944775581359863, 0.0009376406669616699,\n",
      "        0.0022653043270111084]\n",
      "  num_agent_steps_sampled: 88000\n",
      "  num_agent_steps_trained: 2812800\n",
      "  num_env_steps_sampled: 88000\n",
      "  num_env_steps_trained: 2812800\n",
      "  num_target_updates: 176\n",
      "iterations_since_restore: 88\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 88000\n",
      "num_agent_steps_trained: 2812800\n",
      "num_env_steps_sampled: 88000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 18.04321353047604\n",
      "num_env_steps_trained: 2812800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 577.3828329752333\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.684810126582278\n",
      "  ram_util_percent: 73.80379746835443\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04986672817487335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 70.64308427704304\n",
      "  mean_inference_ms: 0.9469005239500451\n",
      "  mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "    StateBufferConnector_ms: 0.0027036666870117188\n",
      "    ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 14559.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.4\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986672817487335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 70.64308427704304\n",
      "    mean_inference_ms: 0.9469005239500451\n",
      "    mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "time_since_restore: 5334.006745815277\n",
      "time_this_iter_s: 55.44119691848755\n",
      "time_total_s: 5334.006745815277\n",
      "timers:\n",
      "  learn_throughput: 6184.607\n",
      "  learn_time_ms: 10.348\n",
      "  load_throughput: 537946.806\n",
      "  load_time_ms: 0.119\n",
      "  sample_time_ms: 80.72\n",
      "  synch_weights_time_ms: 3.215\n",
      "  training_iteration_time_ms: 106.077\n",
      "timestamp: 1709836030\n",
      "timesteps_total: 88000\n",
      "training_iteration: 88\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 89000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "  StateBufferConnector_ms: 0.0027036666870117188\n",
      "  ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "counters:\n",
      "  last_target_update_ts: 89000\n",
      "  num_agent_steps_sampled: 89000\n",
      "  num_agent_steps_trained: 2844800\n",
      "  num_env_steps_sampled: 89000\n",
      "  num_env_steps_trained: 2844800\n",
      "  num_target_updates: 178\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-28-06\n",
      "done: false\n",
      "episode_len_mean: 14559.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.4\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 5\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 89000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 44449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.005442742723971605\n",
      "        max_q: 0.5042747855186462\n",
      "        mean_q: 0.5013846755027771\n",
      "        min_q: 0.4990665912628174\n",
      "      mean_td_error: 0.004932488314807415\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 44450.0\n",
      "      td_error: [0.005497545003890991, 0.007749348878860474, 0.0029005706310272217,\n",
      "        0.007749348878860474, 0.007749348878860474, 0.007749348878860474, 0.007749348878860474,\n",
      "        0.004299193620681763, 0.007749348878860474, 0.0029005706310272217, 0.004299193620681763,\n",
      "        0.007749348878860474, 0.007759898900985718, 0.0042535364627838135, 0.007749348878860474,\n",
      "        0.004299193620681763, 0.0025457143783569336, 0.0025457143783569336, 0.0029005706310272217,\n",
      "        0.007749348878860474, 0.0042535364627838135, 0.007749348878860474, 0.005497545003890991,\n",
      "        0.0029005706310272217, 0.007749348878860474, 0.004299193620681763, 0.004299193620681763,\n",
      "        0.007724553346633911, 0.005497545003890991, 0.004299193620681763, 0.007749348878860474,\n",
      "        0.0029005706310272217, 0.0042535364627838135, 0.005497545003890991, 0.007724553346633911,\n",
      "        0.006121963262557983, 0.0029005706310272217, 0.0029005706310272217, 0.0033161044120788574,\n",
      "        0.0029005706310272217, 0.0033161044120788574, 0.0025457143783569336, 0.004299193620681763,\n",
      "        0.0025457143783569336, 0.0029005706310272217, 0.004299193620681763, 0.0025457143783569336,\n",
      "        0.0042535364627838135, 0.004299193620681763, 0.007749348878860474, 0.0025457143783569336,\n",
      "        0.0042535364627838135, 0.0042535364627838135, 0.005497545003890991, 0.0025457143783569336,\n",
      "        0.007749348878860474, 0.005497545003890991, 0.0042535364627838135, 0.007749348878860474,\n",
      "        0.0029005706310272217, 0.0042535364627838135, 0.0025457143783569336, 0.005497545003890991,\n",
      "        0.0029005706310272217]\n",
      "  num_agent_steps_sampled: 89000\n",
      "  num_agent_steps_trained: 2844800\n",
      "  num_env_steps_sampled: 89000\n",
      "  num_env_steps_trained: 2844800\n",
      "  num_target_updates: 178\n",
      "iterations_since_restore: 89\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 89000\n",
      "num_agent_steps_trained: 2844800\n",
      "num_env_steps_sampled: 89000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 18.059446372296293\n",
      "num_env_steps_trained: 2844800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 577.9022839134814\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.823076923076922\n",
      "  ram_util_percent: 73.96666666666665\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04986672817487335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 70.64308427704304\n",
      "  mean_inference_ms: 0.9469005239500451\n",
      "  mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "    StateBufferConnector_ms: 0.0027036666870117188\n",
      "    ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 14559.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.4\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986672817487335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 70.64308427704304\n",
      "    mean_inference_ms: 0.9469005239500451\n",
      "    mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "time_since_restore: 5389.397285938263\n",
      "time_this_iter_s: 55.39054012298584\n",
      "time_total_s: 5389.397285938263\n",
      "timers:\n",
      "  learn_throughput: 6038.567\n",
      "  learn_time_ms: 10.599\n",
      "  load_throughput: 760009.785\n",
      "  load_time_ms: 0.084\n",
      "  sample_time_ms: 83.682\n",
      "  synch_weights_time_ms: 3.172\n",
      "  training_iteration_time_ms: 108.38\n",
      "timestamp: 1709836086\n",
      "timesteps_total: 89000\n",
      "training_iteration: 89\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 90000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "  StateBufferConnector_ms: 0.0027036666870117188\n",
      "  ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "counters:\n",
      "  last_target_update_ts: 90000\n",
      "  num_agent_steps_sampled: 90000\n",
      "  num_agent_steps_trained: 2876800\n",
      "  num_env_steps_sampled: 90000\n",
      "  num_env_steps_trained: 2876800\n",
      "  num_target_updates: 180\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-29-01\n",
      "done: false\n",
      "episode_len_mean: 14559.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.4\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 5\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 90000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 44949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0013954977039247751\n",
      "        max_q: 0.4916377365589142\n",
      "        mean_q: 0.48986780643463135\n",
      "        min_q: 0.4823857545852661\n",
      "      mean_td_error: -0.00045414408668875694\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 44950.0\n",
      "      td_error: [0.000265270471572876, -0.00264933705329895, -6.568431854248047e-05,\n",
      "        -6.568431854248047e-05, 0.0011038780212402344, 0.0002706944942474365, 0.0002706944942474365,\n",
      "        -0.00264933705329895, 6.461143493652344e-05, -0.00014126300811767578, -0.00264933705329895,\n",
      "        6.461143493652344e-05, -0.00014126300811767578, 0.0002706944942474365, 0.000265270471572876,\n",
      "        6.461143493652344e-05, -0.00264933705329895, -0.00264933705329895, 0.0002706944942474365,\n",
      "        0.0011038780212402344, -0.00264933705329895, 6.461143493652344e-05, 6.461143493652344e-05,\n",
      "        -0.00264933705329895, 0.0011038780212402344, -0.00264933705329895, 0.0002706944942474365,\n",
      "        -0.00264933705329895, -0.00264933705329895, 0.0002706944942474365, -0.00264933705329895,\n",
      "        6.461143493652344e-05, 0.000265270471572876, 0.000265270471572876, 0.0002706944942474365,\n",
      "        0.0002706944942474365, 0.0002706944942474365, 0.0002706944942474365, 0.0002706944942474365,\n",
      "        0.000265270471572876, 6.461143493652344e-05, 0.0011038780212402344, -0.00264933705329895,\n",
      "        0.0011038780212402344, -0.00264933705329895, -0.00264933705329895, 6.461143493652344e-05,\n",
      "        0.0011038780212402344, 0.0002706944942474365, 0.0011038780212402344, -0.00014126300811767578,\n",
      "        0.0011038780212402344, -0.00014126300811767578, 6.461143493652344e-05, 0.000265270471572876,\n",
      "        6.461143493652344e-05, -0.00014126300811767578, -0.00264933705329895, 0.0011038780212402344,\n",
      "        0.0002706944942474365, -0.00264933705329895, 0.0011038780212402344, -0.00264933705329895,\n",
      "        1.564621925354004e-05]\n",
      "  num_agent_steps_sampled: 90000\n",
      "  num_agent_steps_trained: 2876800\n",
      "  num_env_steps_sampled: 90000\n",
      "  num_env_steps_trained: 2876800\n",
      "  num_target_updates: 180\n",
      "iterations_since_restore: 90\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 90000\n",
      "num_agent_steps_trained: 2876800\n",
      "num_env_steps_sampled: 90000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 18.109169462979164\n",
      "num_env_steps_trained: 2876800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 579.4934228153332\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.79615384615385\n",
      "  ram_util_percent: 74.36794871794872\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04986672817487335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 70.64308427704304\n",
      "  mean_inference_ms: 0.9469005239500451\n",
      "  mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004105567932128906\n",
      "    StateBufferConnector_ms: 0.0027036666870117188\n",
      "    ViewRequirementAgentConnector_ms: 0.10174751281738281\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 14559.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.4\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986672817487335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 70.64308427704304\n",
      "    mean_inference_ms: 0.9469005239500451\n",
      "    mean_raw_obs_processing_ms: 0.3895328827659744\n",
      "time_since_restore: 5444.637409210205\n",
      "time_this_iter_s: 55.24012327194214\n",
      "time_total_s: 5444.637409210205\n",
      "timers:\n",
      "  learn_throughput: 6035.852\n",
      "  learn_time_ms: 10.603\n",
      "  load_throughput: 633849.955\n",
      "  load_time_ms: 0.101\n",
      "  sample_time_ms: 89.804\n",
      "  synch_weights_time_ms: 3.16\n",
      "  training_iteration_time_ms: 115.002\n",
      "timestamp: 1709836141\n",
      "timesteps_total: 90000\n",
      "training_iteration: 90\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 91000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "  StateBufferConnector_ms: 0.002769629160563151\n",
      "  ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "counters:\n",
      "  last_target_update_ts: 91000\n",
      "  num_agent_steps_sampled: 91000\n",
      "  num_agent_steps_trained: 2908800\n",
      "  num_env_steps_sampled: 91000\n",
      "  num_env_steps_trained: 2908800\n",
      "  num_target_updates: 182\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-29-56\n",
      "done: false\n",
      "episode_len_mean: 12989.833333333334\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: -0.16666666666666666\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 1\n",
      "episodes_total: 6\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 91000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 45449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.006146707106381655\n",
      "        max_q: 0.49119454622268677\n",
      "        mean_q: 0.4799974262714386\n",
      "        min_q: 0.45641976594924927\n",
      "      mean_td_error: -0.002285843249410391\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 45450.0\n",
      "      td_error: [0.0010476112365722656, 0.0010476112365722656, 0.0010476112365722656,\n",
      "        -0.005201220512390137, -0.0024579763412475586, -0.0051337480545043945, -0.0024579763412475586,\n",
      "        0.0010476112365722656, -0.0024579763412475586, 0.0023239850997924805, -0.015371978282928467,\n",
      "        -0.015371978282928467, 0.008333295583724976, 0.002193957567214966, 0.002193957567214966,\n",
      "        0.008333295583724976, 0.002193957567214966, -0.015465527772903442, -0.015371978282928467,\n",
      "        -0.0024579763412475586, -0.005201220512390137, -0.015321224927902222, -0.0024579763412475586,\n",
      "        0.002193957567214966, 0.002193957567214966, -0.005201220512390137, 0.008596718311309814,\n",
      "        -0.0024579763412475586, 0.0012016594409942627, -0.015371978282928467, 0.0010476112365722656,\n",
      "        0.002139538526535034, -0.015371978282928467, -0.015371978282928467, -0.005451291799545288,\n",
      "        -0.005201220512390137, -0.015371978282928467, 0.008333295583724976, 0.008333295583724976,\n",
      "        -0.005201220512390137, -0.015371978282928467, 0.008333295583724976, 0.0010476112365722656,\n",
      "        -0.005201220512390137, -0.015371978282928467, 0.002193957567214966, 0.008333295583724976,\n",
      "        0.008333295583724976, 0.008333295583724976, 0.008333295583724976, -0.015371978282928467,\n",
      "        -0.015371978282928467, 0.008333295583724976, 0.002193957567214966, -0.015371978282928467,\n",
      "        -0.005201220512390137, 0.0044119954109191895, -0.0024579763412475586, 0.008333295583724976,\n",
      "        -0.005201220512390137, 0.002193957567214966, 0.008333295583724976, 0.0010476112365722656,\n",
      "        -0.005201220512390137]\n",
      "  num_agent_steps_sampled: 91000\n",
      "  num_agent_steps_trained: 2908800\n",
      "  num_env_steps_sampled: 91000\n",
      "  num_env_steps_trained: 2908800\n",
      "  num_target_updates: 182\n",
      "iterations_since_restore: 91\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 91000\n",
      "num_agent_steps_trained: 2908800\n",
      "num_env_steps_sampled: 91000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 18.201929670897204\n",
      "num_env_steps_trained: 2908800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 582.4617494687105\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 25.90128205128205\n",
      "  ram_util_percent: 73.94871794871796\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04999205756957576\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 68.93967669828422\n",
      "  mean_inference_ms: 0.9525189933124011\n",
      "  mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "    StateBufferConnector_ms: 0.002769629160563151\n",
      "    ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 12989.833333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -0.16666666666666666\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 1\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262, 5141]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04999205756957576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 68.93967669828422\n",
      "    mean_inference_ms: 0.9525189933124011\n",
      "    mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "time_since_restore: 5499.59962105751\n",
      "time_this_iter_s: 54.9622118473053\n",
      "time_total_s: 5499.59962105751\n",
      "timers:\n",
      "  learn_throughput: 4715.45\n",
      "  learn_time_ms: 13.572\n",
      "  load_throughput: 586487.778\n",
      "  load_time_ms: 0.109\n",
      "  sample_time_ms: 86.896\n",
      "  synch_weights_time_ms: 6.222\n",
      "  training_iteration_time_ms: 118.104\n",
      "timestamp: 1709836196\n",
      "timesteps_total: 91000\n",
      "training_iteration: 91\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 92000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "  StateBufferConnector_ms: 0.002769629160563151\n",
      "  ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "counters:\n",
      "  last_target_update_ts: 92000\n",
      "  num_agent_steps_sampled: 92000\n",
      "  num_agent_steps_trained: 2940800\n",
      "  num_env_steps_sampled: 92000\n",
      "  num_env_steps_trained: 2940800\n",
      "  num_target_updates: 184\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-30-52\n",
      "done: false\n",
      "episode_len_mean: 12989.833333333334\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: -0.16666666666666666\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 6\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 92000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 45949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0051521905697882175\n",
      "        max_q: 0.5005137324333191\n",
      "        mean_q: 0.48090487718582153\n",
      "        min_q: 0.4701946973800659\n",
      "      mean_td_error: -0.0012126350775361061\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 45950.0\n",
      "      td_error: [-0.00717809796333313, 0.003635793924331665, 0.005966901779174805,\n",
      "        0.005966901779174805, -0.00717809796333313, 0.0037470459938049316, -0.010527878999710083,\n",
      "        -0.005123436450958252, -0.005123436450958252, 0.007692575454711914, -0.010527878999710083,\n",
      "        0.005966901779174805, 0.007692575454711914, -0.005123436450958252, 0.00700792670249939,\n",
      "        0.003812074661254883, 0.005966901779174805, 0.003635793924331665, -0.00717809796333313,\n",
      "        -0.005123436450958252, -0.010527878999710083, -0.00717809796333313, 0.003635793924331665,\n",
      "        -0.005123436450958252, -0.005123436450958252, 0.007692575454711914, -0.00717809796333313,\n",
      "        0.007692575454711914, -0.005123436450958252, 0.005966901779174805, -0.010527878999710083,\n",
      "        -0.010527878999710083, -0.010527878999710083, -0.010527878999710083, 0.005966901779174805,\n",
      "        -0.010527878999710083, 0.003635793924331665, 0.003635793924331665, -0.010527878999710083,\n",
      "        -0.00717809796333313, 0.005966901779174805, -0.00717809796333313, -0.005123436450958252,\n",
      "        -0.00717809796333313, 0.003635793924331665, 0.005966901779174805, 0.007692575454711914,\n",
      "        -0.005123436450958252, 0.005966901779174805, -0.00717809796333313, -0.00717809796333313,\n",
      "        0.018288373947143555, 0.003635793924331665, -0.009423702955245972, 0.007692575454711914,\n",
      "        0.005966901779174805, 0.005966901779174805, -0.00717809796333313, -0.005123436450958252,\n",
      "        0.003635793924331665, -0.010527878999710083, 0.003635793924331665, -0.005123436450958252,\n",
      "        -0.004958212375640869]\n",
      "  num_agent_steps_sampled: 92000\n",
      "  num_agent_steps_trained: 2940800\n",
      "  num_env_steps_sampled: 92000\n",
      "  num_env_steps_trained: 2940800\n",
      "  num_target_updates: 184\n",
      "iterations_since_restore: 92\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 92000\n",
      "num_agent_steps_trained: 2940800\n",
      "num_env_steps_sampled: 92000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.75343108760002\n",
      "num_env_steps_trained: 2940800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 568.1097948032007\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 28.64177215189874\n",
      "  ram_util_percent: 71.31392405063292\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04999205756957576\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 68.93967669828422\n",
      "  mean_inference_ms: 0.9525189933124011\n",
      "  mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "    StateBufferConnector_ms: 0.002769629160563151\n",
      "    ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 12989.833333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -0.16666666666666666\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262, 5141]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04999205756957576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 68.93967669828422\n",
      "    mean_inference_ms: 0.9525189933124011\n",
      "    mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "time_since_restore: 5555.948666095734\n",
      "time_this_iter_s: 56.34904503822327\n",
      "time_total_s: 5555.948666095734\n",
      "timers:\n",
      "  learn_throughput: 4087.735\n",
      "  learn_time_ms: 15.657\n",
      "  load_throughput: 651858.805\n",
      "  load_time_ms: 0.098\n",
      "  sample_time_ms: 85.775\n",
      "  synch_weights_time_ms: 6.065\n",
      "  training_iteration_time_ms: 119.528\n",
      "timestamp: 1709836252\n",
      "timesteps_total: 92000\n",
      "training_iteration: 92\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 93000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "  StateBufferConnector_ms: 0.002769629160563151\n",
      "  ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "counters:\n",
      "  last_target_update_ts: 93000\n",
      "  num_agent_steps_sampled: 93000\n",
      "  num_agent_steps_trained: 2972800\n",
      "  num_env_steps_sampled: 93000\n",
      "  num_env_steps_trained: 2972800\n",
      "  num_target_updates: 186\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-31-53\n",
      "done: false\n",
      "episode_len_mean: 12989.833333333334\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: -0.16666666666666666\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 6\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 93000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 46449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.007988707162439823\n",
      "        max_q: 0.5049008131027222\n",
      "        mean_q: 0.4933890700340271\n",
      "        min_q: 0.4810396730899811\n",
      "      mean_td_error: 0.008239752613008022\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 46450.0\n",
      "      td_error: [0.006288439035415649, 0.011255055665969849, 0.014272361993789673,\n",
      "        0.014272361993789673, 0.006288439035415649, 0.009003967046737671, 0.011255055665969849,\n",
      "        0.011255055665969849, 0.009003967046737671, 0.006288439035415649, 0.011255055665969849,\n",
      "        0.014272361993789673, 0.011255055665969849, 0.01954430341720581, 0.014272361993789673,\n",
      "        -0.002193748950958252, 0.009206503629684448, 0.006288439035415649, -0.002193748950958252,\n",
      "        -0.002193748950958252, 0.009003967046737671, -0.002193748950958252, 0.01954430341720581,\n",
      "        0.01954430341720581, 0.011255055665969849, 0.006288439035415649, -0.002193748950958252,\n",
      "        -0.0017629265785217285, 0.006288439035415649, -0.002193748950958252, 0.014272361993789673,\n",
      "        0.006288439035415649, 0.009003967046737671, 0.011255055665969849, -0.0017629265785217285,\n",
      "        -0.002193748950958252, 0.009003967046737671, 0.006288439035415649, -0.002193748950958252,\n",
      "        0.006288439035415649, -0.002193748950958252, 0.006288439035415649, 0.014272361993789673,\n",
      "        0.014272361993789673, 0.014272361993789673, 0.01954430341720581, 0.011255055665969849,\n",
      "        0.006288439035415649, 0.011255055665969849, 0.0005630552768707275, 0.009003967046737671,\n",
      "        0.006288439035415649, 0.014421403408050537, 0.014272361993789673, -0.002193748950958252,\n",
      "        0.006288439035415649, 0.014272361993789673, 0.009003967046737671, 0.011255055665969849,\n",
      "        0.014272361993789673, 0.006288439035415649, 0.008987665176391602, 0.006288439035415649,\n",
      "        0.014550775289535522]\n",
      "  num_agent_steps_sampled: 93000\n",
      "  num_agent_steps_trained: 2972800\n",
      "  num_env_steps_sampled: 93000\n",
      "  num_env_steps_trained: 2972800\n",
      "  num_target_updates: 186\n",
      "iterations_since_restore: 93\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 93000\n",
      "num_agent_steps_trained: 2972800\n",
      "num_env_steps_sampled: 93000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 16.593777957564523\n",
      "num_env_steps_trained: 2972800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 531.0008946420647\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 59.26511627906977\n",
      "  ram_util_percent: 70.3767441860465\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04999205756957576\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 68.93967669828422\n",
      "  mean_inference_ms: 0.9525189933124011\n",
      "  mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "    StateBufferConnector_ms: 0.002769629160563151\n",
      "    ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 12989.833333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -0.16666666666666666\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262, 5141]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04999205756957576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 68.93967669828422\n",
      "    mean_inference_ms: 0.9525189933124011\n",
      "    mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "time_since_restore: 5616.230464935303\n",
      "time_this_iter_s: 60.28179883956909\n",
      "time_total_s: 5616.230464935303\n",
      "timers:\n",
      "  learn_throughput: 6253.913\n",
      "  learn_time_ms: 10.234\n",
      "  load_throughput: 496826.681\n",
      "  load_time_ms: 0.129\n",
      "  sample_time_ms: 90.98\n",
      "  synch_weights_time_ms: 3.236\n",
      "  training_iteration_time_ms: 116.009\n",
      "timestamp: 1709836313\n",
      "timesteps_total: 93000\n",
      "training_iteration: 93\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 94000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "  StateBufferConnector_ms: 0.002769629160563151\n",
      "  ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "counters:\n",
      "  last_target_update_ts: 94000\n",
      "  num_agent_steps_sampled: 94000\n",
      "  num_agent_steps_trained: 3004800\n",
      "  num_env_steps_sampled: 94000\n",
      "  num_env_steps_trained: 3004800\n",
      "  num_target_updates: 188\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-32-49\n",
      "done: false\n",
      "episode_len_mean: 12989.833333333334\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: -0.16666666666666666\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 6\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 94000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 46949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.004233167972415686\n",
      "        max_q: 0.5552768707275391\n",
      "        mean_q: 0.4962673485279083\n",
      "        min_q: 0.48597240447998047\n",
      "      mean_td_error: 0.010095681995153427\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 46950.0\n",
      "      td_error: [0.000281602144241333, 0.4940871000289917, 0.000281602144241333, 0.0019843876361846924,\n",
      "        0.00011149048805236816, 0.0036742091178894043, 0.0036742091178894043, 0.00011149048805236816,\n",
      "        0.0019843876361846924, 0.0036742091178894043, 0.000281602144241333, 0.0019843876361846924,\n",
      "        0.0036742091178894043, 0.0019843876361846924, 0.0036742091178894043, 0.00027754902839660645,\n",
      "        0.0037728846073150635, 0.000281602144241333, 0.000281602144241333, 0.00011149048805236816,\n",
      "        0.00322917103767395, 0.0019843876361846924, 0.0036742091178894043, 0.00011149048805236816,\n",
      "        0.0019843876361846924, 0.0036742091178894043, 0.0036742091178894043, 0.04502749443054199,\n",
      "        0.0036742091178894043, -0.0002105236053466797, 0.00011149048805236816, 0.000281602144241333,\n",
      "        0.00011149048805236816, 0.00322917103767395, 0.0036742091178894043, 0.00011149048805236816,\n",
      "        0.0035181641578674316, 0.000281602144241333, 0.0029754340648651123, 0.000281602144241333,\n",
      "        0.0029754340648651123, 0.00011149048805236816, 0.000281602144241333, 0.00011149048805236816,\n",
      "        0.0019843876361846924, 0.000281602144241333, 0.00322917103767395, 0.0036742091178894043,\n",
      "        0.0036742091178894043, 0.000281602144241333, 0.000281602144241333, 0.0005495548248291016,\n",
      "        0.00011149048805236816, 0.00322917103767395, 0.0036742091178894043, 0.000281602144241333,\n",
      "        0.000281602144241333, 0.00011149048805236816, 0.002255856990814209, 0.000281602144241333,\n",
      "        0.00322917103767395, 0.0019843876361846924, 0.0019843876361846924, 0.0036742091178894043]\n",
      "  num_agent_steps_sampled: 94000\n",
      "  num_agent_steps_trained: 3004800\n",
      "  num_env_steps_sampled: 94000\n",
      "  num_env_steps_trained: 3004800\n",
      "  num_target_updates: 188\n",
      "iterations_since_restore: 94\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 94000\n",
      "num_agent_steps_trained: 3004800\n",
      "num_env_steps_sampled: 94000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.744562830072436\n",
      "num_env_steps_trained: 3004800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 567.826010562318\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.62658227848101\n",
      "  ram_util_percent: 73.92025316455697\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04999205756957576\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 68.93967669828422\n",
      "  mean_inference_ms: 0.9525189933124011\n",
      "  mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "    StateBufferConnector_ms: 0.002769629160563151\n",
      "    ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 12989.833333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -0.16666666666666666\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262, 5141]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04999205756957576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 68.93967669828422\n",
      "    mean_inference_ms: 0.9525189933124011\n",
      "    mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "time_since_restore: 5672.6045570373535\n",
      "time_this_iter_s: 56.37409210205078\n",
      "time_total_s: 5672.6045570373535\n",
      "timers:\n",
      "  learn_throughput: 6028.045\n",
      "  learn_time_ms: 10.617\n",
      "  load_throughput: 546266.699\n",
      "  load_time_ms: 0.117\n",
      "  sample_time_ms: 79.379\n",
      "  synch_weights_time_ms: 3.233\n",
      "  training_iteration_time_ms: 104.837\n",
      "timestamp: 1709836369\n",
      "timesteps_total: 94000\n",
      "training_iteration: 94\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 93x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m \n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 95000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "  StateBufferConnector_ms: 0.002769629160563151\n",
      "  ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "counters:\n",
      "  last_target_update_ts: 95000\n",
      "  num_agent_steps_sampled: 95000\n",
      "  num_agent_steps_trained: 3036800\n",
      "  num_env_steps_sampled: 95000\n",
      "  num_env_steps_trained: 3036800\n",
      "  num_target_updates: 190\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-33-45\n",
      "done: false\n",
      "episode_len_mean: 12989.833333333334\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: -0.16666666666666666\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 6\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 95000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 47449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.006352581083774567\n",
      "        max_q: 0.5688689947128296\n",
      "        mean_q: 0.4985520541667938\n",
      "        min_q: 0.49471402168273926\n",
      "      mean_td_error: 0.05402393639087677\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 47450.0\n",
      "      td_error: [0.07337620854377747, -0.0004273355007171631, -0.0004273355007171631,\n",
      "        0.0032387971878051758, 0.005578428506851196, 0.0032387971878051758, 0.0016151964664459229,\n",
      "        0.003831148147583008, 0.0028176605701446533, -0.0005379617214202881, -0.0005379617214202881,\n",
      "        0.0016151964664459229, 0.005578428506851196, 0.005578428506851196, -0.0005379617214202881,\n",
      "        0.0032387971878051758, 0.005578428506851196, 0.003831148147583008, 0.0016151964664459229,\n",
      "        0.005578428506851196, 0.0032387971878051758, -0.0004273355007171631, -0.08345627784729004,\n",
      "        -0.0004273355007171631, -0.0004273355007171631, 0.0016151964664459229, -0.0005379617214202881,\n",
      "        0.0016151964664459229, 0.0027585625648498535, -0.0005379617214202881, 0.0032387971878051758,\n",
      "        0.0032387971878051758, 0.005661994218826294, 0.005948692560195923, -0.0004273355007171631,\n",
      "        -0.0004273355007171631, 0.0016151964664459229, 0.0016151964664459229, -0.0005379617214202881,\n",
      "        0.005707889795303345, 0.0013743937015533447, 0.0032387971878051758, 0.0032387971878051758,\n",
      "        -0.0004273355007171631, 0.0016151964664459229, 0.003831148147583008, 0.0032387971878051758,\n",
      "        0.003478109836578369, 0.005707889795303345, -0.0797901451587677, 0.0010927021503448486,\n",
      "        0.0016151964664459229, 0.0013710260391235352, 0.0032387971878051758, -0.0005379617214202881,\n",
      "        0.0010927021503448486, -0.07745051383972168, -0.0005379617214202881, -0.0004273355007171631,\n",
      "        0.005578428506851196, -0.0004273355007171631, 0.0016151964664459229, 3.4990830421447754,\n",
      "        0.003831148147583008]\n",
      "  num_agent_steps_sampled: 95000\n",
      "  num_agent_steps_trained: 3036800\n",
      "  num_env_steps_sampled: 95000\n",
      "  num_env_steps_trained: 3036800\n",
      "  num_target_updates: 190\n",
      "iterations_since_restore: 95\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 95000\n",
      "num_agent_steps_trained: 3036800\n",
      "num_env_steps_sampled: 95000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.90094075343969\n",
      "num_env_steps_trained: 3036800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 572.8301041100701\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.41875\n",
      "  ram_util_percent: 75.52125\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04999205756957576\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 68.93967669828422\n",
      "  mean_inference_ms: 0.9525189933124011\n",
      "  mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "    StateBufferConnector_ms: 0.002769629160563151\n",
      "    ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 12989.833333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -0.16666666666666666\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262, 5141]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04999205756957576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 68.93967669828422\n",
      "    mean_inference_ms: 0.9525189933124011\n",
      "    mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "time_since_restore: 5728.48533987999\n",
      "time_this_iter_s: 55.88078284263611\n",
      "time_total_s: 5728.48533987999\n",
      "timers:\n",
      "  learn_throughput: 5930.283\n",
      "  learn_time_ms: 10.792\n",
      "  load_throughput: 591267.524\n",
      "  load_time_ms: 0.108\n",
      "  sample_time_ms: 94.532\n",
      "  synch_weights_time_ms: 3.225\n",
      "  training_iteration_time_ms: 120.048\n",
      "timestamp: 1709836425\n",
      "timesteps_total: 95000\n",
      "training_iteration: 95\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 96000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "  StateBufferConnector_ms: 0.002769629160563151\n",
      "  ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "counters:\n",
      "  last_target_update_ts: 96000\n",
      "  num_agent_steps_sampled: 96000\n",
      "  num_agent_steps_trained: 3068800\n",
      "  num_env_steps_sampled: 96000\n",
      "  num_env_steps_trained: 3068800\n",
      "  num_target_updates: 192\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-34-41\n",
      "done: false\n",
      "episode_len_mean: 12989.833333333334\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: -0.16666666666666666\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 6\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 96000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 47949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0017473110929131508\n",
      "        max_q: 0.4968794286251068\n",
      "        mean_q: 0.4940568804740906\n",
      "        min_q: 0.49002766609191895\n",
      "      mean_td_error: 3.3515505492687225e-05\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 47950.0\n",
      "      td_error: [0.0034028291702270508, 0.0005903244018554688, 0.0034028291702270508,\n",
      "        0.0034028291702270508, -0.00034233927726745605, 0.0034028291702270508, 0.0034028291702270508,\n",
      "        0.0034028291702270508, -0.00034233927726745605, 0.0034028291702270508, 0.0005903244018554688,\n",
      "        0.0005903244018554688, 0.0034028291702270508, -0.00034233927726745605, 0.0005903244018554688,\n",
      "        0.00046136975288391113, 0.0005903244018554688, -0.0005647540092468262, -0.0005647540092468262,\n",
      "        -0.00034233927726745605, -0.0032668113708496094, 0.0034028291702270508, 0.0034028291702270508,\n",
      "        -0.0005647540092468262, -0.0005647540092468262, 0.0005903244018554688, 0.0005903244018554688,\n",
      "        0.0031943917274475098, 0.0005903244018554688, 0.0005903244018554688, 0.0034028291702270508,\n",
      "        -0.04134184122085571, -0.0032668113708496094, -0.0032668113708496094, -0.00034233927726745605,\n",
      "        -0.0005755126476287842, -0.0032668113708496094, 0.0034028291702270508, 0.0034028291702270508,\n",
      "        0.0005903244018554688, -0.0005647540092468262, -0.00034233927726745605, -0.00034233927726745605,\n",
      "        -0.0005647540092468262, 0.0031943917274475098, -0.00034233927726745605, -0.0005647540092468262,\n",
      "        0.0031943917274475098, -0.0032668113708496094, -0.0032668113708496094, 0.0031943917274475098,\n",
      "        0.0031943917274475098, 0.0034028291702270508, -0.0005755126476287842, -0.0032668113708496094,\n",
      "        -0.0032668113708496094, -0.00034233927726745605, -0.0005647540092468262, 0.0034028291702270508,\n",
      "        0.0034028291702270508, -0.00034233927726745605, -0.00034233927726745605, 0.002839028835296631,\n",
      "        -0.0005647540092468262]\n",
      "  num_agent_steps_sampled: 96000\n",
      "  num_agent_steps_trained: 3068800\n",
      "  num_env_steps_sampled: 96000\n",
      "  num_env_steps_trained: 3068800\n",
      "  num_target_updates: 192\n",
      "iterations_since_restore: 96\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 96000\n",
      "num_agent_steps_trained: 3068800\n",
      "num_env_steps_sampled: 96000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.9369372902297\n",
      "num_env_steps_trained: 3068800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 573.9819932873504\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.66153846153846\n",
      "  ram_util_percent: 75.95897435897439\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04999205756957576\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 68.93967669828422\n",
      "  mean_inference_ms: 0.9525189933124011\n",
      "  mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "    StateBufferConnector_ms: 0.002769629160563151\n",
      "    ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 12989.833333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -0.16666666666666666\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262, 5141]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04999205756957576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 68.93967669828422\n",
      "    mean_inference_ms: 0.9525189933124011\n",
      "    mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "time_since_restore: 5784.254966974258\n",
      "time_this_iter_s: 55.7696270942688\n",
      "time_total_s: 5784.254966974258\n",
      "timers:\n",
      "  learn_throughput: 6186.489\n",
      "  learn_time_ms: 10.345\n",
      "  load_throughput: 558542.355\n",
      "  load_time_ms: 0.115\n",
      "  sample_time_ms: 79.866\n",
      "  synch_weights_time_ms: 3.261\n",
      "  training_iteration_time_ms: 104.626\n",
      "timestamp: 1709836481\n",
      "timesteps_total: 96000\n",
      "training_iteration: 96\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 93x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 97000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "  StateBufferConnector_ms: 0.002769629160563151\n",
      "  ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "counters:\n",
      "  last_target_update_ts: 97000\n",
      "  num_agent_steps_sampled: 97000\n",
      "  num_agent_steps_trained: 3100800\n",
      "  num_env_steps_sampled: 97000\n",
      "  num_env_steps_trained: 3100800\n",
      "  num_target_updates: 194\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-35-38\n",
      "done: false\n",
      "episode_len_mean: 12989.833333333334\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: -0.16666666666666666\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 6\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 97000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 48449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.004562643356621265\n",
      "        max_q: 0.494370698928833\n",
      "        mean_q: 0.4905617833137512\n",
      "        min_q: 0.4859292805194855\n",
      "      mean_td_error: 0.056212954223155975\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 48450.0\n",
      "      td_error: [0.003501713275909424, 0.002865821123123169, 0.003598719835281372,\n",
      "        -0.002734363079071045, -0.002734363079071045, 0.005272030830383301, -0.002734363079071045,\n",
      "        -0.002734363079071045, -0.002734363079071045, -0.002734363079071045, 0.003501713275909424,\n",
      "        0.002865821123123169, -0.002734363079071045, 0.0030508339405059814, 0.0030508339405059814,\n",
      "        0.002865821123123169, 0.002865821123123169, 0.003619760274887085, -0.002734363079071045,\n",
      "        0.002865821123123169, 0.003619760274887085, 0.003501713275909424, 0.005272030830383301,\n",
      "        -0.002734363079071045, 3.485929250717163, 0.003619760274887085, 0.005272030830383301,\n",
      "        0.0027795732021331787, -0.002734363079071045, 0.003619760274887085, 0.005272030830383301,\n",
      "        0.003501713275909424, 0.002865821123123169, 0.0030508339405059814, 0.005272030830383301,\n",
      "        0.002865821123123169, 0.002865821123123169, 0.003619760274887085, 0.003501713275909424,\n",
      "        0.003501713275909424, -0.002734363079071045, 0.002865821123123169, 0.003619760274887085,\n",
      "        0.003619760274887085, 0.003501713275909424, 0.002865821123123169, 0.003501713275909424,\n",
      "        0.003501713275909424, -0.002734363079071045, 0.005272030830383301, -0.009589314460754395,\n",
      "        0.0033032000064849854, -0.002734363079071045, -0.002734363079071045, 0.005402982234954834,\n",
      "        0.002865821123123169, 0.0030508339405059814, 0.002865821123123169, 0.0030508339405059814,\n",
      "        0.003501713275909424, 0.005272030830383301, -0.002734363079071045, -0.002734363079071045,\n",
      "        0.0030508339405059814]\n",
      "  num_agent_steps_sampled: 97000\n",
      "  num_agent_steps_trained: 3100800\n",
      "  num_env_steps_sampled: 97000\n",
      "  num_env_steps_trained: 3100800\n",
      "  num_target_updates: 194\n",
      "iterations_since_restore: 97\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 97000\n",
      "num_agent_steps_trained: 3100800\n",
      "num_env_steps_sampled: 97000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.557789164378338\n",
      "num_env_steps_trained: 3100800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 561.8492532601068\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.767901234567905\n",
      "  ram_util_percent: 76.79753086419751\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04999205756957576\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 68.93967669828422\n",
      "  mean_inference_ms: 0.9525189933124011\n",
      "  mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "    StateBufferConnector_ms: 0.002769629160563151\n",
      "    ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 12989.833333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -0.16666666666666666\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262, 5141]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04999205756957576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 68.93967669828422\n",
      "    mean_inference_ms: 0.9525189933124011\n",
      "    mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "time_since_restore: 5841.229122638702\n",
      "time_this_iter_s: 56.97415566444397\n",
      "time_total_s: 5841.229122638702\n",
      "timers:\n",
      "  learn_throughput: 5899.603\n",
      "  learn_time_ms: 10.848\n",
      "  load_throughput: 571382.41\n",
      "  load_time_ms: 0.112\n",
      "  sample_time_ms: 96.335\n",
      "  synch_weights_time_ms: 3.252\n",
      "  training_iteration_time_ms: 122.64\n",
      "timestamp: 1709836538\n",
      "timesteps_total: 97000\n",
      "training_iteration: 97\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95588)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 98000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "  StateBufferConnector_ms: 0.002769629160563151\n",
      "  ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "counters:\n",
      "  last_target_update_ts: 98000\n",
      "  num_agent_steps_sampled: 98000\n",
      "  num_agent_steps_trained: 3132800\n",
      "  num_env_steps_sampled: 98000\n",
      "  num_env_steps_trained: 3132800\n",
      "  num_target_updates: 196\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-36-34\n",
      "done: false\n",
      "episode_len_mean: 12989.833333333334\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: -0.16666666666666666\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 6\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 98000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 48949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0006808118778280914\n",
      "        max_q: 0.49506261944770813\n",
      "        mean_q: 0.4939170181751251\n",
      "        min_q: 0.49213868379592896\n",
      "      mean_td_error: -0.00017136381939053535\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 48950.0\n",
      "      td_error: [0.000495612621307373, 0.000495612621307373, -0.0008454620838165283,\n",
      "        0.0007743239402770996, 0.0007183849811553955, -0.0008454620838165283, -0.0017682909965515137,\n",
      "        -0.0008454620838165283, 0.000495612621307373, -0.0005402266979217529, -0.0008454620838165283,\n",
      "        0.000495612621307373, 0.0007743239402770996, -0.0008454620838165283, 0.0007743239402770996,\n",
      "        -0.0008454620838165283, -0.0008454620838165283, -0.0017682909965515137, -0.0005402266979217529,\n",
      "        0.000495612621307373, -0.0017682909965515137, -0.0010275542736053467, 0.000495612621307373,\n",
      "        0.0007743239402770996, 0.00017318129539489746, -0.0017682909965515137, -0.0005402266979217529,\n",
      "        -0.0017682909965515137, -0.0005402266979217529, -0.0017682909965515137, -0.0008454620838165283,\n",
      "        -0.0008454620838165283, -0.0017682909965515137, 0.0007183849811553955, 0.000495612621307373,\n",
      "        0.000495612621307373, -0.0008454620838165283, 0.0007743239402770996, -0.0009725093841552734,\n",
      "        -0.0008454620838165283, 0.0007183849811553955, -0.0017682909965515137, -0.0005402266979217529,\n",
      "        0.0007183849811553955, 0.0007183849811553955, 0.0007743239402770996, 0.0007183849811553955,\n",
      "        -0.0017682909965515137, -0.0005402266979217529, 0.000495612621307373, 0.0007183849811553955,\n",
      "        0.0007183849811553955, -0.0008454620838165283, 0.00063362717628479, 0.0007743239402770996,\n",
      "        0.0007743239402770996, -0.0008454620838165283, 0.000495612621307373, 0.0007743239402770996,\n",
      "        0.000495612621307373, 0.000495612621307373, 0.000495612621307373, 0.0007183849811553955,\n",
      "        0.000495612621307373]\n",
      "  num_agent_steps_sampled: 98000\n",
      "  num_agent_steps_trained: 3132800\n",
      "  num_env_steps_sampled: 98000\n",
      "  num_env_steps_trained: 3132800\n",
      "  num_target_updates: 196\n",
      "iterations_since_restore: 98\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 98000\n",
      "num_agent_steps_trained: 3132800\n",
      "num_env_steps_sampled: 98000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.881199466970834\n",
      "num_env_steps_trained: 3132800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 572.1983829430667\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.713924050632908\n",
      "  ram_util_percent: 77.09873417721516\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.04999205756957576\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 68.93967669828422\n",
      "  mean_inference_ms: 0.9525189933124011\n",
      "  mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004112720489501953\n",
      "    StateBufferConnector_ms: 0.002769629160563151\n",
      "    ViewRequirementAgentConnector_ms: 0.10260740915934245\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 12989.833333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -0.16666666666666666\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262, 5141]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0, -3.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04999205756957576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 68.93967669828422\n",
      "    mean_inference_ms: 0.9525189933124011\n",
      "    mean_raw_obs_processing_ms: 0.39235648332892925\n",
      "time_since_restore: 5897.171838760376\n",
      "time_this_iter_s: 55.942716121673584\n",
      "time_total_s: 5897.171838760376\n",
      "timers:\n",
      "  learn_throughput: 6102.137\n",
      "  learn_time_ms: 10.488\n",
      "  load_throughput: 514835.934\n",
      "  load_time_ms: 0.124\n",
      "  sample_time_ms: 84.674\n",
      "  synch_weights_time_ms: 3.153\n",
      "  training_iteration_time_ms: 110.033\n",
      "timestamp: 1709836594\n",
      "timesteps_total: 98000\n",
      "training_iteration: 98\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 84x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 92x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 99000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.0041348593575613836\n",
      "  StateBufferConnector_ms: 0.0028031212942940848\n",
      "  ViewRequirementAgentConnector_ms: 0.1018660409109933\n",
      "counters:\n",
      "  last_target_update_ts: 99000\n",
      "  num_agent_steps_sampled: 99000\n",
      "  num_agent_steps_trained: 3164800\n",
      "  num_env_steps_sampled: 99000\n",
      "  num_env_steps_trained: 3164800\n",
      "  num_target_updates: 198\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-37-30\n",
      "done: false\n",
      "episode_len_mean: 13474.714285714286\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.5714285714285714\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 1\n",
      "episodes_total: 7\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 99000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 49449.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.0034136860631406307\n",
      "        max_q: 0.5047406554222107\n",
      "        mean_q: 0.502841591835022\n",
      "        min_q: 0.4993196725845337\n",
      "      mean_td_error: 0.0038261646404862404\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 49450.0\n",
      "      td_error: [0.0057923197746276855, 0.004243403673171997, 0.004243403673171997,\n",
      "        0.004448503255844116, 0.0025535523891448975, 0.004243403673171997, 8.574128150939941e-05,\n",
      "        0.004243403673171997, 0.004243403673171997, 0.004448503255844116, 0.0025535523891448975,\n",
      "        0.0025535523891448975, 8.574128150939941e-05, 8.574128150939941e-05, 0.004243403673171997,\n",
      "        0.0025535523891448975, 0.004448503255844116, 8.574128150939941e-05, 0.005506724119186401,\n",
      "        0.004448503255844116, 0.004448503255844116, 0.005506724119186401, 0.005351513624191284,\n",
      "        8.574128150939941e-05, 0.004243403673171997, 0.0021820366382598877, 0.005351513624191284,\n",
      "        0.005351513624191284, 0.004448503255844116, 0.004243403673171997, 0.005506724119186401,\n",
      "        0.004243403673171997, 0.004448503255844116, 0.004243403673171997, 0.004448503255844116,\n",
      "        0.0025535523891448975, 0.004243403673171997, 0.0025535523891448975, 0.0025535523891448975,\n",
      "        0.019783735275268555, 8.574128150939941e-05, 0.004243403673171997, 0.0041502416133880615,\n",
      "        0.004448503255844116, 8.574128150939941e-05, 0.005351513624191284, 0.004243403673171997,\n",
      "        0.004448503255844116, 0.005351513624191284, 0.005351513624191284, 0.0025535523891448975,\n",
      "        0.004448503255844116, 0.0025535523891448975, 8.574128150939941e-05, 0.005351513624191284,\n",
      "        0.004448503255844116, 0.004243403673171997, 0.004448503255844116, 0.004448503255844116,\n",
      "        0.004243403673171997, 0.004243403673171997, 0.0025535523891448975, 3.692507743835449e-05,\n",
      "        0.0025535523891448975]\n",
      "  num_agent_steps_sampled: 99000\n",
      "  num_agent_steps_trained: 3164800\n",
      "  num_env_steps_sampled: 99000\n",
      "  num_env_steps_trained: 3164800\n",
      "  num_target_updates: 198\n",
      "iterations_since_restore: 99\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 99000\n",
      "num_agent_steps_trained: 3164800\n",
      "num_env_steps_sampled: 99000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 17.76971710771221\n",
      "num_env_steps_trained: 3164800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 568.6309474467907\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 21.350632911392402\n",
      "  ram_util_percent: 76.47215189873415\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05006317361521372\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 69.7821787963264\n",
      "  mean_inference_ms: 0.94941431065234\n",
      "  mean_raw_obs_processing_ms: 0.3902110313521204\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.0041348593575613836\n",
      "    StateBufferConnector_ms: 0.0028031212942940848\n",
      "    ViewRequirementAgentConnector_ms: 0.1018660409109933\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 13474.714285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.5714285714285714\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 1\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262, 5141, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0, -3.0, 5.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05006317361521372\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 69.7821787963264\n",
      "    mean_inference_ms: 0.94941431065234\n",
      "    mean_raw_obs_processing_ms: 0.3902110313521204\n",
      "time_since_restore: 5953.4665858745575\n",
      "time_this_iter_s: 56.29474711418152\n",
      "time_total_s: 5953.4665858745575\n",
      "timers:\n",
      "  learn_throughput: 6160.097\n",
      "  learn_time_ms: 10.389\n",
      "  load_throughput: 528624.372\n",
      "  load_time_ms: 0.121\n",
      "  sample_time_ms: 81.808\n",
      "  synch_weights_time_ms: 3.217\n",
      "  training_iteration_time_ms: 106.621\n",
      "timestamp: 1709836650\n",
      "timesteps_total: 99000\n",
      "training_iteration: 99\n",
      "trial_id: default\n",
      "\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 99x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 172x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 192x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 165x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=95589)\u001b[0m Pokédex: 0, Badges: 0, Death: 0, Levels: 0, exploration: 0\u001b[32m [repeated 90x across cluster]\u001b[0m\n",
      "agent_timesteps_total: 100000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.0041348593575613836\n",
      "  StateBufferConnector_ms: 0.0028031212942940848\n",
      "  ViewRequirementAgentConnector_ms: 0.1018660409109933\n",
      "counters:\n",
      "  last_target_update_ts: 100000\n",
      "  num_agent_steps_sampled: 100000\n",
      "  num_agent_steps_trained: 3196800\n",
      "  num_env_steps_sampled: 100000\n",
      "  num_env_steps_trained: 3196800\n",
      "  num_target_updates: 200\n",
      "custom_metrics: {}\n",
      "date: 2024-03-07_19-38-12\n",
      "done: false\n",
      "episode_len_mean: 13474.714285714286\n",
      "episode_media: {}\n",
      "episode_reward_max: 5.0\n",
      "episode_reward_mean: 0.5714285714285714\n",
      "episode_reward_min: -3.0\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 7\n",
      "hostname: Joeys-MacBook-Pro.local\n",
      "info:\n",
      "  last_target_update_ts: 100000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 49949.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.003374649677425623\n",
      "        max_q: 0.5106121301651001\n",
      "        mean_q: 0.5046276450157166\n",
      "        min_q: 0.4984714090824127\n",
      "      mean_td_error: 0.001890579704195261\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 64.0\n",
      "      num_grad_updates_lifetime: 49950.0\n",
      "      td_error: [-0.002953946590423584, 0.0029785633087158203, -0.002953946590423584,\n",
      "        -0.004103153944015503, 0.0029785633087158203, 0.0029785633087158203, -0.002953946590423584,\n",
      "        -0.002953946590423584, -0.003812849521636963, 0.007338464260101318, 0.004362881183624268,\n",
      "        0.004362881183624268, 0.004362881183624268, -0.002953946590423584, 0.007618367671966553,\n",
      "        -0.003812849521636963, 0.007338464260101318, -0.002953946590423584, -0.003812849521636963,\n",
      "        -0.002953946590423584, 0.0029785633087158203, 0.007338464260101318, 0.004362881183624268,\n",
      "        0.0031381845474243164, 0.007338464260101318, 0.007338464260101318, 0.015223085880279541,\n",
      "        0.007338464260101318, 0.0031381845474243164, 0.004362881183624268, -0.002953946590423584,\n",
      "        0.004362881183624268, 0.0029785633087158203, 0.0031381845474243164, -0.003812849521636963,\n",
      "        0.004362881183624268, 0.004362881183624268, -0.003812849521636963, 0.0029785633087158203,\n",
      "        0.004362881183624268, 0.007338464260101318, 0.0029785633087158203, 0.0029785633087158203,\n",
      "        0.0029785633087158203, -0.002953946590423584, 0.010569572448730469, 0.0029785633087158203,\n",
      "        -0.003812849521636963, 0.0031381845474243164, 0.0029785633087158203, 0.004362881183624268,\n",
      "        -0.002953946590423584, 0.0029785633087158203, -0.003812849521636963, 0.0029287338256835938,\n",
      "        -0.002953946590423584, 0.007338464260101318, -0.003812849521636963, 0.0029785633087158203,\n",
      "        0.004362881183624268, 0.004362881183624268, -0.002953946590423584, -0.003812849521636963,\n",
      "        -0.003812849521636963]\n",
      "  num_agent_steps_sampled: 100000\n",
      "  num_agent_steps_trained: 3196800\n",
      "  num_env_steps_sampled: 100000\n",
      "  num_env_steps_trained: 3196800\n",
      "  num_target_updates: 200\n",
      "iterations_since_restore: 100\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 100000\n",
      "num_agent_steps_trained: 3196800\n",
      "num_env_steps_sampled: 100000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 23.84942729074915\n",
      "num_env_steps_trained: 3196800\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 763.1816733039728\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 2\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 27.550000000000004\n",
      "  ram_util_percent: 77.64500000000001\n",
      "pid: 95515\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05006317361521372\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 69.7821787963264\n",
      "  mean_inference_ms: 0.94941431065234\n",
      "  mean_raw_obs_processing_ms: 0.3902110313521204\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.0041348593575613836\n",
      "    StateBufferConnector_ms: 0.0028031212942940848\n",
      "    ViewRequirementAgentConnector_ms: 0.1018660409109933\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 13474.714285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: 0.5714285714285714\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: [16384, 16384, 16384, 16384, 7262, 5141, 16384]\n",
      "    episode_reward: [5.0, 0.0, 0.0, 0.0, -3.0, -3.0, 5.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05006317361521372\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 69.7821787963264\n",
      "    mean_inference_ms: 0.94941431065234\n",
      "    mean_raw_obs_processing_ms: 0.3902110313521204\n",
      "time_since_restore: 5995.415114164352\n",
      "time_this_iter_s: 41.94852828979492\n",
      "time_total_s: 5995.415114164352\n",
      "timers:\n",
      "  learn_throughput: 6156.212\n",
      "  learn_time_ms: 10.396\n",
      "  load_throughput: 625140.792\n",
      "  load_time_ms: 0.102\n",
      "  sample_time_ms: 89.298\n",
      "  synch_weights_time_ms: 3.145\n",
      "  training_iteration_time_ms: 115.054\n",
      "timestamp: 1709836692\n",
      "timesteps_total: 100000\n",
      "training_iteration: 100\n",
      "trial_id: default\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.dqn.dqn import DQNConfig, DQN\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "replay_config = {\n",
    "        \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n",
    "        \"capacity\": 60000,\n",
    "        \"prioritized_replay_alpha\": 0.5,\n",
    "        \"prioritized_replay_beta\": 0.5,\n",
    "        \"prioritized_replay_eps\": 3e-6,\n",
    "    }\n",
    "\n",
    "config = (DQNConfig()\n",
    "          .training(replay_buffer_config=replay_config,\n",
    "                         train_batch_size=64,\n",
    "                         n_step=1,\n",
    "                         num_atoms=1,\n",
    "                         double_q=False,\n",
    "                         dueling=False,\n",
    "                         num_steps_sampled_before_learning_starts=100)\n",
    "            .resources(num_gpus=0)\n",
    "            .rollouts(num_rollout_workers=2)\n",
    "            .environment(\"PokemonEnv\"))\n",
    "algo = DQN(config=config)\n",
    "for i in range(100):\n",
    "   print(pretty_print(algo.train())) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
